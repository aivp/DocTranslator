import threading
import openai
import os
import sys
import time
import getopt
from . import to_translate
from . import word
from . import excel
from . import powerpoint
from . import pdf

from . import txt
from . import csv_handle
from . import md
from . import md_separator_fix
import pymysql
from . import db
from . import common
import traceback
from . import rediscon
import logging

# å½“å‰æ­£åœ¨æ‰§è¡Œçš„çº¿ç¨‹
run_threads=0

def main():
    global run_threads
    # ç¡¬ç¼–ç çº¿ç¨‹æ•°ä¸º30ï¼Œå¿½ç•¥å‰ç«¯ä¼ å…¥çš„é…ç½®
    max_threads=30
    # å½“å‰æ‰§è¡Œçš„ç´¢å¼•ä½ç½®
    run_index=0
    # æ˜¯å¦ä¿ç•™åŸæ–‡
    keep_original=False
    # è¦ç¿»è¯‘çš„æ–‡ä»¶è·¯å¾„
    file_path=''
    # ç¿»è¯‘åçš„ç›®æ ‡æ–‡ä»¶è·¯å¾„
    target_file=''
    uuid=sys.argv[1]
    storage_path=sys.argv[2]
    trans=db.get("select * from translate where uuid=%s", uuid)
    
    # éªŒè¯å¿…è¦å­—æ®µ
    if not trans or not trans.get('id'):
        logging.error(f"æœªæ‰¾åˆ°ç¿»è¯‘è®°å½•: uuid={uuid}")
        sys.exit(1)
    
    # éªŒè¯langå­—æ®µä¸èƒ½ä¸ºç©ºï¼ˆå¿…é¡»ç”±å‰ç«¯ä¼ é€’ï¼‰
    lang_value = trans.get('lang', '').strip() if trans.get('lang') else ''
    if not lang_value:
        logging.error(f"ç¿»è¯‘è®°å½•ä¸­langå­—æ®µç¼ºå¤±æˆ–ä¸ºç©º: uuid={uuid}, trans={trans}")
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        from datetime import datetime
        import pytz
        end_time = datetime.now(pytz.timezone('Asia/Shanghai'))
        db.execute("update translate set status='failed', failed_reason='ç›®æ ‡è¯­è¨€å‚æ•°(lang)ç¼ºå¤±æˆ–ä¸ºç©º', end_at=%s where uuid=%s", end_time, uuid)
        sys.exit(1)
    
    translate_id=trans['id']
    origin_filename=trans['origin_filename']
    origin_filepath=trans['origin_filepath']
    target_filepath=trans['target_filepath']
    api_key=trans['api_key']
    api_url=trans['api_url']
    comparison=get_comparison(trans['comparison_id'])
    prompt=get_prompt(trans['prompt_id'], comparison)
    if comparison:
        prompt = (
            "æœ¯è¯­å¯¹ç…§è¡¨:\n"
            f"{comparison}\n"
            "è¯·æŒ‰ç…§ä»¥ä¸‹è§„åˆ™è¿›è¡Œç¿»è¯‘ï¼š\n"
            "1. é‡åˆ°æœ¯è¯­æ—¶ï¼Œè¯·ä½¿ç”¨æœ¯è¯­å¯¹ç…§è¡¨ä¸­çš„å¯¹åº”ç¿»è¯‘ï¼Œæ— è®ºç¿»è¯‘æˆä»€ä¹ˆè¯­è¨€ã€‚\n"
            "2. æœªåœ¨æœ¯è¯­å¯¹ç…§è¡¨ä¸­çš„æ–‡æœ¬ï¼Œè¯·éµå¾ªç¿»è¯‘è¯´æ˜è¿›è¡Œç¿»è¯‘ã€‚\n"
            "3. ç¡®ä¿ç¿»è¯‘ç»“æœä¸åŒ…å«åŸæ–‡æˆ–ä»»ä½•è§£é‡Šã€‚\n"
            "ç¿»è¯‘è¯´æ˜:\n"
            f"{prompt}"
        )
    trans['prompt']=prompt
    
    file_path=storage_path+origin_filepath
    target_file=storage_path+target_filepath

    origin_path_dir=os.path.dirname(file_path)
    target_path_dir=os.path.dirname(target_file)
    
    if not os.path.exists(origin_path_dir):
        os.makedirs(origin_path_dir, mode=0o777, exist_ok=True)

    if not os.path.exists(target_path_dir):
        os.makedirs(target_path_dir, mode=0o777, exist_ok=True)

    trans['file_path']=file_path
    trans['target_file']=target_file
    trans['storage_path']=storage_path
    trans['target_path_dir']=target_path_dir
    extension = origin_filename[origin_filename.rfind('.'):]
    trans['extension']=extension
    trans['run_complete']=True
    item_count=0
    spend_time=''
    try:
        status=True
        # è®¾ç½®OpenAI API
        to_translate.init_openai(api_url, api_key)
        if extension=='.docx' or extension == '.doc':
            status=word.start(trans)
        elif extension=='.xls' or extension == '.xlsx':
            status=excel.start(trans)
        elif extension=='.ppt' or extension == '.pptx':
            status=powerpoint.start(trans)
        elif extension == '.pdf':
            # if pdf.is_scanned_pdf(trans['file_path']):
            #     status=gptpdf.start(trans)
            # else:
            status=pdf.start(trans)
        elif extension == '.txt':
            status=txt.start(trans)
        elif extension == '.csv':
            status=csv_handle.start(trans)
        elif extension == '.md':
            # ä½¿ç”¨ä¸“é—¨ä¿®å¤è¡¨æ ¼åˆ†éš”è¡Œçš„markdownç¿»è¯‘é€»è¾‘
            status=md_separator_fix.start(trans)
        if status:
            print("success")
            #before_active_count=threading.activeCount()
            #mredis.decr(api_url,threading_num-before_active_count)
            # print(item_count + ";" + spend_time)
        else:
            #before_active_count=threading.active_count()
            #mredis.decr(api_url,threading_num-before_active_count)
            logging.error("ç¿»è¯‘å‡ºé”™äº†")
    except Exception as e:
        #before_active_count=threading.active_count()
        #mredis.decr(api_url,threading_num-before_active_count)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        line_number = exc_traceback.tb_lineno  # å¼‚å¸¸æŠ›å‡ºçš„å…·ä½“è¡Œå·
        logging.error(f"Error occurred on line: {line_number}")
        logging.error(f"Error details: {e}")

def get_prompt(prompt_id, comparison):
    # ç¡®ä¿prompt_idä¸ä¸ºNoneï¼Œå¦‚æœæ˜¯Noneåˆ™è®¾ä¸º0
    if prompt_id is None:
        prompt_id = 0
    else:
        prompt_id = int(prompt_id)
    
    if prompt_id > 0:
        prompt=db.get("select content from prompt where id=%s and deleted_flag='N'", prompt_id)
        if prompt and len(prompt['content'])>0:
            return prompt['content']

    prompt=db.get("select value from setting where `group`='other_setting' and alias='prompt'")
    return prompt['value']

def get_comparison(comparison_id):
    # ç¡®ä¿comparison_idä¸ä¸ºNoneï¼Œå¦‚æœæ˜¯Noneåˆ™è®¾ä¸ºç©ºå­—ç¬¦ä¸²
    if comparison_id is None:
        comparison_id = ''
    else:
        comparison_id = str(comparison_id)
    
    if comparison_id and comparison_id.strip():
        # æ”¯æŒå¤šä¸ªæœ¯è¯­åº“IDï¼Œé€—å·åˆ†éš”
        comparison_ids = [int(id.strip()) for id in comparison_id.split(',') if id.strip().isdigit()]
        if comparison_ids:
            all_terms = {}  # ç”¨äºå»é‡çš„å­—å…¸
            
            for comp_id in comparison_ids:
                try:
                    # ä» comparison_sub è¡¨è·å–æœ¯è¯­æ•°æ® - ä½¿ç”¨æ­£ç¡®çš„æŸ¥è¯¢æ–¹æ³•
                    terms = db.get_all("select original, comparison_text from comparison_sub where comparison_sub_id=%s", comp_id)
                    
                    # æ£€æŸ¥termsæ˜¯å¦ä¸ºæœ‰æ•ˆç»“æœ
                    if terms and isinstance(terms, list) and len(terms) > 0:
                        # logging.info(f"æœ¯è¯­åº“ {comp_id} æ‰¾åˆ° {len(terms)} æ¡æœ¯è¯­")
                        
                        for term in terms:
                            if term and isinstance(term, dict) and term.get('original') and term.get('comparison_text'):
                                # å»é‡ï¼šå¦‚æœåŸæ–‡å·²å­˜åœ¨ï¼Œè·³è¿‡ï¼ˆä»¥ç¬¬ä¸€ä¸ªä¸ºå‡†ï¼‰
                                if term['original'] not in all_terms:
                                    all_terms[term['original']] = term['comparison_text']
                                    # logging.info(f"æ·»åŠ æœ¯è¯­: {term['original']} -> {term['comparison_text']}")
                    else:
                        logging.warning(f"æœ¯è¯­åº“ {comp_id} æœªæ‰¾åˆ°æœ¯è¯­æ•°æ®æˆ–æŸ¥è¯¢ç»“æœä¸ºç©º")
                        
                except Exception as e:
                    logging.error(f"æŸ¥è¯¢æœ¯è¯­åº“ {comp_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                    continue
            
            # è¿”å›åŸå§‹æœ¯è¯­å­—å…¸ï¼Œä¾›åç»­ç­›é€‰ä½¿ç”¨
            if all_terms:
                logging.info(f"ä»»åŠ¡ä½¿ç”¨æœ¯è¯­è¡¨ID: {comparison_id}")
                # logging.info(f"æ€»å…±åˆå¹¶äº† {len(all_terms)} æ¡æœ¯è¯­")
                
                # å¦‚æœæœ¯è¯­åº“è¾ƒå¤§ï¼ˆ>1000æ¡ï¼‰ï¼Œé¢„å»ºç«‹å€’æ’ç´¢å¼•å’Œç²¾ç¡®åŒ¹é…ç´¢å¼•ä»¥æå‡æ€§èƒ½
                if len(all_terms) > 1000:
                    try:
                        from .term_filter import build_inverted_index, build_exact_match_index
                        build_inverted_index(all_terms, comparison_id)
                        build_exact_match_index(all_terms, comparison_id)
                        logging.info(f"å·²é¢„å»ºç«‹å€’æ’ç´¢å¼•å’Œç²¾ç¡®åŒ¹é…ç´¢å¼•ï¼Œæœ¯è¯­åº“å¤§å°: {len(all_terms)}")
                    except Exception as e:
                        logging.warning(f"é¢„å»ºç«‹ç´¢å¼•å¤±è´¥: {e}")
                
                return all_terms
            else:
                logging.warning(f"ä»»åŠ¡æœ¯è¯­è¡¨ID {comparison_id} æœªæ‰¾åˆ°å†…å®¹")
                return None
        else:
            logging.warning(f"ä»»åŠ¡æœ¯è¯­è¡¨IDæ ¼å¼æ— æ•ˆ: {comparison_id}")
            return None
    else:
        logging.info("ä»»åŠ¡æœªä½¿ç”¨æœ¯è¯­åº“")
        return None

def get_filtered_terms_for_text(text, comparison_id, max_terms=10):
    """
    æ ¹æ®æ–‡æœ¬å†…å®¹è·å–ç­›é€‰åçš„æœ¯è¯­åº“
    
    Args:
        text: è¦ç¿»è¯‘çš„æ–‡æœ¬
        comparison_id: æœ¯è¯­åº“ID
        max_terms: æœ€å¤§æœ¯è¯­æ•°é‡ï¼ˆä¼šæ ¹æ®æœ¯è¯­åº“å¤§å°è‡ªåŠ¨è°ƒæ•´ï¼‰
        
    Returns:
        str: ç­›é€‰åçš„æœ¯è¯­åº“å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸åŸæœ‰é€»è¾‘å…¼å®¹
    """
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # è·å–åŸå§‹æœ¯è¯­åº“
    all_terms = get_comparison(comparison_id)
    
    if not all_terms:
        return None
    
    # ç»Ÿä¸€é™åˆ¶ï¼šæœ€å¤š10ä¸ªæœ¯è¯­ï¼ˆé¿å…APIè¶…æ—¶ï¼‰
    max_terms = min(10, max_terms)
    
    # å¯¼å…¥æœ¯è¯­ç­›é€‰æ¨¡å—
    from .term_filter import optimize_terms_for_api
    
    # ç­›é€‰ç›¸å…³æœ¯è¯­ï¼ˆä¼ å…¥comparison_idä»¥ä½¿ç”¨ç¼“å­˜ï¼‰
    filtered_terms = optimize_terms_for_api(text, all_terms, max_terms, comparison_id=str(comparison_id) if comparison_id else None)
    
    if not filtered_terms:
        logging.info("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æœ¯è¯­")
        return None
    
    # è½¬æ¢ä¸ºåŸæœ‰æ ¼å¼ï¼ˆå­—ç¬¦ä¸²ï¼‰
    combined_terms = []
    for term in filtered_terms:
        combined_terms.append(f"{term['source']}: {term['target']}")
    
    result = '\n'.join(combined_terms)
    
    # è®¡ç®—æ€»ç”¨æ—¶
    end_time = time.time()
    duration = end_time - start_time
    logging.info(f"ğŸ“š æœ¯è¯­åº“ç­›é€‰æ€»ç”¨æ—¶: {duration:.3f}ç§’, åŸå§‹æœ¯è¯­æ•°: {len(all_terms)}, ç­›é€‰å: {len(filtered_terms)}")
    
    return result

if __name__ == '__main__':
    main()


