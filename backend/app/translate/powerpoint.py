import threading
import pptx
from . import to_translate
from . import common
import os
import sys
import time
import logging
from datetime import datetime
import re # Added for regex operations

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# ç®€å•çš„è¯­æ³•æ£€æŸ¥
try:
    # æµ‹è¯•åŸºæœ¬è¯­æ³•
    test_var = "test"
    test_list = [1, 2, 3]
    test_dict = {"key": "value"}
    logger.info("PPTç¿»è¯‘æ¨¡å—è¯­æ³•æ£€æŸ¥é€šè¿‡")
except Exception as e:
    logger.error(f"PPTç¿»è¯‘æ¨¡å—è¯­æ³•æ£€æŸ¥å¤±è´¥: {e}")
    raise

# å­—ä½“ç¼©æ”¾åŠŸèƒ½å¼€å…³
ENABLE_FONT_SCALING = True  # è®¾ç½®ä¸ºFalseå…³é—­å­—ä½“ç¼©æ”¾ï¼Œè®¾ç½®ä¸ºTrueå¼€å¯å­—ä½“ç¼©æ”¾

# å­—ä½“ç¼©æ”¾åŠŸèƒ½è¯´æ˜ï¼š
# å½“ENABLE_FONT_SCALING = Trueæ—¶ï¼š
#   - ç³»ç»Ÿä¼šæ ¹æ®ç¿»è¯‘åæ–‡æœ¬çš„é•¿åº¦è‡ªåŠ¨è°ƒæ•´å­—ä½“å¤§å°
#   - é•¿æ–‡æœ¬ä¼šé€‚å½“ç¼©å°å­—ä½“ï¼ŒçŸ­æ–‡æœ¬ä¼šé€‚å½“æ”¾å¤§å­—ä½“
#   - ç¡®ä¿æ–‡æœ¬åœ¨PPTä¸­æ˜¾ç¤ºå®Œæ•´ä¸”ç¾è§‚
#
# å½“ENABLE_FONT_SCALING = Falseæ—¶ï¼š
#   - å­—ä½“å¤§å°ä¿æŒä¸å˜ï¼Œä½¿ç”¨åŸå§‹è®¾ç½®
#   - ç¿»è¯‘åçš„æ–‡æœ¬å¯èƒ½è¶…å‡ºæ–‡æœ¬æ¡†è¾¹ç•Œ
#   - éœ€è¦æ‰‹åŠ¨è°ƒæ•´æ–‡æœ¬æ¡†å¤§å°æˆ–å­—ä½“å¤§å°
#
# ä½¿ç”¨æ–¹æ³•ï¼š
# 1. å…³é—­å­—ä½“ç¼©æ”¾ï¼šENABLE_FONT_SCALING = False
# 2. å¼€å¯å­—ä½“ç¼©æ”¾ï¼šENABLE_FONT_SCALING = True
# 3. ä¿®æ”¹åéœ€è¦é‡æ–°è¿è¡Œç¿»è¯‘ä»»åŠ¡æ‰èƒ½ç”Ÿæ•ˆ

def start(trans):
    """PPTç¿»è¯‘å…¥å£å‡½æ•°ï¼Œæ”¯æŒOkapiå’Œä¼ ç»Ÿæ–¹æ³•"""
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨Okapiæ–¹æ³•ï¼ˆé»˜è®¤ä½¿ç”¨Okapiï¼Œä¸Wordç¿»è¯‘ä¿æŒä¸€è‡´ï¼‰
    use_okapi = trans.get('use_okapi', True)
    
    if use_okapi:
        logger.info("ä½¿ç”¨ Okapi Framework è¿›è¡Œ PPT ç¿»è¯‘")
        return start_with_okapi(trans)
    else:
        logger.info("ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•è¿›è¡Œ PPT ç¿»è¯‘")
        return start_traditional(trans)


def start_with_okapi(trans):
    """ä½¿ç”¨ Okapi Framework è¿›è¡Œç¿»è¯‘"""
    try:
        # å¯¼å…¥ Okapi é›†æˆæ¨¡å—
        from .okapi_integration import OkapiPptxTranslator, verify_okapi_installation
        
        # éªŒè¯ Okapi å®‰è£…
        if not verify_okapi_installation():
            logger.error("âŒ Okapi å®‰è£…éªŒè¯å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•")
            return start_traditional(trans)
        
        # å¦‚æœç”¨æˆ·é€‰æ‹©äº†qwen-mt-plusï¼Œè®¾ç½®serverä¸ºqwen
        if trans.get('model') == 'qwen-mt-plus':
            trans['server'] = 'qwen'
            logger.info("âœ… è®¾ç½®ç¿»è¯‘æœåŠ¡ä¸º Qwen")
        
        # é¢„åŠ è½½æœ¯è¯­åº“
        comparison_id = trans.get('comparison_id')
        if comparison_id:
            logger.info(f"ğŸ“š å¼€å§‹é¢„åŠ è½½æœ¯è¯­åº“: {comparison_id}")
            from .main import get_comparison
            preloaded_terms = get_comparison(comparison_id)
            if preloaded_terms:
                logger.info(f"ğŸ“š æœ¯è¯­åº“é¢„åŠ è½½æˆåŠŸ: {len(preloaded_terms)} ä¸ªæœ¯è¯­")
                trans['preloaded_terms'] = preloaded_terms
            else:
                logger.warning(f"ğŸ“š æœ¯è¯­åº“é¢„åŠ è½½å¤±è´¥: {comparison_id}")
        
        # åˆ›å»º Okapi ç¿»è¯‘å™¨
        translator = OkapiPptxTranslator()
        logger.info("âœ… Okapi PPTX ç¿»è¯‘å™¨åˆ›å»ºæˆåŠŸ")
        
        # è®¾ç½®ç¿»è¯‘æœåŠ¡
        class OkapiTranslationService:
            def __init__(self, trans):
                self.trans = trans
            
            def batch_translate(self, texts, source_lang, target_lang):
                """æ‰¹é‡ç¿»è¯‘æ–‡æœ¬ - ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼Œæ”¯æŒæœ¯è¯­åº“ç­›é€‰"""
                from concurrent.futures import ThreadPoolExecutor, as_completed
                import threading
                
                translated_texts = [None] * len(texts)  # é¢„åˆ†é…ç»“æœæ•°ç»„
                max_workers = min(30, len(texts))  # æœ€å¤š30ä¸ªçº¿ç¨‹
                
                logger.info(f"å¼€å§‹å¹¶è¡Œç¿»è¯‘ {len(texts)} ä¸ªæ–‡æœ¬ï¼Œä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹")
                
                # è¿›åº¦æ›´æ–°ç›¸å…³å˜é‡
                total_count = len(texts)
                progress_lock = threading.Lock()
                
                def update_progress():
                    """æ›´æ–°ç¿»è¯‘è¿›åº¦"""
                    with progress_lock:
                        actual_completed = sum(1 for i, text in enumerate(texts) if translated_texts[i] is not None)
                        
                        if actual_completed >= total_count:
                            actual_completed = total_count
                            progress_percentage = 100.0
                        else:
                            progress_percentage = min((actual_completed / total_count) * 100, 100.0)
                        
                        logger.info(f"ç¿»è¯‘è¿›åº¦: {actual_completed}/{total_count} ({progress_percentage:.1f}%)")
                        
                        # æ›´æ–°æ•°æ®åº“è¿›åº¦
                        try:
                            from .to_translate import db
                            db.execute("update translate set process=%s where id=%s", 
                                     str(format(progress_percentage, '.1f')), 
                                     self.trans['id'])
                        except Exception as e:
                            logger.error(f"æ›´æ–°è¿›åº¦å¤±è´¥: {str(e)}")
                
                def translate_single_text(index, text):
                    """ç¿»è¯‘å•ä¸ªæ–‡æœ¬ - ä½¿ç”¨ translate_text å‡½æ•°ï¼ˆOkapiåªç”¨äºè§£æï¼Œç¿»è¯‘ç”¨qwen-mt-plusï¼‰"""
                    try:
                        # ä½¿ç”¨ translate_text å‡½æ•°è¿›è¡Œç¿»è¯‘
                        result = to_translate.translate_text(
                            self.trans,
                            text,
                            source_lang="auto",
                            target_lang=self.trans.get('lang', 'English')
                        )
                        return result
                    except Exception as e:
                        logger.error(f"ç¿»è¯‘æ–‡æœ¬ {index} å¤±è´¥: {e}")
                        return text  # å¤±è´¥æ—¶è¿”å›åŸæ–‡
                
                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œç¿»è¯‘
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_index = {
                        executor.submit(translate_single_text, i, text): i 
                        for i, text in enumerate(texts)
                    }
                    
                    # æ”¶é›†ç»“æœ
                    completed = 0
                    for future in as_completed(future_to_index):
                        index = future_to_index[future]
                        try:
                            translated_texts[index] = future.result()
                            completed += 1
                            
                            # æ¯å®Œæˆ10%æ›´æ–°ä¸€æ¬¡è¿›åº¦
                            if completed % max(1, total_count // 10) == 0:
                                update_progress()
                        except Exception as e:
                            logger.error(f"è·å–ç¿»è¯‘ç»“æœ {index} å¤±è´¥: {e}")
                            translated_texts[index] = texts[index]  # å¤±è´¥æ—¶ä½¿ç”¨åŸæ–‡
                
                # æœ€ç»ˆè¿›åº¦æ›´æ–°
                update_progress()
                
                return translated_texts
        
        # è®¾ç½®ç¿»è¯‘æœåŠ¡
        translation_service = OkapiTranslationService(trans)
        translator.set_translation_service(translation_service)
        
        # å‡†å¤‡æ–‡ä»¶è·¯å¾„
        input_file = trans['file_path']
        output_file = trans.get('target_file') or input_file.replace('.pptx', '_translated.pptx')
        
        # ç¡®å®šæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€
        source_lang = "zh"  # PPTX é»˜è®¤æºè¯­è¨€ä¸ºä¸­æ–‡
        target_lang = trans.get('lang', 'English')
        
        # è¯­è¨€ä»£ç æ˜ å°„ï¼ˆå¦‚æœéœ€è¦ï¼‰
        lang_code_map = {
            'English': 'en',
            'Chinese': 'zh',
            'Japanese': 'ja',
            'Korean': 'ko',
            # å¯ä»¥æ·»åŠ æ›´å¤šæ˜ å°„
        }
        target_lang_code = lang_code_map.get(target_lang, target_lang.lower()[:2])
        
        # æ‰§è¡Œç¿»è¯‘
        logger.info(f"å¼€å§‹ç¿»è¯‘ PPTX: {input_file} -> {output_file}")
        logger.info(f"æºè¯­è¨€: {source_lang}, ç›®æ ‡è¯­è¨€: {target_lang} ({target_lang_code})")
        
        success = translator.translate_document(
            input_file, output_file, source_lang, target_lang_code
        )
        
        if success:
            # æ›´æ–°æ•°æ®åº“çŠ¶æ€
            try:
                from .to_translate import db
                db.execute("update translate set status='done', process='100.0', result_path=%s where id=%s",
                         output_file, trans['id'])
                logger.info(f"âœ… PPTX ç¿»è¯‘å®Œæˆ: {output_file}")
            except Exception as e:
                logger.error(f"æ›´æ–°æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")
            
            # ç¿»è¯‘æˆåŠŸï¼Œåˆ é™¤åŸå§‹æ–‡ä»¶ä»¥èŠ‚çœç©ºé—´
            original_file = trans['file_path']
            if os.path.exists(original_file) and original_file != output_file:
                try:
                    os.remove(original_file)
                    logger.info(f"âœ… ç¿»è¯‘æˆåŠŸï¼Œå·²åˆ é™¤åŸå§‹æ–‡ä»¶: {os.path.basename(original_file)}")
                except Exception as e:
                    logger.warning(f"âš ï¸ åˆ é™¤åŸå§‹æ–‡ä»¶å¤±è´¥: {str(e)}")
            
            return True
        else:
            # ç¿»è¯‘å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
            logger.error("âŒ Okapi ç¿»è¯‘å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•")
            return start_traditional(trans)
            
    except Exception as e:
        logger.error(f"Okapi ç¿»è¯‘è¿‡ç¨‹å‡ºé”™: {e}", exc_info=True)
        # å‡ºé”™æ—¶å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
        return start_traditional(trans)


def start_traditional(trans):
    """ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•è¿›è¡Œç¿»è¯‘ï¼ˆåŸæœ‰çš„ start å‡½æ•°é€»è¾‘ï¼‰"""
    # å…è®¸çš„æœ€å¤§çº¿ç¨‹
    threads=trans['threads']
    if threads is None or int(threads)<0:
        max_threads=10
    else:
        max_threads=int(threads)
    # å½“å‰æ‰§è¡Œçš„ç´¢å¼•ä½ç½®
    run_index=0
    start_time = datetime.now()
    wb = pptx.Presentation(trans['file_path']) 
    logger.info(f"å¤„ç†æ–‡ä»¶: {trans['file_path']}")
    slides = wb.slides
    texts=[]
    
    # æ”¹è¿›çš„å»é‡ç­–ç•¥ï¼šä½¿ç”¨ä½ç½®+æ–‡æœ¬ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œå…è®¸ç›¸åŒæ–‡æœ¬åœ¨ä¸åŒä½ç½®å­˜åœ¨
    # ä½†é¿å…åœ¨åŒä¸€ä½ç½®é‡å¤æå–ç›¸åŒæ–‡æœ¬
    extracted_texts_by_location = {}  # {(slide_index, shape_index, text_type, text): True}
    
    # æå–æ–‡æœ¬æ—¶ä¿å­˜æ ·å¼ä¿¡æ¯ï¼Œå¹¶å»ºç«‹æ–‡æœ¬ä¸å½¢çŠ¶çš„å¯¹åº”å…³ç³»
    slide_count = 0
    for slide in slides:
        slide_count += 1
        slide_text_count = 0
        logger.info(f"æ­£åœ¨å¤„ç†ç¬¬ {slide_count} é¡µå¹»ç¯ç‰‡...")
        
        for shape_index, shape in enumerate(slide.shapes):
            # å¤„ç†è¡¨æ ¼
            if shape.has_table:
                table = shape.table
                logger.info(f"å‘ç°è¡¨æ ¼: {table}")
                rows = len(table.rows)
                cols = len(table.columns)
                for r in range(rows):
                    for c in range(cols):
                        cell_text = table.cell(r, c).text
                        if cell_text!=None and len(cell_text)>0 and not common.is_all_punc(cell_text):
                            # ä½¿ç”¨ä½ç½®+æ–‡æœ¬ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œå…è®¸ç›¸åŒæ–‡æœ¬åœ¨ä¸åŒä½ç½®å­˜åœ¨
                            cell_text_clean = cell_text.strip()
                            location_key = (slide_count, shape_index, "table_cell", r, c, cell_text_clean)
                            if location_key not in extracted_texts_by_location:
                                # ä¿å­˜è¡¨æ ¼å•å…ƒæ ¼çš„æ ·å¼ä¿¡æ¯ï¼Œå¹¶å»ºç«‹å¯¹åº”å…³ç³»
                                cell = table.cell(r, c)
                                style_info = extract_cell_style(cell)
                                texts.append({
                                    "text": cell_text,
                                    "row": r,
                                    "column": c, 
                                    "complete": False,
                                    "type": "table_cell",
                                    "style_info": style_info,
                                    "slide_index": slide_count,
                                    "shape_index": shape_index,
                                    "shape": shape,
                                    "cell": cell,
                                    "original_text": cell_text  # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºåŒ¹é…
                                })
                                slide_text_count += 1
                                extracted_texts_by_location[location_key] = True
                                logger.debug(f"æ·»åŠ è¡¨æ ¼å•å…ƒæ ¼æ–‡æœ¬: {cell_text_clean[:50]}... (ä½ç½®: å¹»ç¯ç‰‡{slide_count}, å½¢çŠ¶{shape_index}, è¡Œ{r}, åˆ—{c})")
                            else:
                                logger.debug(f"è·³è¿‡é‡å¤çš„è¡¨æ ¼å•å…ƒæ ¼æ–‡æœ¬: {cell_text_clean[:50]}... (åŒä¸€ä½ç½®)")
            
            # å¤„ç†æ‰€æœ‰æœ‰æ–‡æœ¬æ¡†æ¶çš„å½¢çŠ¶ï¼ˆåŒ…æ‹¬æ–‡æœ¬æ¡†ã€æ ‡é¢˜ã€å ä½ç¬¦ç­‰ï¼‰
            elif shape.has_text_frame:
                text_frame = shape.text_frame
                logger.debug(f"å‘ç°æ–‡æœ¬æ¡†æ¶ï¼Œæ®µè½æ•°: {len(text_frame.paragraphs)}")
                
                # è®°å½•å·²æå–çš„æ–‡æœ¬ï¼Œé¿å…é‡å¤æå–
                extracted_texts_in_frame = set()
                paragraph_texts = []  # æ”¶é›†æ‰€æœ‰æ®µè½æ–‡æœ¬
                
                # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šæå–æ®µè½æ–‡æœ¬
                for paragraph_index, paragraph in enumerate(text_frame.paragraphs):
                    text = paragraph.text
                    if text!=None and len(text)>0 and not common.is_all_punc(text):
                        text_clean = text.strip()
                        # ä½¿ç”¨ä½ç½®+æ–‡æœ¬ä½œä¸ºå”¯ä¸€æ ‡è¯†
                        location_key = (slide_count, shape_index, "paragraph", paragraph_index, text_clean)
                        if location_key not in extracted_texts_by_location:
                            # ä¿å­˜æ®µè½çš„æ ·å¼ä¿¡æ¯ï¼Œå¹¶å»ºç«‹å¯¹åº”å…³ç³»
                            style_info = extract_paragraph_style(paragraph)
                            texts.append({
                                "text": text, 
                                "complete": False,
                                "type": "paragraph",
                                "style_info": style_info,
                                "paragraph": paragraph,
                                "slide_index": slide_count,
                                "shape_index": shape_index,
                                "shape": shape,
                                "paragraph_index": paragraph_index,
                                "original_text": text  # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºåŒ¹é…
                            })
                            slide_text_count += 1
                            # è®°å½•å·²æå–çš„æ–‡æœ¬
                            extracted_texts_in_frame.add(text_clean)
                            extracted_texts_by_location[location_key] = True
                            paragraph_texts.append(text_clean)
                            logger.debug(f"æ·»åŠ æ®µè½æ–‡æœ¬: {text_clean[:30]}... (ä½ç½®: å¹»ç¯ç‰‡{slide_count}, å½¢çŠ¶{shape_index}, æ®µè½{paragraph_index})")
                        else:
                            logger.debug(f"è·³è¿‡é‡å¤çš„æ®µè½æ–‡æœ¬: {text_clean[:30]}... (åŒä¸€ä½ç½®)")
                
                # ç¬¬äºŒä¼˜å…ˆçº§ï¼šæ£€æŸ¥æ–‡æœ¬æ¡†æ¶æ˜¯å¦æœ‰é—æ¼çš„æ–‡æœ¬
                # æ³¨æ„ï¼šå¦‚æœå·²ç»æå–äº†æ®µè½æ–‡æœ¬ï¼Œé€šå¸¸ä¸éœ€è¦å†æå–æ¡†æ¶æ–‡æœ¬ï¼Œé™¤éæ¡†æ¶æ–‡æœ¬åŒ…å«æ®µè½æ–‡æœ¬æ²¡æœ‰çš„å†…å®¹
                # è¿™é‡Œæš‚æ—¶è·³è¿‡æ¡†æ¶æ–‡æœ¬çš„æå–ï¼Œé¿å…é‡å¤
                # å¦‚æœç¡®å®éœ€è¦ï¼Œå¯ä»¥é€šè¿‡æ¯”è¾ƒæ¡†æ¶æ–‡æœ¬å’Œæ®µè½æ–‡æœ¬ç»„åˆæ¥åˆ¤æ–­
                pass
            
            # å¤„ç†å…¶ä»–å¯èƒ½æœ‰æ–‡æœ¬çš„å½¢çŠ¶ï¼ˆå¦‚å½¢çŠ¶å†…çš„æ–‡æœ¬ï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œåªå¤„ç†æ²¡æœ‰æ–‡æœ¬æ¡†æ¶çš„å½¢çŠ¶ï¼Œé¿å…é‡å¤æå–
            elif hasattr(shape, 'text') and shape.text and not shape.has_text_frame:
                text = shape.text
                if text!=None and len(text)>0 and not common.is_all_punc(text):
                    text_clean = text.strip()
                    # ä½¿ç”¨ä½ç½®+æ–‡æœ¬ä½œä¸ºå”¯ä¸€æ ‡è¯†
                    location_key = (slide_count, shape_index, "shape_text", text_clean)
                    if location_key not in extracted_texts_by_location:
                        texts.append({
                            "text": text, 
                            "complete": False,
                            "type": "shape_text",
                            "shape": shape,
                            "slide_index": slide_count,
                            "shape_index": shape_index,
                            "original_text": text  # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºåŒ¹é…
                        })
                        slide_text_count += 1
                        extracted_texts_by_location[location_key] = True
                        logger.debug(f"æ·»åŠ å½¢çŠ¶æ–‡æœ¬: {text_clean[:50]}... (ä½ç½®: å¹»ç¯ç‰‡{slide_count}, å½¢çŠ¶{shape_index})")
                    else:
                        logger.debug(f"è·³è¿‡é‡å¤çš„å½¢çŠ¶æ–‡æœ¬: {text_clean[:50]}... (åŒä¸€ä½ç½®)")
            
            # å¤„ç†å½¢çŠ¶åç§°ï¼ˆé€šå¸¸ä¸ä¼šä¸å†…å®¹æ–‡æœ¬é‡å¤ï¼Œä½†ä¹Ÿè¦æ£€æŸ¥ï¼‰
            elif hasattr(shape, 'name') and shape.name:
                shape_name = shape.name
                if shape_name and len(shape_name.strip()) > 0:
                    shape_name_clean = shape_name.strip()
                    # ä½¿ç”¨ä½ç½®+æ–‡æœ¬ä½œä¸ºå”¯ä¸€æ ‡è¯†
                    location_key = (slide_count, shape_index, "shape_name", shape_name_clean)
                    if location_key not in extracted_texts_by_location:
                        texts.append({
                            "text": shape_name,
                            "complete": False,
                            "type": "shape_name",
                            "shape": shape,
                            "slide_index": slide_count,
                            "shape_index": shape_index,
                            "original_text": shape_name  # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºåŒ¹é…
                        })
                        slide_text_count += 1
                        extracted_texts_by_location[location_key] = True
                        logger.debug(f"æ·»åŠ å½¢çŠ¶åç§°æ–‡æœ¬: {shape_name_clean[:50]}... (ä½ç½®: å¹»ç¯ç‰‡{slide_count}, å½¢çŠ¶{shape_index})")
                    else:
                        logger.debug(f"è·³è¿‡é‡å¤çš„å½¢çŠ¶åç§°æ–‡æœ¬: {shape_name_clean[:50]}... (åŒä¸€ä½ç½®)")
        
        logger.info(f"ç¬¬ {slide_count} é¡µå¹»ç¯ç‰‡æå–äº† {slide_text_count} ä¸ªæ–‡æœ¬å…ƒç´ ")
    
    # ä¸å†è¿›è¡Œå…¨å±€å»é‡ï¼Œå› ä¸ºç›¸åŒæ–‡æœ¬åœ¨ä¸åŒä½ç½®éœ€è¦åˆ†åˆ«ç¿»è¯‘
    logger.info(f"æ€»å…±æå–äº† {len(texts)} ä¸ªæ–‡æœ¬å…ƒç´ ")
    
    # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰æå–çš„æ–‡æœ¬ç±»å‹å’Œè¯¦ç»†ä¿¡æ¯
    text_types = {}
    duplicate_check = {}  # æ£€æŸ¥é‡å¤æ–‡æœ¬
    
    for i, item in enumerate(texts):
        text_type = item.get('type', 'unknown')
        text_types[text_type] = text_types.get(text_type, 0) + 1
        
        # æ£€æŸ¥é‡å¤æ–‡æœ¬
        text_content = item.get('text', '').strip()
        if text_content in duplicate_check:
            duplicate_check[text_content].append({
                'index': i,
                'type': text_type,
                'slide': item.get('slide_index', 'N/A'),
                'shape': item.get('shape_index', 'N/A')
            })
        else:
            duplicate_check[text_content] = [{
                'index': i,
                'type': text_type,
                'slide': item.get('slide_index', 'N/A'),
                'shape': item.get('shape_index', 'N/A')
            }]
        
        # è®°å½•æ¯ä¸ªæ–‡æœ¬é¡¹çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå‰10ä¸ªï¼‰
        if i < 10:
            logger.info(f"æ–‡æœ¬é¡¹ {i+1}: ç±»å‹={text_type}, å¹»ç¯ç‰‡={item.get('slide_index', 'N/A')}, å½¢çŠ¶ç´¢å¼•={item.get('shape_index', 'N/A')}, å†…å®¹='{item.get('text', '')[:50]}...'")
    
    # æŠ¥å‘Šé‡å¤æ–‡æœ¬æƒ…å†µ
    duplicate_count = 0
    for text_content, occurrences in duplicate_check.items():
        if len(occurrences) > 1:
            duplicate_count += 1
            logger.warning(f"å‘ç°é‡å¤æ–‡æœ¬: '{text_content[:50]}...' å‡ºç° {len(occurrences)} æ¬¡:")
            for occ in occurrences:
                logger.warning(f"  - ç´¢å¼•{occ['index']}, ç±»å‹={occ['type']}, å¹»ç¯ç‰‡={occ['slide']}, å½¢çŠ¶={occ['shape']}")
    
    if duplicate_count > 0:
        logger.warning(f"æ€»å…±å‘ç° {duplicate_count} ä¸ªé‡å¤æ–‡æœ¬ï¼Œè¿™å¯èƒ½å¯¼è‡´ç¿»è¯‘é‡å¤")
    else:
        logger.info("æœªå‘ç°é‡å¤æ–‡æœ¬ï¼Œæå–æ­£å¸¸")
    
    logger.info(f"æå–çš„æ–‡æœ¬ç±»å‹åˆ†å¸ƒ: {text_types}")
    logger.info(f"æ€»å…±æå–äº† {len(texts)} ä¸ªæ–‡æœ¬å…ƒç´ ")
    max_run=max_threads if len(texts)>max_threads else len(texts)
    before_active_count=threading.activeCount()
    event=threading.Event()
    
    # è¿›åº¦æ›´æ–°ç›¸å…³å˜é‡
    completed_count = 0
    total_count = len(texts)
    progress_lock = threading.Lock()
    
    def update_progress():
        """æ›´æ–°ç¿»è¯‘è¿›åº¦"""
        nonlocal completed_count
        with progress_lock:
            completed_count += 1
            progress_percentage = min((completed_count / total_count) * 100, 100.0)
            
            # æ›´æ–°æ•°æ®åº“è¿›åº¦
            try:
                from .to_translate import db
                db.execute("update translate set process=%s where id=%s", 
                         str(format(progress_percentage, '.1f')), 
                         trans['id'])
                
                # å¦‚æœè¿›åº¦è¾¾åˆ°100%ï¼Œç«‹å³æ›´æ–°çŠ¶æ€ä¸ºå·²å®Œæˆ
                if progress_percentage >= 100.0:
                    import pytz
                    end_time = datetime.now(pytz.timezone('Asia/Shanghai'))
                    db.execute(
                        "update translate set status='done',end_at=%s,process=100 where id=%s",
                        end_time, trans['id']
                    )
                    print("âœ… ç¿»è¯‘å®Œæˆï¼ŒçŠ¶æ€å·²æ›´æ–°ä¸ºå·²å®Œæˆ")
                    
            except Exception as e:
                print(f"æ›´æ–°è¿›åº¦å¤±è´¥: {str(e)}")
    
    while run_index<=len(texts)-1:
        if threading.activeCount()<max_run+before_active_count:
            if not event.is_set():
                thread = threading.Thread(target=to_translate.get,args=(trans,event,texts,run_index))
                thread.start()
                run_index+=1
            else:
                return False
    
    # ç­‰å¾…ç¿»è¯‘å®Œæˆï¼Œå¹¶ç›‘æ§è¿›åº¦
    last_completed_count = 0
    while True:
        complete=True
        current_completed = 0
        for text in texts:
            if not text['complete']:
                complete=False
            else:
                current_completed += 1
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æ–‡æœ¬å®Œæˆ
        if current_completed > last_completed_count:
            completed_count = current_completed
            progress_percentage = min((completed_count / total_count) * 100, 100.0)
            
            # æ›´æ–°æ•°æ®åº“è¿›åº¦
            try:
                from .to_translate import db
                db.execute("update translate set process=%s where id=%s", 
                         str(format(progress_percentage, '.1f')), 
                         trans['id'])
                
            except Exception as e:
                print(f"æ›´æ–°è¿›åº¦å¤±è´¥: {str(e)}")
            
            last_completed_count = current_completed
        
        if complete:
            break
        else:
            time.sleep(1)

    text_count=0
    slide_count = 0
    for slide in slides:
        slide_count += 1
        slide_processed_count = 0
        # logger.info(f"æ­£åœ¨åº”ç”¨ç¿»è¯‘ç»“æœåˆ°ç¬¬ {slide_count} é¡µå¹»ç¯ç‰‡...")
        
        for shape_index, shape in enumerate(slide.shapes):
            # æ·»åŠ è¯¦ç»†çš„å½¢çŠ¶ä¿¡æ¯æ—¥å¿—
            # logger.info(f"=== å¤„ç†ç¬¬ {slide_count} é¡µå½¢çŠ¶ ===")
            # logger.info(f"å½¢çŠ¶ç±»å‹: {type(shape).__name__}")
            # logger.info(f"å½¢çŠ¶åç§°: {getattr(shape, 'name', 'N/A')}")
            # logger.info(f"æ˜¯å¦æœ‰è¡¨æ ¼: {shape.has_table}")
            # logger.info(f"æ˜¯å¦æœ‰æ–‡æœ¬æ¡†æ¶: {shape.has_text_frame}")
            # logger.info(f"æ˜¯å¦æœ‰æ–‡æœ¬å±æ€§: {hasattr(shape, 'text')}")
            # try:
            #     logger.info(f"æ˜¯å¦æœ‰å ä½ç¬¦æ ¼å¼: {hasattr(shape, 'placeholder_format')}")
            # except ValueError:
            #     logger.info(f"æ˜¯å¦æœ‰å ä½ç¬¦æ ¼å¼: False (éå ä½ç¬¦å½¢çŠ¶)")
            
            # å¤„ç†è¡¨æ ¼
            if shape.has_table:
                table = shape.table
                rows = len(table.rows)
                cols = len(table.columns)
                for r in range(rows):
                    row_data = []
                    for c in range(cols):
                        cell_text = table.cell(r, c).text
                        if cell_text!=None and len(cell_text)>0 and not common.is_all_punc(cell_text):
                            # æŸ¥æ‰¾å¯¹åº”çš„ç¿»è¯‘ç»“æœ
                            cell = table.cell(r, c)
                            translated_item = find_translated_text_for_shape(texts, slide_count, shape_index, "table_cell", cell=cell, row=r, column=c)
                            if translated_item:
                                # é»˜è®¤å¯ç”¨è‡ªé€‚åº”æ ·å¼
                                apply_translation_to_cell_with_adaptive_styles(cell, translated_item['text'], translated_item.get('style_info', {}))
                                text_count+=translated_item.get('count', 1)
                                slide_processed_count += 1
                                logger.info(f"è¡¨æ ¼å•å…ƒæ ¼ç¿»è¯‘åº”ç”¨æˆåŠŸ: åŸæ–‡='{cell_text[:30]}...' -> è¯‘æ–‡='{translated_item['text'][:30]}...'")
                            else:
                                logger.warning(f"æœªæ‰¾åˆ°è¡¨æ ¼å•å…ƒæ ¼çš„ç¿»è¯‘ç»“æœ: {cell_text[:30]}...")
                          
            # å¤„ç†æ‰€æœ‰æœ‰æ–‡æœ¬æ¡†æ¶çš„å½¢çŠ¶ï¼ˆåŒ…æ‹¬æ–‡æœ¬æ¡†ã€æ ‡é¢˜ã€å ä½ç¬¦ç­‰ï¼‰
            elif shape.has_text_frame:
                text_frame = shape.text_frame
                logger.info(f"å¤„ç†æ–‡æœ¬æ¡†æ¶å½¢çŠ¶ï¼Œæ®µè½æ•°: {len(text_frame.paragraphs)}")
                for paragraph_index, paragraph in enumerate(text_frame.paragraphs):
                    text=paragraph.text
                    if text!=None and len(text)>0 and not common.is_all_punc(text):
                        # æŸ¥æ‰¾å¯¹åº”çš„ç¿»è¯‘ç»“æœ
                        translated_item = find_translated_text_for_shape(texts, slide_count, shape_index, "paragraph", paragraph=paragraph, paragraph_index=paragraph_index)
                        if translated_item:
                            # é»˜è®¤å¯ç”¨è‡ªé€‚åº”æ ·å¼
                            logger.info(f"åº”ç”¨ç¿»è¯‘åˆ°æ®µè½: åŸæ–‡='{paragraph.text[:30]}...' -> è¯‘æ–‡='{translated_item['text'][:30]}...'")
                            apply_translation_to_paragraph_with_adaptive_styles(paragraph, translated_item['text'], translated_item.get('style_info', {}))
                            text_count+=translated_item.get('count', 1)
                            slide_processed_count += 1
                            logger.info(f"æ®µè½ç¿»è¯‘å®Œæˆï¼Œå½“å‰runsæ•°: {len(paragraph.runs)}")
                        else:
                            logger.warning(f"æœªæ‰¾åˆ°æ®µè½çš„ç¿»è¯‘ç»“æœ: {text[:30]}...")
                
                # æ–‡æœ¬æ¡†æ¶å†…å®¹é€šå¸¸å·²ç»é€šè¿‡æ®µè½å¤„ç†äº†ï¼Œè¿™é‡Œä¸å†å•ç‹¬å¤„ç†ï¼Œé¿å…é‡å¤
                pass
            
            # å¤„ç†å…¶ä»–å¯èƒ½æœ‰æ–‡æœ¬çš„å½¢çŠ¶ï¼ˆå¦‚å½¢çŠ¶å†…çš„æ–‡æœ¬ï¼‰
            # æ³¨æ„ï¼šåªå¤„ç†æ²¡æœ‰æ–‡æœ¬æ¡†æ¶çš„å½¢çŠ¶ï¼Œé¿å…é‡å¤
            elif hasattr(shape, 'text') and shape.text and not shape.has_text_frame:
                text = shape.text
                if text!=None and len(text)>0 and not common.is_all_punc(text):
                    # æŸ¥æ‰¾å¯¹åº”çš„ç¿»è¯‘ç»“æœ
                    translated_item = find_translated_text_for_shape(texts, slide_count, shape_index, "shape_text", shape=shape)
                    if translated_item:
                        # å¤„ç†å½¢çŠ¶æ–‡æœ¬
                        original_text = shape.text
                        shape.text = translated_item['text']
                        # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°å½¢çŠ¶æ–‡æœ¬
                        apply_adaptive_styles_to_shape(shape, original_text, translated_item['text'])
                        text_count+=translated_item.get('count', 1)
                        slide_processed_count += 1
                        logger.info(f"å½¢çŠ¶æ–‡æœ¬ç¿»è¯‘åº”ç”¨æˆåŠŸ: åŸæ–‡='{original_text[:30]}...' -> è¯‘æ–‡='{translated_item['text'][:30]}...'")
                    else:
                        logger.warning(f"æœªæ‰¾åˆ°å½¢çŠ¶æ–‡æœ¬çš„ç¿»è¯‘ç»“æœ: {text[:30]}...")
            
            # æ–‡æœ¬æ¡†æ¶å·²ç»åœ¨ä¸Šé¢å¤„ç†è¿‡äº†ï¼Œè¿™é‡Œä¸å†é‡å¤å¤„ç†
            
            # å¤„ç†å½¢çŠ¶åç§°æ–‡æœ¬
            elif hasattr(shape, 'name') and shape.name:
                shape_name = shape.name
                if shape_name and len(shape_name.strip()) > 0:
                    # æŸ¥æ‰¾å¯¹åº”çš„ç¿»è¯‘ç»“æœ
                    translated_item = find_translated_text_for_shape(texts, slide_count, shape_index, "shape_name", shape=shape)
                    if translated_item:
                        # å¤„ç†å½¢çŠ¶åç§°æ–‡æœ¬
                        original_name = shape.name
                        shape.name = translated_item['text']
                        # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°å½¢çŠ¶åç§°
                        apply_adaptive_styles_to_shape(shape, original_name, translated_item['text'])
                        text_count+=translated_item.get('count', 1)
                        slide_processed_count += 1
                        logger.info(f"å½¢çŠ¶åç§°ç¿»è¯‘åº”ç”¨æˆåŠŸ: åŸæ–‡='{original_name[:30]}...' -> è¯‘æ–‡='{translated_item['text'][:30]}...'")
                    else:
                        logger.warning(f"æœªæ‰¾åˆ°å½¢çŠ¶åç§°çš„ç¿»è¯‘ç»“æœ: {shape_name[:30]}...")
            
            # å¤„ç†å ä½ç¬¦æ–‡æœ¬
            try:
                if hasattr(shape, 'placeholder_format') and shape.placeholder_format:
                    # æŸ¥æ‰¾å¯¹åº”çš„ç¿»è¯‘ç»“æœ
                    translated_item = find_translated_text_for_shape(texts, slide_count, shape_index, "placeholder", shape=shape)
                    if translated_item:
                        # å¤„ç†å ä½ç¬¦æ–‡æœ¬
                        if hasattr(shape, 'text_frame') and shape.text_frame:
                            original_text = shape.text_frame.text
                            shape.text_frame.text = translated_item['text']
                            # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°æ‰€æœ‰æ®µè½
                            if shape.text_frame.paragraphs:
                                for paragraph in shape.text_frame.paragraphs:
                                    if paragraph.runs:
                                        for run in paragraph.runs:
                                            if ENABLE_FONT_SCALING:
                                                apply_adaptive_styles_ppt(run, original_text, translated_item['text'])
                            text_count += translated_item.get('count', 1)
                            slide_processed_count += 1
                            logger.info(f"å ä½ç¬¦æ–‡æœ¬ç¿»è¯‘åº”ç”¨æˆåŠŸ: åŸæ–‡='{original_text[:30]}...' -> è¯‘æ–‡='{translated_item['text'][:30]}...'")
                        else:
                            logger.warning(f"æœªæ‰¾åˆ°å ä½ç¬¦æ–‡æœ¬çš„ç¿»è¯‘ç»“æœ")
            except ValueError as e:
                # å¿½ç•¥"shape is not a placeholder"é”™è¯¯
                pass
            except Exception as e:
                logger.warning(f"åº”ç”¨å ä½ç¬¦ç¿»è¯‘æ—¶å‡ºé”™: {str(e)}")
        
        logger.info(f"ç¬¬ {slide_count} é¡µå¹»ç¯ç‰‡å¤„ç†äº† {slide_processed_count} ä¸ªæ–‡æœ¬å…ƒç´ ")
    
    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå¤„ç†çš„æ–‡æœ¬
    # if texts:
    #     logger.warning(f"è¿˜æœ‰ {len(texts)} ä¸ªæ–‡æœ¬å…ƒç´ æœªå¤„ç†:")
    #     for i, item in enumerate(texts[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
    #         logger.warning(f"  æœªå¤„ç†æ–‡æœ¬ {i+1}: {item.get('text', '')[:50]}... (ç±»å‹: {item.get('type', 'unknown')})")
    #     if len(texts) > 5:
    #         logger.warning(f"  ... è¿˜æœ‰ {len(texts) - 5} ä¸ªæœªå¤„ç†")
    
    # æ·»åŠ è¯¦ç»†çš„å¤„ç†ç»Ÿè®¡
    logger.info(f"=== PowerPointå¤„ç†ç»Ÿè®¡ ===")
    logger.info(f"æ€»æ–‡æœ¬å…ƒç´ æ•°: {len(texts) + text_count}")
    logger.info(f"å·²å¤„ç†æ–‡æœ¬æ•°: {text_count}")
    logger.info(f"æœªå¤„ç†æ–‡æœ¬æ•°: {len(texts)}")
    logger.info(f"å¤„ç†æˆåŠŸç‡: {text_count / (len(texts) + text_count) * 100:.1f}%" if (len(texts) + text_count) > 0 else "0%")

    logger.info(f"æ€»å…±å¤„ç†äº† {text_count} ä¸ªæ–‡æœ¬å…ƒç´ ")
    wb.save(trans['target_file'])
    end_time = datetime.now()
    spend_time=common.display_spend(start_time, end_time)
    to_translate.complete(trans,text_count,spend_time)
    
    # ç¿»è¯‘æˆåŠŸï¼Œåˆ é™¤åŸå§‹æ–‡ä»¶ä»¥èŠ‚çœç©ºé—´
    original_file = trans['file_path']
    if os.path.exists(original_file) and original_file != trans.get('target_file'):
        try:
            os.remove(original_file)
            logger.info(f"âœ… ç¿»è¯‘æˆåŠŸï¼Œå·²åˆ é™¤åŸå§‹æ–‡ä»¶: {os.path.basename(original_file)}")
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ é™¤åŸå§‹æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    return True

def extract_paragraph_style(paragraph):
    """æå–æ®µè½çš„æ ·å¼ä¿¡æ¯"""
    style_info = {
        'paragraph_level': {},
        'runs': []
    }
    
    try:
        # æ®µè½çº§åˆ«çš„æ ·å¼
        if paragraph.alignment:
            style_info['paragraph_level']['alignment'] = paragraph.alignment
        if paragraph.level:
            style_info['paragraph_level']['level'] = paragraph.level
        
        # æ¯ä¸ªrunçš„æ ·å¼
        for run in paragraph.runs:
            run_style = {}
            
            try:
                # å­—ä½“æ ·å¼
                if run.font.name:
                    run_style['font_name'] = run.font.name
                if run.font.size:
                    run_style['font_size'] = run.font.size
                if run.font.bold is not None:
                    run_style['bold'] = run.font.bold
                if run.font.italic is not None:
                    run_style['italic'] = run.font.italic
                if run.font.underline is not None:
                    run_style['underline'] = run.font.underline
                
                # é¢œè‰²å¤„ç† - ç®€åŒ–ç‰ˆæœ¬ï¼Œåªä¿å­˜é¢œè‰²å¯¹è±¡
                if run.font.color:
                    # ç›´æ¥ä¿å­˜é¢œè‰²å¯¹è±¡ï¼Œé¿å…ç±»å‹æ£€æŸ¥é”™è¯¯
                    run_style['color_object'] = run.font.color
                        
            except Exception as e:
                # å¦‚æœè·å–æ ·å¼å¤±è´¥ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªrun
                logger.warning(f"æå–runæ ·å¼å¤±è´¥: {str(e)}")
                continue
            
            style_info['runs'].append({
                'text': run.text,
                'style': run_style
            })
    except Exception as e:
        # å¦‚æœæå–æ®µè½æ ·å¼å¤±è´¥ï¼Œè¿”å›ç©ºçš„æ ·å¼ä¿¡æ¯
        logger.warning(f"æå–æ®µè½æ ·å¼å¤±è´¥: {str(e)}")
    
    return style_info

def extract_cell_style(cell):
    """æå–è¡¨æ ¼å•å…ƒæ ¼çš„æ ·å¼ä¿¡æ¯"""
    style_info = {
        'paragraphs': []
    }
    
    for paragraph in cell.text_frame.paragraphs:
        para_style = extract_paragraph_style(paragraph)
        style_info['paragraphs'].append(para_style)
    
    return style_info

def apply_translation_to_paragraph(paragraph, translated_text, style_info):
    """åº”ç”¨ç¿»è¯‘ç»“æœåˆ°æ®µè½å¹¶æ¢å¤æ ·å¼ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰"""
    # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºè‡ªé€‚åº”è®¡ç®—
    original_text = paragraph.text
    
    # æ¸…ç©ºæ®µè½å†…å®¹
    paragraph.clear()
    
    # å¦‚æœæœ‰æ ·å¼ä¿¡æ¯ï¼ŒæŒ‰runæ¢å¤æ ·å¼
    if style_info and 'runs' in style_info and style_info['runs']:
        # æŒ‰åŸå§‹runçš„æ ·å¼åˆ†é…ç¿»è¯‘æ–‡æœ¬ï¼ˆåº”ç”¨è‡ªé€‚åº”æ ·å¼ï¼‰
        distribute_text_to_runs_with_adaptive_styles(paragraph, translated_text, style_info['runs'], original_text)
    else:
        # æ²¡æœ‰æ ·å¼ä¿¡æ¯ï¼Œç›´æ¥æ·»åŠ æ–‡æœ¬
        original_text = paragraph.text
        paragraph.text = translated_text
        # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°æ‰€æœ‰runs
        if paragraph.runs:
            for run in paragraph.runs:
                if ENABLE_FONT_SCALING:
                    apply_adaptive_styles_ppt(run, original_text, translated_text)
    
    # æ¢å¤æ®µè½çº§åˆ«çš„æ ·å¼
    if style_info and 'paragraph_level' in style_info:
        para_level = style_info['paragraph_level']
        if 'alignment' in para_level:
            paragraph.alignment = para_level['alignment']
        if 'level' in para_level:
            paragraph.level = para_level['level']


def apply_translation_to_cell(cell, translated_text, style_info):
    """åº”ç”¨ç¿»è¯‘ç»“æœåˆ°è¡¨æ ¼å•å…ƒæ ¼å¹¶æ¢å¤æ ·å¼ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰"""
    # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºè‡ªé€‚åº”è®¡ç®—
    original_text = cell.text
    
    # æ¸…ç©ºå•å…ƒæ ¼å†…å®¹
    cell.text = ""
    
    # å¦‚æœæœ‰æ ·å¼ä¿¡æ¯ï¼ŒæŒ‰æ®µè½æ¢å¤æ ·å¼
    if style_info and 'paragraphs' in style_info and style_info['paragraphs']:
        # æŒ‰åŸå§‹æ®µè½çš„æ ·å¼åˆ†é…ç¿»è¯‘æ–‡æœ¬ï¼ˆåº”ç”¨è‡ªé€‚åº”æ ·å¼ï¼‰
        distribute_text_to_paragraphs_with_adaptive_styles(cell.text_frame, translated_text, style_info['paragraphs'], original_text)
    else:
        # æ²¡æœ‰æ ·å¼ä¿¡æ¯ï¼Œç›´æ¥æ·»åŠ æ–‡æœ¬
        original_text = cell.text
        cell.text = translated_text
        # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°å•å…ƒæ ¼ä¸­çš„æ‰€æœ‰æ®µè½çš„æ‰€æœ‰runs
        if cell.text_frame.paragraphs:
            for paragraph in cell.text_frame.paragraphs:
                if paragraph.runs:
                    for run in paragraph.runs:
                        if ENABLE_FONT_SCALING:
                            apply_adaptive_styles_ppt(run, original_text, translated_text)


def apply_translation_to_paragraph_with_adaptive_styles(paragraph, translated_text, style_info):
    """åº”ç”¨ç¿»è¯‘ç»“æœåˆ°æ®µè½å¹¶æ¢å¤æ ·å¼ï¼ŒåŒæ—¶åº”ç”¨è‡ªé€‚åº”æ ·å¼"""
    # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºè‡ªé€‚åº”è®¡ç®—
    original_text = paragraph.text
    
    # æ¸…ç©ºæ®µè½å†…å®¹
    paragraph.clear()
    
    # å¦‚æœæœ‰æ ·å¼ä¿¡æ¯ï¼ŒæŒ‰runæ¢å¤æ ·å¼
    if style_info and 'runs' in style_info and style_info['runs']:
        # æŒ‰åŸå§‹runçš„æ ·å¼åˆ†é…ç¿»è¯‘æ–‡æœ¬
        distribute_text_to_runs_with_adaptive_styles(paragraph, translated_text, style_info['runs'], original_text)
    else:
        # æ²¡æœ‰æ ·å¼ä¿¡æ¯ï¼Œç›´æ¥æ·»åŠ æ–‡æœ¬
        paragraph.text = translated_text
        # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°æ‰€æœ‰runs
        if paragraph.runs:
            for run in paragraph.runs:
                if ENABLE_FONT_SCALING:
                    apply_adaptive_styles_ppt(run, original_text, translated_text)
    
    # æ¢å¤æ®µè½çº§åˆ«çš„æ ·å¼
    if style_info and 'paragraph_level' in style_info:
        para_level = style_info['paragraph_level']
        if 'alignment' in para_level:
            paragraph.alignment = para_level['alignment']
        if 'level' in para_level:
            paragraph.level = para_level['level']


def apply_translation_to_cell_with_adaptive_styles(cell, translated_text, style_info):
    """åº”ç”¨ç¿»è¯‘ç»“æœåˆ°è¡¨æ ¼å•å…ƒæ ¼å¹¶æ¢å¤æ ·å¼ï¼ŒåŒæ—¶åº”ç”¨è‡ªé€‚åº”æ ·å¼"""
    # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºè‡ªé€‚åº”è®¡ç®—
    original_text = cell.text
    
    # æ¸…ç©ºå•å…ƒæ ¼å†…å®¹
    cell.text = ""
    
    # å¦‚æœæœ‰æ ·å¼ä¿¡æ¯ï¼ŒæŒ‰æ®µè½æ¢å¤æ ·å¼
    if style_info and 'paragraphs' in style_info and style_info['paragraphs']:
        # æŒ‰åŸå§‹æ®µè½çš„æ ·å¼åˆ†é…ç¿»è¯‘æ–‡æœ¬
        distribute_text_to_paragraphs_with_adaptive_styles(cell.text_frame, translated_text, style_info['paragraphs'], original_text)
    else:
        # æ²¡æœ‰æ ·å¼ä¿¡æ¯ï¼Œç›´æ¥æ·»åŠ æ–‡æœ¬
        cell.text = translated_text
        # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°å•å…ƒæ ¼ä¸­çš„æ‰€æœ‰æ®µè½çš„æ‰€æœ‰runs
        if cell.text_frame.paragraphs:
            for paragraph in cell.text_frame.paragraphs:
                if paragraph.runs:
                    for run in paragraph.runs:
                        if ENABLE_FONT_SCALING:
                            apply_adaptive_styles_ppt(run, original_text, translated_text)


def distribute_text_to_runs_with_adaptive_styles(paragraph, translated_text, run_styles, original_text):
    """å°†ç¿»è¯‘æ–‡æœ¬æŒ‰åŸå§‹runçš„æ ·å¼åˆ†é…åˆ°æ–°çš„runä¸­ï¼ŒåŒæ—¶åº”ç”¨è‡ªé€‚åº”æ ·å¼"""
    if not run_styles:
        paragraph.text = translated_text
        # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°æ‰€æœ‰runs
        if paragraph.runs:
            for run in paragraph.runs:
                if ENABLE_FONT_SCALING:
                    apply_adaptive_styles_ppt(run, original_text, translated_text)
        return
    
    # è®¡ç®—æ¯ä¸ªrunåº”è¯¥åˆ†é…çš„æ–‡æœ¬é•¿åº¦
    total_original_length = sum(len(run['text']) for run in run_styles)
    if total_original_length == 0:
        paragraph.text = translated_text
        # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°æ‰€æœ‰runs
        if paragraph.runs:
            for run in paragraph.runs:
                if ENABLE_FONT_SCALING:
                    apply_adaptive_styles_ppt(run, original_text, translated_text)
        return
    
    # æŒ‰æ¯”ä¾‹åˆ†é…ç¿»è¯‘æ–‡æœ¬
    current_pos = 0
    for i, run_style in enumerate(run_styles):
        original_length = len(run_style['text'])
        if original_length == 0:
            continue
        
        # è®¡ç®—è¿™ä¸ªrunåº”è¯¥åˆ†é…çš„æ–‡æœ¬é•¿åº¦
        if i == len(run_styles) - 1:
            # æœ€åä¸€ä¸ªrunï¼Œåˆ†é…å‰©ä½™çš„æ‰€æœ‰æ–‡æœ¬
            allocated_text = translated_text[current_pos:]
        else:
            # æŒ‰æ¯”ä¾‹åˆ†é…
            ratio = original_length / total_original_length
            allocated_length = max(1, int(len(translated_text) * ratio))
            # ç¡®ä¿ä¸è¶…è¿‡å‰©ä½™æ–‡æœ¬é•¿åº¦
            remaining_length = len(translated_text) - current_pos
            allocated_length = min(allocated_length, remaining_length)
            allocated_text = translated_text[current_pos:current_pos + allocated_length]
            current_pos += allocated_length
        
        if allocated_text:
            # åˆ›å»ºæ–°çš„runå¹¶åº”ç”¨æ ·å¼
            run = paragraph.add_run()
            run.text = allocated_text
            apply_run_style(run, run_style['style'])
            # åº”ç”¨è‡ªé€‚åº”æ ·å¼ - ä½¿ç”¨æ•´ä¸ªæ®µè½çš„åŸå§‹æ–‡æœ¬å’Œç¿»è¯‘æ–‡æœ¬
            if ENABLE_FONT_SCALING:
                apply_adaptive_styles_ppt(run, original_text, translated_text)


def distribute_text_to_paragraphs_with_adaptive_styles(text_frame, translated_text, paragraph_styles, original_text):
    """å°†ç¿»è¯‘æ–‡æœ¬æŒ‰åŸå§‹æ®µè½çš„æ ·å¼åˆ†é…åˆ°æ–°çš„æ®µè½ä¸­ï¼ŒåŒæ—¶åº”ç”¨è‡ªé€‚åº”æ ·å¼"""
    if not paragraph_styles:
        text_frame.text = translated_text
        # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°æ‰€æœ‰æ®µè½çš„æ‰€æœ‰runs
        if text_frame.paragraphs:
            for paragraph in text_frame.paragraphs:
                if paragraph.runs:
                    for run in paragraph.runs:
                        if ENABLE_FONT_SCALING:
                            apply_adaptive_styles_ppt(run, original_text, translated_text)
        return
    
    # æ¸…ç©ºæ–‡æœ¬æ¡†æ¶
    text_frame.clear()
    
    # æŒ‰æ®µè½åˆ†é…æ–‡æœ¬
    total_original_length = sum(len(run['text']) for para in paragraph_styles for run in para['runs'])
    if total_original_length == 0:
        text_frame.text = translated_text
        # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°æ‰€æœ‰æ®µè½çš„æ‰€æœ‰runs
        if text_frame.paragraphs:
            for paragraph in text_frame.paragraphs:
                if paragraph.runs:
                    for run in paragraph.runs:
                        if ENABLE_FONT_SCALING:
                            apply_adaptive_styles_ppt(run, original_text, translated_text)
        return
    
    current_pos = 0
    for i, para_style in enumerate(paragraph_styles):
        if i > 0:
            # æ·»åŠ æ®µè½åˆ†éš”ç¬¦
            text_frame.add_paragraph()
        
        paragraph = text_frame.paragraphs[-1] if text_frame.paragraphs else text_frame.add_paragraph()
        
        # è®¡ç®—è¿™ä¸ªæ®µè½åº”è¯¥åˆ†é…çš„æ–‡æœ¬é•¿åº¦
        para_original_length = sum(len(run['text']) for run in para_style['runs'])
        if para_original_length == 0:
            continue
        
        if i == len(paragraph_styles) - 1:
            # æœ€åä¸€ä¸ªæ®µè½ï¼Œåˆ†é…å‰©ä½™çš„æ‰€æœ‰æ–‡æœ¬
            allocated_text = translated_text[current_pos:]
        else:
            # æŒ‰æ¯”ä¾‹åˆ†é…
            ratio = para_original_length / total_original_length
            allocated_length = max(1, int(len(translated_text) * ratio))
            # ç¡®ä¿ä¸è¶…è¿‡å‰©ä½™æ–‡æœ¬é•¿åº¦
            remaining_length = len(translated_text) - current_pos
            allocated_length = min(allocated_length, remaining_length)
            allocated_text = translated_text[current_pos:current_pos + allocated_length]
            current_pos += allocated_length
        
        if allocated_text:
            # æŒ‰runåˆ†é…æ–‡æœ¬å¹¶åº”ç”¨æ ·å¼
            if para_style['runs']:
                distribute_text_to_runs_with_adaptive_styles(paragraph, allocated_text, para_style['runs'], original_text)
            else:
                paragraph.text = allocated_text
                # åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°æ‰€æœ‰runs
                if paragraph.runs:
                    for run in paragraph.runs:
                        if ENABLE_FONT_SCALING:
                            apply_adaptive_styles_ppt(run, original_text, allocated_text)

def apply_run_style(run, style):
    """åº”ç”¨runçš„æ ·å¼"""
    if not style:
        return
    
    try:
        # å­—ä½“åç§°
        if 'font_name' in style:
            run.font.name = style['font_name']
        
        # å­—ä½“å¤§å°
        if 'font_size' in style:
            run.font.size = style['font_size']
        
        # ç²—ä½“
        if 'bold' in style:
            run.font.bold = style['bold']
        
        # æ–œä½“
        if 'italic' in style:
            run.font.italic = style['italic']
        
        # ä¸‹åˆ’çº¿
        if 'underline' in style:
            run.font.underline = style['underline']
        
        # é¢œè‰²å¤„ç† - ç®€åŒ–ç‰ˆæœ¬
        if 'color_object' in style:
            try:
                color_object = style['color_object']
                # å°è¯•å¤åˆ¶é¢œè‰²å±æ€§
                if hasattr(color_object, 'rgb') and color_object.rgb:
                    run.font.color.rgb = color_object.rgb
                elif hasattr(color_object, 'theme_color') and color_object.theme_color:
                    run.font.color.theme_color = color_object.theme_color
                elif hasattr(color_object, 'color_index') and color_object.color_index:
                    run.font.color.color_index = color_object.color_index
                elif hasattr(color_object, 'srgbClr') and color_object.srgbClr:
                    run.font.color.srgbClr = color_object.srgbClr
                # å…¶ä»–é¢œè‰²ç±»å‹æš‚æ—¶è·³è¿‡ï¼Œé¿å…é”™è¯¯
            except Exception as e:
                logger.warning(f"åº”ç”¨é¢œè‰²æ ·å¼å¤±è´¥: {str(e)}")
                pass  # å¦‚æœé¢œè‰²è®¾ç½®å¤±è´¥ï¼Œè·³è¿‡é¢œè‰²è®¾ç½®
    except Exception as e:
        # å¦‚æœåº”ç”¨æ ·å¼å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†
        logger.warning(f"åº”ç”¨runæ ·å¼å¤±è´¥: {str(e)}")


def calculate_adaptive_font_size_ppt(original_text, translated_text, original_font_size):
    """æ ¹æ®ç¿»è¯‘åæ–‡æœ¬é•¿åº¦è®¡ç®—PPTè‡ªé€‚åº”å­—ä½“å¤§å°"""
    try:
        if not original_font_size:
            return None
        
        # è®¡ç®—æ–‡æœ¬é•¿åº¦æ¯”ä¾‹
        original_length = len(original_text.strip())
        translated_length = len(translated_text.strip())
        
        if original_length == 0:
            return original_font_size
        
        # è®¡ç®—é•¿åº¦æ¯”ä¾‹
        length_ratio = translated_length / original_length
        
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logger.info(f"PPTå­—ä½“è‡ªé€‚åº”è°ƒè¯•: åŸæ–‡é•¿åº¦={original_length}, è¯‘æ–‡é•¿åº¦={translated_length}, æ¯”ä¾‹={length_ratio:.2f}")
        
        # å¦‚æœç¿»è¯‘åæ–‡æœ¬å˜é•¿ï¼Œé€‚å½“ç¼©å°å­—ä½“
        if length_ratio > 2.0:  # æ–‡æœ¬é•¿åº¦å¢åŠ è¶…è¿‡100%
            # æ–‡æœ¬ç‰¹åˆ«é•¿æ—¶ï¼Œæœ€å°å¯ä»¥åˆ°åŸå§‹å¤§å°çš„50%
            new_size = max(original_font_size * 0.5, original_font_size / length_ratio)
            logger.info(f"PPTå­—ä½“è‡ªé€‚åº”: æ–‡æœ¬ç‰¹åˆ«é•¿ï¼Œç¼©å°åˆ°50% -> {new_size}pt")
            return int(new_size)
        elif length_ratio > 1.3:  # æ–‡æœ¬é•¿åº¦å¢åŠ è¶…è¿‡30%
            # æœ€å°å¯ä»¥åˆ°åŸå§‹å¤§å°çš„50%
            new_size = max(original_font_size * 0.5, original_font_size / length_ratio)
            logger.info(f"PPTå­—ä½“è‡ªé€‚åº”: æ–‡æœ¬è¾ƒé•¿ï¼Œç¼©å°åˆ°50% -> {new_size}pt")
            return int(new_size)
        elif length_ratio < 0.7:  # æ–‡æœ¬é•¿åº¦å‡å°‘è¶…è¿‡30%
            # å¦‚æœæ–‡æœ¬å˜çŸ­ï¼Œå¯ä»¥é€‚å½“å¢å¤§å­—ä½“ï¼Œä½†ä¸è¦è¶…è¿‡åŸå§‹å¤§å°çš„130%
            new_size = min(original_font_size * 1.3, original_font_size / length_ratio)
            return int(new_size)
        else:
            # é•¿åº¦å˜åŒ–ä¸å¤§ï¼Œä¿æŒåŸå§‹å­—ä½“å¤§å°
            return original_font_size
            
    except Exception as e:
        logger.error(f"è®¡ç®—PPTè‡ªé€‚åº”å­—ä½“å¤§å°å¤±è´¥: {str(e)}")
        return original_font_size


def apply_adaptive_styles_ppt(run, original_text, translated_text):
    """åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°PPT run"""
    # æ£€æŸ¥å­—ä½“ç¼©æ”¾åŠŸèƒ½æ˜¯å¦å¯ç”¨
    if not ENABLE_FONT_SCALING:
        return  # å¦‚æœå…³é—­äº†å­—ä½“ç¼©æ”¾ï¼Œç›´æ¥è¿”å›
    
    try:
        # è·å–åŸå§‹å­—ä½“å¤§å°
        original_font_size = None
        
        # æ–¹æ³•1ï¼šç›´æ¥ä»runè·å–å­—ä½“å¤§å°
        if run.font.size:
            try:
                original_font_size = run.font.size.pt
            except:
                original_font_size = None
        
        # æ–¹æ³•2ï¼šä»æ®µè½çº§åˆ«è·å–å­—ä½“å¤§å°
        if not original_font_size and hasattr(run, '_element') and run._element.getparent():
            try:
                paragraph = run._element.getparent()
                if hasattr(paragraph, 'pPr') and paragraph.pPr:
                    defRPr = paragraph.pPr.defRPr
                    if defRPr and defRPr.sz:
                        original_font_size = defRPr.sz.val / 100  # è½¬æ¢ä¸ºpt
            except:
                pass
        
        # æ–¹æ³•3ï¼šä½¿ç”¨é»˜è®¤å­—ä½“å¤§å°
        if not original_font_size:
            original_font_size = 14  # é»˜è®¤14pt
            logger.info(f"ä½¿ç”¨é»˜è®¤å­—ä½“å¤§å°: {original_font_size}pt")
        
        # æ·»åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯
        logger.info(f"=== PPTè‡ªé€‚åº”æ ·å¼è°ƒè¯• ===")
        logger.info(f"Runæ–‡æœ¬: '{run.text[:30]}...'")
        logger.info(f"åŸæ–‡: '{original_text[:30]}...'")
        logger.info(f"è¯‘æ–‡: '{translated_text[:30]}...'")
        logger.info(f"åŸå§‹å­—ä½“å¤§å°: {original_font_size}pt")
        
        # è®¡ç®—è‡ªé€‚åº”å­—ä½“å¤§å°
        if original_font_size:
            adaptive_font_size = calculate_adaptive_font_size_ppt(original_text, translated_text, original_font_size)
            logger.info(f"è®¡ç®—åå­—ä½“å¤§å°: {adaptive_font_size}pt")
            
            if adaptive_font_size and adaptive_font_size != original_font_size:
                from pptx.util import Pt
                run.font.size = Pt(adaptive_font_size)
                logger.info(f"âœ… å­—ä½“å¤§å°å·²è°ƒæ•´: {original_font_size}pt -> {adaptive_font_size}pt")
            else:
                logger.info(f"âš ï¸ å­—ä½“å¤§å°æœªæ”¹å˜ (åŸå§‹={original_font_size}pt, è®¡ç®—={adaptive_font_size}pt)")
        else:
            logger.warning(f"âŒ æ— æ³•è·å–åŸå§‹å­—ä½“å¤§å°")
                    
    except Exception as e:
        logger.error(f"âŒ åº”ç”¨PPTè‡ªé€‚åº”æ ·å¼å¤±è´¥: {str(e)}")


def apply_adaptive_styles_to_shape(shape, original_text, translated_text):
    """åº”ç”¨è‡ªé€‚åº”æ ·å¼åˆ°å½¢çŠ¶æ–‡æœ¬"""
    # æ£€æŸ¥å­—ä½“ç¼©æ”¾åŠŸèƒ½æ˜¯å¦å¯ç”¨
    if not ENABLE_FONT_SCALING:
        return  # å¦‚æœå…³é—­äº†å­—ä½“ç¼©æ”¾ï¼Œç›´æ¥è¿”å›
    
    try:
        # è·å–åŸå§‹å­—ä½“å¤§å°
        original_font_size = None
        
        # æ–¹æ³•1ï¼šä»æ–‡æœ¬æ¡†æ¶è·å–å­—ä½“å¤§å°
        if hasattr(shape, 'text_frame') and shape.text_frame:
            if shape.text_frame.paragraphs:
                paragraph = shape.text_frame.paragraphs[0]
                if paragraph.runs:
                    run = paragraph.runs[0]
                    if run.font.size:
                        try:
                            original_font_size = run.font.size.pt
                        except:
                            original_font_size = None
        
        # æ–¹æ³•2ï¼šä»å½¢çŠ¶å±æ€§è·å–å­—ä½“å¤§å°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if not original_font_size and hasattr(shape, 'text') and shape.text:
            # å¯¹äºç®€å•çš„å½¢çŠ¶æ–‡æœ¬ï¼Œå°è¯•è·å–é»˜è®¤å­—ä½“å¤§å°
            try:
                # ä½¿ç”¨ä¸€ä¸ªåˆç†çš„é»˜è®¤å­—ä½“å¤§å°
                original_font_size = 18  # é»˜è®¤18pt
                logger.info(f"PPTå½¢çŠ¶è‡ªé€‚åº”: ä½¿ç”¨é»˜è®¤å­—ä½“å¤§å° {original_font_size}pt")
            except:
                original_font_size = None
        
        # æ–¹æ³•3ï¼šä»å½¢çŠ¶åç§°è·å–å­—ä½“å¤§å°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if not original_font_size and hasattr(shape, 'name') and shape.name:
            # å¯¹äºå½¢çŠ¶åç§°ï¼Œä½¿ç”¨è¾ƒå°çš„é»˜è®¤å­—ä½“å¤§å°
            original_font_size = 12  # é»˜è®¤12pt
            logger.info(f"PPTå½¢çŠ¶åç§°è‡ªé€‚åº”: ä½¿ç”¨é»˜è®¤å­—ä½“å¤§å° {original_font_size}pt")
        
        # è®¡ç®—è‡ªé€‚åº”å­—ä½“å¤§å°
        if original_font_size:
            adaptive_font_size = calculate_adaptive_font_size_ppt(original_text, translated_text, original_font_size)
            if adaptive_font_size and adaptive_font_size != original_font_size:
                from pptx.util import Pt
                # åº”ç”¨åˆ°å½¢çŠ¶çš„æ–‡æœ¬æ¡†æ¶
                if hasattr(shape, 'text_frame') and shape.text_frame and shape.text_frame.paragraphs:
                    for paragraph in shape.text_frame.paragraphs:
                        for run in paragraph.runs:
                            if ENABLE_FONT_SCALING:
                                run.font.size = Pt(adaptive_font_size)
                logger.info(f"PPTå½¢çŠ¶å­—ä½“å¤§å°è‡ªé€‚åº”: {original_font_size}pt -> {adaptive_font_size}pt")
            else:
                logger.info(f"PPTå½¢çŠ¶è‡ªé€‚åº”: å­—ä½“å¤§å°æœªæ”¹å˜ (åŸå§‹={original_font_size}pt, è®¡ç®—={adaptive_font_size}pt)")
        else:
            logger.warning(f"PPTå½¢çŠ¶è‡ªé€‚åº”: æ— æ³•è·å–åŸå§‹å­—ä½“å¤§å°")
                    
    except Exception as e:
        logger.error(f"åº”ç”¨PPTå½¢çŠ¶è‡ªé€‚åº”æ ·å¼å¤±è´¥: {str(e)}")


def distribute_text_to_runs(paragraph, translated_text, run_styles):
    """å°†ç¿»è¯‘æ–‡æœ¬æŒ‰åŸå§‹runçš„æ ·å¼åˆ†é…åˆ°æ–°çš„runä¸­ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰"""
    if not run_styles:
        paragraph.text = translated_text
        return
    
    # è®¡ç®—æ¯ä¸ªrunåº”è¯¥åˆ†é…çš„æ–‡æœ¬é•¿åº¦
    total_original_length = sum(len(run['text']) for run in run_styles)
    if total_original_length == 0:
        paragraph.text = translated_text
        return
    
    # æŒ‰æ¯”ä¾‹åˆ†é…ç¿»è¯‘æ–‡æœ¬
    current_pos = 0
    for i, run_style in enumerate(run_styles):
        original_length = len(run_style['text'])
        if original_length == 0:
            continue
        
        # è®¡ç®—è¿™ä¸ªrunåº”è¯¥åˆ†é…çš„æ–‡æœ¬é•¿åº¦
        if i == len(run_styles) - 1:
            # æœ€åä¸€ä¸ªrunï¼Œåˆ†é…å‰©ä½™çš„æ‰€æœ‰æ–‡æœ¬
            allocated_text = translated_text[current_pos:]
        else:
            # æŒ‰æ¯”ä¾‹åˆ†é…
            ratio = original_length / total_original_length
            allocated_length = max(1, int(len(translated_text) * ratio))
            # ç¡®ä¿ä¸è¶…è¿‡å‰©ä½™æ–‡æœ¬é•¿åº¦
            remaining_length = len(translated_text) - current_pos
            allocated_length = min(allocated_length, remaining_length)
            allocated_text = translated_text[current_pos:current_pos + allocated_length]
            current_pos += allocated_length
        
        if allocated_text:
            # åˆ›å»ºæ–°çš„runå¹¶åº”ç”¨æ ·å¼
            run = paragraph.add_run()
            run.text = allocated_text
            apply_run_style(run, run_style['style'])


def distribute_text_to_paragraphs(text_frame, translated_text, paragraph_styles):
    """å°†ç¿»è¯‘æ–‡æœ¬æŒ‰åŸå§‹æ®µè½çš„æ ·å¼åˆ†é…åˆ°æ–°çš„æ®µè½ä¸­ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰"""
    if not paragraph_styles:
        text_frame.text = translated_text
        return
    
    # æ¸…ç©ºæ–‡æœ¬æ¡†æ¶
    text_frame.clear()
    
    # æŒ‰æ®µè½åˆ†é…æ–‡æœ¬
    total_original_length = sum(len(run['text']) for para in paragraph_styles for run in para['runs'])
    if total_original_length == 0:
        text_frame.text = translated_text
        return
    
    current_pos = 0
    for i, para_style in enumerate(paragraph_styles):
        if i > 0:
            # æ·»åŠ æ®µè½åˆ†éš”ç¬¦
            text_frame.add_paragraph()
        
        paragraph = text_frame.paragraphs[-1] if text_frame.paragraphs else text_frame.add_paragraph()
        
        # è®¡ç®—è¿™ä¸ªæ®µè½åº”è¯¥åˆ†é…çš„æ–‡æœ¬é•¿åº¦
        para_original_length = sum(len(run['text']) for run in para_style['runs'])
        if para_original_length == 0:
            continue
        
        if i == len(paragraph_styles) - 1:
            # æœ€åä¸€ä¸ªæ®µè½ï¼Œåˆ†é…å‰©ä½™çš„æ‰€æœ‰æ–‡æœ¬
            allocated_text = translated_text[current_pos:]
        else:
            # æŒ‰æ¯”ä¾‹åˆ†é…
            ratio = para_original_length / total_original_length
            allocated_length = max(1, int(len(translated_text) * ratio))
            # ç¡®ä¿ä¸è¶…è¿‡å‰©ä½™æ–‡æœ¬é•¿åº¦
            remaining_length = len(translated_text) - current_pos
            allocated_length = min(allocated_length, remaining_length)
            allocated_text = translated_text[current_pos:current_pos + allocated_length]
            current_pos += allocated_length
        
        if allocated_text:
            # æŒ‰runåˆ†é…æ–‡æœ¬å¹¶åº”ç”¨è‡ªé€‚åº”æ ·å¼
            # æ³¨æ„ï¼šæœ€åä¸€ä¸ªå‚æ•°åº”è¯¥æ˜¯original_textï¼Œç”¨äºæ ·å¼æ¢å¤
            distribute_text_to_runs_with_adaptive_styles(paragraph, allocated_text, para_style['runs'], original_text)
            
            # æ¢å¤æ®µè½çº§åˆ«çš„æ ·å¼
            if 'paragraph_level' in para_style:
                para_level = para_style['paragraph_level']
                if 'alignment' in para_level:
                    paragraph.alignment = para_level['alignment']
                if 'level' in para_level:
                    paragraph.level = para_level['level']


def find_translated_text_for_shape(texts, slide_index, shape_index, text_type, **kwargs):
    """ä»textsåˆ—è¡¨ä¸­æŸ¥æ‰¾ä¸ç»™å®šå½¢çŠ¶å’Œæ–‡æœ¬ç±»å‹åŒ¹é…çš„ç¿»è¯‘ç»“æœ"""
    # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…ï¼ˆå¯¹è±¡å¼•ç”¨åŒ¹é…ï¼‰
    for item in texts:
        if item['type'] == text_type and item.get('complete', False):
            # æ£€æŸ¥å½¢çŠ¶æ˜¯å¦åŒ¹é…
            if 'shape' in kwargs and item.get('shape') == kwargs.get('shape'):
                return item
            # æ£€æŸ¥æ–‡æœ¬æ¡†æ¶æ˜¯å¦åŒ¹é…
            if 'text_frame' in kwargs and item.get('text_frame') == kwargs.get('text_frame'):
                return item
            # æ£€æŸ¥æ®µè½æ˜¯å¦åŒ¹é…
            if 'paragraph' in kwargs and item.get('paragraph') == kwargs.get('paragraph'):
                return item
            # æ£€æŸ¥å•å…ƒæ ¼æ˜¯å¦åŒ¹é…
            if 'cell' in kwargs and item.get('cell') == kwargs.get('cell'):
                return item
    
    # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•åŸºäºä½ç½®å’Œå†…å®¹çš„ç²¾ç¡®åŒ¹é…
    for item in texts:
        if item['type'] == text_type and item.get('complete', False):
            # æ£€æŸ¥å¹»ç¯ç‰‡ç´¢å¼•å’Œå½¢çŠ¶ç´¢å¼•æ˜¯å¦åŒ¹é…
            if (item.get('slide_index') == slide_index and 
                item.get('shape_index') == shape_index):
                
                # å¯¹äºæ®µè½ç±»å‹ï¼Œè¿˜éœ€è¦æ£€æŸ¥æ®µè½ç´¢å¼•
                if text_type == 'paragraph' and 'paragraph_index' in kwargs:
                    if item.get('paragraph_index') == kwargs.get('paragraph_index'):
                        # é¢å¤–æ£€æŸ¥åŸå§‹æ–‡æœ¬æ˜¯å¦åŒ¹é…
                        paragraph = kwargs.get('paragraph')
                        original_text = paragraph.text if paragraph and hasattr(paragraph, 'text') else None
                        if original_text and item.get('original_text'):
                            if original_text.strip() == item.get('original_text', '').strip():
                                return item
                # å¯¹äºè¡¨æ ¼å•å…ƒæ ¼ï¼Œæ£€æŸ¥è¡Œåˆ—ç´¢å¼•
                elif text_type == 'table_cell':
                    if (item.get('row') == kwargs.get('row') and 
                        item.get('column') == kwargs.get('column')):
                        # é¢å¤–æ£€æŸ¥åŸå§‹æ–‡æœ¬æ˜¯å¦åŒ¹é…
                        cell = kwargs.get('cell')
                        cell_text = cell.text if cell and hasattr(cell, 'text') else None
                        if cell_text and item.get('original_text'):
                            if cell_text.strip() == item.get('original_text', '').strip():
                                return item
                # å¯¹äºå…¶ä»–ç±»å‹ï¼Œæ£€æŸ¥åŸå§‹æ–‡æœ¬æ˜¯å¦åŒ¹é…
                elif text_type in ['shape_text', 'shape_name', 'text_frame']:
                    # è·å–åŸå§‹æ–‡æœ¬
                    original_text = None
                    if 'shape' in kwargs:
                        shape = kwargs.get('shape')
                        if text_type == 'shape_text' and hasattr(shape, 'text'):
                            original_text = shape.text
                        elif text_type == 'shape_name' and hasattr(shape, 'name'):
                            original_text = shape.name
                    elif 'text_frame' in kwargs:
                        text_frame = kwargs.get('text_frame')
                        if hasattr(text_frame, 'text'):
                            original_text = text_frame.text
                    
                    # æ¯”è¾ƒåŸå§‹æ–‡æœ¬
                    if original_text and item.get('original_text'):
                        if original_text.strip() == item.get('original_text', '').strip():
                            return item
    
    # å¦‚æœæ‰€æœ‰åŒ¹é…éƒ½å¤±è´¥ï¼Œè®°å½•è­¦å‘Šå¹¶è¿”å›None
    logger.warning(f"æœªæ‰¾åˆ°åŒ¹é…çš„ç¿»è¯‘ç»“æœ: slide_index={slide_index}, shape_index={shape_index}, text_type={text_type}, kwargs={kwargs}")
    return None


