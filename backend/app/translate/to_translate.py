# -*- coding: utf-8 -*-
import tiktoken
import datetime
import hashlib
import logging
import os
import sys
import re
import openai
from . import common
from . import db
import time

from .baidu.main import baidu_translate

# å¯¼å…¥Qwenç¿»è¯‘æ¨¡å—
try:
    from .qwen_translate import qwen_translate, check_qwen_availability
    logging.info("âœ… æˆåŠŸå¯¼å…¥ qwen_translate æ¨¡å—")
except ImportError as e:
    logging.error(f"âŒ å¯¼å…¥ qwen_translate æ¨¡å—å¤±è´¥: {e}")
    # å¦‚æœQwenæ¨¡å—ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å‡½æ•°
    def qwen_translate(text, target_language, source_lang="auto", tm_list=None, terms=None, domains=None, prompt=None, prompt_id=None, max_retries=10, texts=None, index=None):
        logging.warning("âš ï¸ ä½¿ç”¨å¤‡ç”¨ qwen_translate å‡½æ•°ï¼Œä¸Šä¸‹æ–‡åŠŸèƒ½ä¸å¯ç”¨")
        return text
    def check_qwen_availability():
        return False, "Qwenæ¨¡å—æœªæ‰¾åˆ°"


def translate_text(trans, text, source_lang="auto", target_lang=None):
    """
    ç¿»è¯‘å•ä¸ªæ–‡æœ¬
    
    Args:
        trans: ç¿»è¯‘é…ç½®å­—å…¸
        text: è¦ç¿»è¯‘çš„æ–‡æœ¬
        source_lang: æºè¯­è¨€
        target_lang: ç›®æ ‡è¯­è¨€
        
    Returns:
        str: ç¿»è¯‘åçš„æ–‡æœ¬
    """
    try:
        # è·å–ç¿»è¯‘é…ç½®
        api_key = trans.get('api_key', '')
        api_url = trans.get('api_url', '')
        model = trans.get('model', 'gpt-3.5-turbo')
        server = trans.get('server', 'openai')
        app_id = trans.get('app_id', '')
        app_key = trans.get('app_key', '')
        
        # å¦‚æœæ²¡æœ‰ä¼ é€’target_langå‚æ•°ï¼Œä»transä¸­è·å–
        if target_lang is None or not target_lang or not str(target_lang).strip():
            target_lang = trans.get('lang')
            # å¿…é¡»ä½¿ç”¨å‰ç«¯ä¼ å€¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™æŠ¥é”™
            if not target_lang or not str(target_lang).strip():
                logging.error(f"ç›®æ ‡è¯­è¨€å‚æ•°ç¼ºå¤±æˆ–ä¸ºç©º: trans={trans}")
                raise ValueError("ç›®æ ‡è¯­è¨€å‚æ•°(lang)ç¼ºå¤±æˆ–ä¸ºç©ºï¼Œå¿…é¡»ç”±å‰ç«¯ä¼ é€’")
        
        # æ ¹æ®æœåŠ¡å™¨ç±»å‹é€‰æ‹©ç¿»è¯‘æ–¹æ³•
        if server == 'baidu':
            return baidu_translate(
                text=text,
                appid=app_id,
                app_key=app_key,
                from_lang=source_lang,
                to_lang=target_lang,
                use_term_base=False
            )
        elif server == 'qwen':
            # å‰ç«¯å·²ç›´æ¥ä¼ å…¥è‹±æ–‡åï¼ˆEnglish Nameï¼‰ï¼Œæ— éœ€æ˜ å°„
            # target_lang å·²ç»æ˜¯è‹±æ–‡å…¨æ‹¼æ ¼å¼ï¼ˆå¦‚ "English", "Chinese"ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
            return qwen_translate(
                text=text,
                target_language=target_lang,  # ç›´æ¥ä½¿ç”¨ï¼Œå·²ç»æ˜¯è‹±æ–‡å
                source_lang="auto",
                prompt=trans.get('prompt'),
                prompt_id=trans.get('prompt_id'),
                texts=None,  # translate_textå‡½æ•°ä¸­æ²¡æœ‰textsæ•°ç»„
                index=None,   # translate_textå‡½æ•°ä¸­æ²¡æœ‰index
                api_key=trans.get('api_key'),  # ä»é…ç½®ä¸­è·å–API Key
                translate_id=trans.get('id'),
                customer_id=trans.get('customer_id'),
                tenant_id=trans.get('tenant_id'),
                uuid=trans.get('uuid')
            )
        else:
            # OpenAI ç¿»è¯‘ (å…¼å®¹æ–°æ—§ç‰ˆæœ¬)
            try:
                import openai
                
                # å°è¯•æ–°ç‰ˆæœ¬ API
                if hasattr(openai, 'OpenAI'):
                    client = openai.OpenAI(api_key=api_key, base_url=api_url if api_url else None)
                    response = client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": f"è¯·å°†ä»¥ä¸‹{source_lang}æ–‡æœ¬ç¿»è¯‘ä¸º{target_lang}ï¼Œåªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡è®°ã€‚"},
                            {"role": "user", "content": text}
                        ],
                        temperature=0.3
                    )
                    return response.choices[0].message.content.strip()
                else:
                    # æ—§ç‰ˆæœ¬ API
                    openai.api_key = api_key
                    if api_url:
                        openai.api_base = api_url
                    
                    response = openai.ChatCompletion.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": f"è¯·å°†ä»¥ä¸‹{source_lang}æ–‡æœ¬ç¿»è¯‘ä¸º{target_lang}ï¼Œåªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡è®°ã€‚"},
                            {"role": "user", "content": text}
                        ],
                        temperature=0.3
                    )
                    return response.choices[0].message.content.strip()
            except Exception as e:
                logging.error(f"OpenAI ç¿»è¯‘å¤±è´¥: {e}")
                # å¦‚æœ OpenAI å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ Qwen ä½œä¸ºå¤‡ç”¨
                try:
                    # å‰ç«¯å·²ç›´æ¥ä¼ å…¥è‹±æ–‡åï¼Œç›´æ¥ä½¿ç”¨
                    return qwen_translate(
                        text=text,
                        target_language=target_lang,  # ç›´æ¥ä½¿ç”¨ï¼Œå·²ç»æ˜¯è‹±æ–‡å
                        source_lang="auto",
                        prompt=trans.get('prompt'),
                        prompt_id=trans.get('prompt_id'),
                        texts=None,  # å¤‡ç”¨æ–¹æ¡ˆä¸­æ²¡æœ‰textsæ•°ç»„
                        index=None,   # å¤‡ç”¨æ–¹æ¡ˆä¸­æ²¡æœ‰index
                        api_key=trans.get('api_key'),  # ä»é…ç½®ä¸­è·å–API Key
                        translate_id=trans.get('id'),
                        customer_id=trans.get('customer_id'),
                        tenant_id=trans.get('tenant_id'),
                        uuid=trans.get('uuid')
                    )
                except:
                    return text  # æœ€åè¿”å›åŸæ–‡
            
    except Exception as e:
        logging.error(f"ç¿»è¯‘å¤±è´¥: {e}")
        return text  # å¤±è´¥æ—¶è¿”å›åŸæ–‡


def get(trans, event, texts, index):
    # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
    if event.is_set():
        exit(0)
    
    # æ£€æŸ¥å…¨å±€å–æ¶ˆäº‹ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    cancel_event = trans.get('cancel_event')
    if cancel_event and cancel_event.is_set():
        logging.info(f"ä»»åŠ¡ {trans.get('id')} å·²è¢«ç”¨æˆ·å–æ¶ˆ")
        exit(0)
    
    # æ£€æŸ¥æš‚åœäº‹ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    from app.utils.task_manager import get_task_pause_event
    pause_event = get_task_pause_event(trans.get('id'))
    if pause_event and pause_event.is_set():
        logging.info(f"ä»»åŠ¡ {trans.get('id')} å·²è¢«æš‚åœï¼Œç­‰å¾…æ¢å¤...")
        # ç­‰å¾…æš‚åœäº‹ä»¶è¢«æ¸…é™¤ï¼ˆæ¢å¤ï¼‰
        while pause_event.is_set():
            time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…
            # åœ¨ç­‰å¾…æœŸé—´ä¹Ÿè¦æ£€æŸ¥å–æ¶ˆäº‹ä»¶
            if cancel_event and cancel_event.is_set():
                logging.info(f"ä»»åŠ¡ {trans.get('id')} åœ¨æš‚åœæœŸé—´è¢«å–æ¶ˆ")
                exit(0)
        logging.info(f"ä»»åŠ¡ {trans.get('id')} å·²æ¢å¤")
    # æ¢å¤çº¿ç¨‹æ•°ä¸º30ï¼Œæé«˜ç¿»è¯‘æ•ˆç‡
    max_threads = 30
    translate_id = trans['id']
    target_lang = trans['lang']
    
    # ============== æ¨¡å‹é…ç½® ==============
    model = trans['model']
    backup_model = trans['backup_model']
    
    # æ‰“å°å½“å‰é…ç½®ï¼ˆä»…ç¬¬ä¸€æ¬¡ï¼‰
    if index == 0:
        try:
            # æ£€æŸ¥QwenæœåŠ¡å¯ç”¨æ€§
            if model == 'qwen-mt-plus':
                qwen_available, qwen_message = check_qwen_availability()
                # ç¿»è¯‘æ—¥å¿—å·²å…³é—­ï¼ˆè°ƒè¯•æ—¶å¯æ‰“å¼€ï¼‰
                # logging.info(f"QwenæœåŠ¡æ£€æŸ¥: {qwen_message}")
                if not qwen_available:
                    logging.warning("è­¦å‘Š: QwenæœåŠ¡ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                # else:
                #     logging.info("Qwenç¿»è¯‘æœåŠ¡å·²å¯ç”¨")
        except:
            pass
    # ==========================================
    
    prompt = trans['prompt']
    
    # ç¿»è¯‘æ—¥å¿—å·²å…³é—­ï¼ˆè°ƒè¯•æ—¶å¯æ‰“å¼€ï¼‰
    # logging.info(f"ğŸ” to_translate.py è°ƒè¯•ä¿¡æ¯:")
    # logging.info(f"  trans['prompt']ç±»å‹: {type(prompt)}")
    # logging.info(f"  trans['prompt']å€¼: {repr(prompt)}")
    # logging.info(f"  trans['prompt']æ˜¯å¦ä¸ºç©º: {not prompt}")
    # logging.info(f"  trans['prompt']é•¿åº¦: {len(prompt) if prompt else 0}")
    
    extension = trans['extension'].lower()
    text = texts[index]
    api_key = trans['api_key']
    api_url = trans['api_url']
    app_id = trans['app_id']
    app_key = trans['app_key']
    comparison_id = trans.get('comparison_id', 0)
    # ç¡®ä¿comparison_idä¸ä¸ºNoneï¼Œå¦‚æœæ˜¯Noneåˆ™è®¾ä¸º0
    if comparison_id is None:
        comparison_id = 0
    # ä¸è¦å¼ºåˆ¶è½¬æ¢ä¸ºintï¼Œä¿æŒåŸå§‹å­—ç¬¦ä¸²æ ¼å¼ä»¥æ”¯æŒå¤šä¸ªID
    server = trans.get('server', 'openai')
    old_text = text['text']
    md5_key = md5_encryption(
        str(api_key) + str(api_url) + str(old_text) + str(prompt) + str(backup_model) + str(
            model) + str(target_lang))

    # ============== ç™¾åº¦ç¿»è¯‘å¤„ç† ==============
    if server == 'baidu':
        try:
            if not text['complete']:
                content = baidu_translate(
                    text=old_text,
                    appid=app_id,
                    app_key=app_key,
                    from_lang='auto',
                    to_lang=target_lang,
                    use_term_base=comparison_id == 1  # ä½¿ç”¨æœ¯è¯­åº“
                )
                text['count'] = count_text(text['text'])
                if check_translated(content):
                    text['text'] = content  # ç™¾åº¦ç¿»è¯‘æ— éœ€è¿‡æ»¤<think>æ ‡ç­¾
                text['complete'] = True
        except Exception as e:
            logging.error(f"ç™¾åº¦ç¿»è¯‘é”™è¯¯: {str(e)}")
            if "retry" not in text:
                text["retry"] = 0
            text["retry"] += 1
            if text["retry"] <= 3:
                time.sleep(5)
                logging.info('ç™¾åº¦ç¿»è¯‘å‡ºé”™ï¼Œæ­£åœ¨é‡è¯•ï¼')
                return get(trans, event, texts, index)  # é‡æ–°å°è¯•
            text['complete'] = True

    # ============== AIç¿»è¯‘å¤„ç† ==============
    elif server == 'openai' or server == 'doc2x' or server == 'qwen':
        try:
            # mredis.set("threading_count",threading_num+1)
            # å‰ç«¯å·²ç›´æ¥ä¼ å…¥è‹±æ–‡åï¼ˆEnglish Nameï¼‰ï¼Œç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€æ˜ å°„
            # target_lang å·²ç»æ˜¯è‹±æ–‡å…¨æ‹¼æ ¼å¼ï¼ˆå¦‚ "English", "Chinese"ï¼‰ï¼Œç›´æ¥ä¼ ç»™API

            # è·å–æœ¯è¯­åº“å†…å®¹å¹¶è½¬æ¢ä¸ºtm_listæ ¼å¼ï¼ˆä»…å½“ä½¿ç”¨åƒé—®æ¨¡å‹ä¸”æœ‰æœ¯è¯­åº“æ—¶ï¼‰
            tm_list = None
            if model == 'qwen-mt-plus' and comparison_id:
                # æ£€æŸ¥æ˜¯å¦æœ‰é¢„ç­›é€‰çš„æœ¯è¯­åº“ï¼ˆæ¥è‡ªOkapiTranslationServiceï¼‰
                filtered_terms = trans.get('filtered_terms')
                if filtered_terms:
                    # ä½¿ç”¨é¢„ç­›é€‰çš„æœ¯è¯­åº“
                    # logging.info(f"ä½¿ç”¨é¢„ç­›é€‰çš„æœ¯è¯­åº“ï¼Œé•¿åº¦: {len(filtered_terms)}")
                    tm_list = []
                    for line in filtered_terms.split('\n'):
                        if ':' in line:
                            source, target = line.split(':', 1)
                            tm_list.append({
                                "source": source.strip(),
                                "target": target.strip()
                            })
                    # logging.info(f"é¢„ç­›é€‰æœ¯è¯­åº“å¤„ç†å®Œæˆï¼Œå…± {len(tm_list)} æ¡æœ¯è¯­")
                else:
                    # æ£€æŸ¥æ˜¯å¦æœ‰é¢„åŠ è½½çš„æœ¯è¯­åº“
                    preloaded_terms = trans.get('preloaded_terms')
                    if preloaded_terms:
                        # ä½¿ç”¨é¢„åŠ è½½çš„æœ¯è¯­åº“è¿›è¡Œç­›é€‰
                        try:
                            from .term_filter import optimize_terms_for_api
                            
                            # è®°å½•æœ¯è¯­åº“å¤„ç†å¼€å§‹æ—¶é—´
                            term_start_time = time.time()
                            comparison_id = trans.get('comparison_id')
                            filtered_terms = optimize_terms_for_api(old_text, preloaded_terms, max_terms=10, comparison_id=str(comparison_id) if comparison_id else None)
                            term_end_time = time.time()
                            term_duration = term_end_time - term_start_time
                            
                            logging.info(f"ğŸ“š æœ¯è¯­åº“ç­›é€‰ç”¨æ—¶: {term_duration:.3f}ç§’, æ‰¾åˆ°æœ¯è¯­æ•°: {len(filtered_terms) if filtered_terms else 0}")
                            
                            if filtered_terms:
                                # è½¬æ¢ä¸ºtm_listæ ¼å¼
                                tm_list = []
                                for term in filtered_terms:
                                    tm_list.append({
                                        "source": term['source'],
                                        "target": term['target']
                                    })
                            else:
                                logging.info("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æœ¯è¯­")
                                tm_list = []
                                
                        except Exception as e:
                            logging.error(f"é¢„åŠ è½½æœ¯è¯­åº“ç­›é€‰å¤±è´¥: {str(e)}")
                            tm_list = []
                    else:
                        # æ²¡æœ‰é¢„åŠ è½½çš„æœ¯è¯­åº“ï¼Œä½¿ç”¨åŸæœ‰çš„ç­›é€‰é€»è¾‘
                        try:
                            # å¯¼å…¥æœ¯è¯­ç­›é€‰æ¨¡å—
                            from .main import get_filtered_terms_for_text
                            
                            # ä½¿ç”¨æœ¯è¯­ç­›é€‰åŠŸèƒ½ï¼Œæ ¹æ®å½“å‰æ–‡æœ¬å†…å®¹ç­›é€‰ç›¸å…³æœ¯è¯­
                            # è®°å½•æœ¯è¯­åº“å¤„ç†å¼€å§‹æ—¶é—´
                            term_start_time = time.time()
                            filtered_terms_str = get_filtered_terms_for_text(old_text, comparison_id, max_terms=10)
                            term_end_time = time.time()
                            term_duration = term_end_time - term_start_time
                            
                            logging.info(f"ğŸ“š æœ¯è¯­åº“å¤„ç†ç”¨æ—¶: {term_duration:.3f}ç§’, æ‰¾åˆ°æœ¯è¯­æ•°: {len(filtered_terms_str.split(chr(10))) if filtered_terms_str else 0}")
                            
                            if filtered_terms_str:
                                # å°†ç­›é€‰åçš„æœ¯è¯­å­—ç¬¦ä¸²è½¬æ¢ä¸ºtm_listæ ¼å¼
                                tm_list = []
                                for line in filtered_terms_str.split('\n'):
                                    if ':' in line:
                                        source, target = line.split(':', 1)
                                        tm_list.append({
                                            "source": source.strip(),
                                            "target": target.strip()
                                        })
                                
                                # logging.info(f"æœ¯è¯­ç­›é€‰å®Œæˆ: {len(tm_list)} ä¸ªæœ¯è¯­")
                            else:
                                logging.info("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æœ¯è¯­")
                                tm_list = []
                                
                        except Exception as e:
                            logging.error(f"æœ¯è¯­ç­›é€‰å¤±è´¥: {str(e)}")
                            # å¦‚æœç­›é€‰å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹é€»è¾‘
                            logging.info("å›é€€åˆ°åŸå§‹æœ¯è¯­åº“å¤„ç†é€»è¾‘")
                            
                        # æ”¯æŒå¤šä¸ªæœ¯è¯­åº“IDï¼Œé€—å·åˆ†éš”
                        comparison_ids = [int(id.strip()) for id in str(comparison_id).split(',') if id.strip().isdigit()]
                        
                        if comparison_ids:
                            all_terms = {}  # ç”¨äºå»é‡çš„å­—å…¸
                            
                            for comp_id in comparison_ids:
                                try:
                                    # ä» comparison_sub è¡¨è·å–æœ¯è¯­æ•°æ®
                                    terms = db.get_all("select original, comparison_text from comparison_sub where comparison_sub_id=%s", comp_id)
                                    
                                    if terms and isinstance(terms, list) and len(terms) > 0:
                                        for term in terms:
                                            if term and isinstance(term, dict) and term.get('original') and term.get('comparison_text'):
                                                source = term['original'].strip()
                                                target = term['comparison_text'].strip()
                                                if source not in all_terms:
                                                    all_terms[source] = target
                                    else:
                                        logging.warning(f"æœ¯è¯­åº“ {comp_id} æœªæ‰¾åˆ°æœ¯è¯­æ•°æ®")
                                        
                                except Exception as e:
                                    logging.error(f"æŸ¥è¯¢æœ¯è¯­åº“ {comp_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                                    continue
                            
                            # è½¬æ¢ä¸ºtm_listæ ¼å¼ï¼ˆéœ€è¦ç­›é€‰ï¼Œé¿å…ä¼ å…¥è¿‡å¤šæœ¯è¯­å¯¼è‡´è¶…æ—¶ï¼‰
                            if all_terms:
                                # ä½¿ç”¨æœ¯è¯­ç­›é€‰åŠŸèƒ½ï¼Œåªé€‰æ‹©æœ€ç›¸å…³çš„å°‘é‡æœ¯è¯­
                                try:
                                    from .term_filter import optimize_terms_for_api
                                    
                                    # è®°å½•æœ¯è¯­åº“å¤„ç†å¼€å§‹æ—¶é—´
                                    term_start_time = time.time()
                                    # ç»Ÿä¸€é™åˆ¶ï¼šæœ€å¤š10ä¸ªæœ¯è¯­ï¼ˆé¿å…APIè¶…æ—¶ï¼‰
                                    max_terms = 10
                                    
                                    filtered_terms = optimize_terms_for_api(old_text, all_terms, max_terms=max_terms, comparison_id=str(comparison_id) if comparison_id else None)
                                    term_end_time = time.time()
                                    term_duration = term_end_time - term_start_time
                                    
                                    if filtered_terms:
                                        logging.info(f"ğŸ“š æœ¯è¯­åº“ç­›é€‰ç”¨æ—¶: {term_duration:.3f}ç§’, åŸå§‹: {len(all_terms)}æ¡, ç­›é€‰å: {len(filtered_terms)}æ¡")
                                        # è½¬æ¢ä¸ºtm_listæ ¼å¼
                                        tm_list = []
                                        for term in filtered_terms:
                                            tm_list.append({
                                                "source": term['source'],
                                                "target": term['target']
                                            })
                                    else:
                                        logging.info("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æœ¯è¯­")
                                        tm_list = []
                                        
                                except Exception as e:
                                    logging.error(f"æœ¯è¯­ç­›é€‰å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ°åŸå§‹é€»è¾‘ï¼ˆä½†é™åˆ¶æ•°é‡ï¼‰")
                                    # å¦‚æœç­›é€‰å¤±è´¥ï¼Œè‡³å°‘é™åˆ¶æ•°é‡ï¼Œé¿å…ä¼ å…¥è¿‡å¤šæœ¯è¯­
                                    tm_list = []
                                    term_count = 0
                                    max_fallback_terms = 10  # å›é€€æ—¶æœ€å¤š10ä¸ªæœ¯è¯­ï¼ˆç»Ÿä¸€é™åˆ¶ï¼‰
                                    for source, target in all_terms.items():
                                        if term_count >= max_fallback_terms:
                                            break
                                        tm_list.append({
                                            "source": source,
                                            "target": target
                                        })
                                        term_count += 1
                                    logging.warning(f"âš ï¸ ä½¿ç”¨å›é€€é€»è¾‘ï¼Œé™åˆ¶ä¸ºå‰{len(tm_list)}ä¸ªæœ¯è¯­")
                                
                                # logging.info(f"åŸå§‹æœ¯è¯­åº“å¤„ç†å®Œæˆï¼Œå…± {len(tm_list)} æ¡æœ¯è¯­")
                        else:
                            logging.warning(f"ä»»åŠ¡ {translate_id} æœ¯è¯­è¡¨IDæ ¼å¼æ— æ•ˆ: {comparison_id}")
            else:
                logging.info(f"ä»»åŠ¡ {translate_id} æœªä½¿ç”¨æœ¯è¯­åº“ï¼Œmodel: {model}, comparison_id: {comparison_id}")

            if text['complete'] == False:
                content = ''
                # ç‰¹åˆ«å¤„ç†PDFç±»å‹

                # elif extension == ".pdf":
                #     return handle_pdf(trans, event, texts, index)
                # elif extension == ".pdf":
                #     if text['type'] == "text":
                #         content = translate_html(text['text'], target_lang, model, prompt)
                #         time.sleep(0.1)
                #     else:
                #         content = get_content_by_image(text['text'], target_lang)
                #         time.sleep(0.1)
                # ---------------è¿™é‡Œå®ç°ä¸åŒæ¨¡å‹æ ¼å¼çš„è¯·æ±‚--------------
                if extension == ".md":
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼å…ƒç´ ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡ç¿»è¯‘
                    element_type = text.get('element_type', 'unknown')
                    preserve = text.get('preserve', False)
                    logging.info(f"MDå…ƒç´ æ£€æŸ¥: element_type={element_type}, preserve={preserve}, content={repr(text['text'][:50])}")
                    
                    if preserve or element_type == 'table_separator':
                        content = text['text']  # ç›´æ¥ä½¿ç”¨åŸæ–‡ï¼Œä¸ç¿»è¯‘
                        logging.info(f"âœ… è·³è¿‡è¡¨æ ¼åˆ†éš”è¡Œç¿»è¯‘: {element_type}, å†…å®¹: {repr(text['text'])}")
                    elif model == 'qwen-mt-plus':
                        logging.info(f"ğŸ” è°ƒç”¨ qwen_translate (MDæ–‡ä»¶): texts={texts is not None}, index={index}")
                        translate_id_val = trans.get('id')
                        customer_id_val = trans.get('customer_id')
                        tenant_id_val = trans.get('tenant_id')
                        uuid_val = trans.get('uuid')
                        logging.debug(f"ğŸ” Tokenè®°å½•å‚æ•°: translate_id={translate_id_val}, customer_id={customer_id_val}, tenant_id={tenant_id_val}, uuid={uuid_val}")
                        content = qwen_translate(
                            text['text'], target_lang, source_lang="auto", 
                            tm_list=tm_list, prompt=prompt, prompt_id=trans.get('prompt_id'), 
                            texts=texts, index=index, tenant_id=tenant_id_val, 
                            api_key=trans.get('api_key'),
                            translate_id=translate_id_val,
                            customer_id=customer_id_val,
                            uuid=uuid_val
                        )
                    else:
                        content = req(text['text'], target_lang, model, prompt, True)
                else:
                    # ç»Ÿä¸€å¤„ç†ï¼šåªè¦æ˜¯qwen-mt-plusæ¨¡å‹ï¼Œéƒ½ä½¿ç”¨å¸¦ä¸Šä¸‹æ–‡çš„ç¿»è¯‘
                    if model == 'qwen-mt-plus':
                        logging.info(f"ğŸ” è°ƒç”¨ qwen_translate (ç»Ÿä¸€å¤„ç†): texts={texts is not None}, index={index}")
                        translate_id_val = trans.get('id')
                        customer_id_val = trans.get('customer_id')
                        tenant_id_val = trans.get('tenant_id')
                        uuid_val = trans.get('uuid')
                        logging.debug(f"ğŸ” Tokenè®°å½•å‚æ•°: translate_id={translate_id_val}, customer_id={customer_id_val}, tenant_id={tenant_id_val}, uuid={uuid_val}")
                        content = qwen_translate(
                            text['text'], target_lang, source_lang="auto", 
                            tm_list=tm_list, prompt=prompt, prompt_id=trans.get('prompt_id'), 
                            texts=texts, index=index, tenant_id=tenant_id_val, 
                            api_key=trans.get('api_key'),
                            translate_id=translate_id_val,
                            customer_id=customer_id_val,
                            uuid=uuid_val
                        )
                    else:
                        # å…¶ä»–æ¨¡å‹ï¼šæ ¹æ®æ˜¯å¦æœ‰ä¸Šä¸‹æ–‡é€‰æ‹©ç¿»è¯‘æ–¹å¼
                        if 'context_text' in text and text.get('context_type') == 'body':
                            # æ­£æ–‡æ®µè½ï¼šä½¿ç”¨å¸¦ä¸Šä¸‹æ–‡çš„æ–‡æœ¬
                            content = req(text['context_text'], target_lang, model, prompt, False)
                        else:
                            # å…¶ä»–å†…å®¹ï¼šä½¿ç”¨åŸå§‹æ–‡æœ¬
                            content = req(text['text'], target_lang, model, prompt, False)
                    # print("content", text['content'])
                text['count'] = count_text(text['text'])
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯data_inspection_failedå¯¼è‡´çš„ç©ºå­—ç¬¦ä¸²
                if content == "" and model == 'qwen-mt-plus':
                    # data_inspection_failedé”™è¯¯ï¼Œç›´æ¥è®¾ç½®ä¸ºå®ŒæˆçŠ¶æ€ï¼Œä¸è¿›è¡Œé‡è¯•
                    logging.warning(f"å†…å®¹æ£€æŸ¥å¤±è´¥ï¼Œè·³è¿‡æ­¤å†…å®¹: {text['text'][:50]}...")
                    text['text'] = ""  # è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²
                    text['complete'] = True
                elif check_translated(content):
                    # è¿‡æ»¤deepseekæ€è€ƒè¿‡ç¨‹
                    cleaned_content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL)
                    # æ¸…ç†ä¸Šä¸‹æ–‡æ ‡è®°
                    # cleaned_content = clean_translation_result(cleaned_content)
                    text['text'] = cleaned_content
                    text['complete'] = True
                else:
                    # ç¿»è¯‘å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­å¤„ç†
                    logging.warning(f"ç¿»è¯‘å¤±è´¥ï¼Œä¿ç•™åŸæ–‡: {text['text'][:50]}...")
                    text['complete'] = True
        except openai.AuthenticationError as e:
            # set_threading_num(mredis)
            return use_backup_model(trans, event, texts, index, "openaiå¯†é’¥æˆ–ä»¤ç‰Œæ— æ•ˆ")
        except openai.APIConnectionError as e:
            # set_threading_num(mredis)
            return use_backup_model(trans, event, texts, index,
                                    "è¯·æ±‚æ— æ³•ä¸openaiæœåŠ¡å™¨æˆ–å»ºç«‹å®‰å…¨è¿æ¥")
        except openai.PermissionDeniedError as e:
            # set_threading_num(mredis)
            texts[index] = text
            # return use_backup_model(trans, event, texts, index, "ä»¤ç‰Œé¢åº¦ä¸è¶³")
        except openai.RateLimitError as e:
            # set_threading_num(mredis)
            if "retry" not in text:
                trans['model'] = backup_model
                trans['backup_model'] = model
                time.sleep(1)
                logging.warning("è®¿é—®é€Ÿç‡è¾¾åˆ°é™åˆ¶,äº¤æ¢å¤‡ç”¨æ¨¡å‹ä¸æ¨¡å‹é‡æ–°é‡è¯•")
                get(trans, event, texts, index)
            else:
                return use_backup_model(trans, event, texts, index,
                                        "è®¿é—®é€Ÿç‡è¾¾åˆ°é™åˆ¶,10åˆ†é’Ÿåå†è¯•" + str(text['text']))
        except openai.InternalServerError as e:
            # set_threading_num(mredis)
            if "retry" not in text:
                trans['model'] = backup_model
                trans['backup_model'] = model
                time.sleep(1)
                logging.warning("å½“å‰åˆ†ç»„ä¸Šæ¸¸è´Ÿè½½å·²é¥±å’Œï¼Œäº¤æ¢å¤‡ç”¨æ¨¡å‹ä¸æ¨¡å‹é‡æ–°é‡è¯•")
                get(trans, event, texts, index)
            else:
                return use_backup_model(trans, event, texts, index,
                                        "å½“å‰åˆ†ç»„ä¸Šæ¸¸è´Ÿè½½å·²é¥±å’Œï¼Œè¯·ç¨åå†è¯•" + str(text['text']))
        except openai.APIStatusError as e:
            # set_threading_num(mredis)
            return use_backup_model(trans, event, texts, index, e.response)
        except Exception as e:
            # set_threading_num(mredis)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            line_number = exc_traceback.tb_lineno  # å¼‚å¸¸æŠ›å‡ºçš„å…·ä½“è¡Œå·
            logging.error(f"Error occurred on line: {line_number}")
            logging.error(f"Error details: {e}")
            if "retry" not in text:
                text["retry"] = 0
            text["retry"] += 1
            if text["retry"] <= 3:
                trans['model'] = backup_model
                trans['backup_model'] = model
                logging.warning("å½“å‰æ¨¡å‹æ‰§è¡Œå¼‚å¸¸ï¼Œäº¤æ¢å¤‡ç”¨æ¨¡å‹ä¸æ¨¡å‹é‡æ–°é‡è¯•")
                time.sleep(1)
                get(trans, event, texts, index)
                return
            else:
                text['complete'] = True
            # traceback.print_exc()
            # print("translate error")
    
    texts[index] = text
    # print(text)
    if not event.is_set():
        # å¯¹äºWordæ–‡æ¡£ç¿»è¯‘å’Œå¤§PDFç¿»è¯‘ï¼Œä¸è°ƒç”¨processå‡½æ•°ï¼Œå› ä¸ºå®ƒä»¬æœ‰è‡ªå·±çš„è¿›åº¦æ›´æ–°æœºåˆ¶
        extension = trans.get('extension', '').lower()
        is_large_pdf = trans.get('is_large_pdf', False)  # æ£€æŸ¥æ˜¯å¦ä¸ºå¤§PDFç¿»è¯‘
        if extension not in ['.docx', '.doc'] and not is_large_pdf:
            process(texts, translate_id)
    # set_threading_num(mredis)
    return True  # è¿”å›ç»“æœè€Œä¸æ˜¯exit(0)


def get11(trans, event, texts, index):
    if event.is_set():
        exit(0)
    # æ¢å¤çº¿ç¨‹æ•°ä¸º30ï¼Œæé«˜ç¿»è¯‘æ•ˆç‡
    max_threads = 30
    # mredis=rediscon.get_conn()
    # threading_num=get_threading_num(mredis)
    # while threading_num>=max_threads:
    #    time.sleep(1)
    # print('transé…ç½®é¡¹', trans)
    translate_id = trans['id']
    target_lang = trans['lang']
    model = trans['model']
    backup_model = trans['backup_model']
    prompt = trans['prompt']
    extension = trans['extension'].lower()
    text = texts[index]
    api_key = trans['api_key']
    api_url = trans['api_url']
    old_text = text['text']
    md5_key = md5_encryption(
        str(api_key) + str(api_url) + str(old_text) + str(prompt) + str(backup_model) + str(
            model) + str(target_lang))
    try:
        # mredis.set("threading_count",threading_num+1)
        if text['complete'] == False:
            content = ''
            # ç‰¹åˆ«å¤„ç†PDFç±»å‹

            # elif extension == ".pdf":
            #     return handle_pdf(trans, event, texts, index)
            # elif extension == ".pdf":
            #     if text['type'] == "text":
            #         content = translate_html(text['text'], target_lang, model, prompt)
            #         time.sleep(0.1)
            #     else:
            #         content = get_content_by_image(text['text'], target_lang)
            #         time.sleep(0.1)
            # ---------------è¿™é‡Œå®ç°ä¸åŒæ¨¡å‹æ ¼å¼çš„è¯·æ±‚--------------
            if extension == ".md":
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼å…ƒç´ ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡ç¿»è¯‘
                element_type = text.get('element_type', 'unknown')
                preserve = text.get('preserve', False)
                logging.info(f"MDå…ƒç´ æ£€æŸ¥: element_type={element_type}, preserve={preserve}, content={repr(text['text'][:50])}")
                
                if preserve or element_type == 'table_separator':
                    content = text['text']  # ç›´æ¥ä½¿ç”¨åŸæ–‡ï¼Œä¸ç¿»è¯‘
                    logging.info(f"âœ… è·³è¿‡è¡¨æ ¼åˆ†éš”è¡Œç¿»è¯‘: {element_type}, å†…å®¹: {repr(text['text'])}")
                else:
                    content = req(text['text'], target_lang, model, prompt, True)
            else:
                content = req(text['text'], target_lang, model, prompt, False)
                # print("content", text['content'])
            text['count'] = count_text(text['text'])
            if check_translated(content):
                # è¿‡æ»¤deepseekæ€è€ƒè¿‡ç¨‹
                text['text'] = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL)
            text['complete'] = True
    except openai.AuthenticationError as e:
        # set_threading_num(mredis)
        return use_backup_model(trans, event, texts, index, "openaiå¯†é’¥æˆ–ä»¤ç‰Œæ— æ•ˆ")
    except openai.APIConnectionError as e:
        # set_threading_num(mredis)
        return use_backup_model(trans, event, texts, index, "è¯·æ±‚æ— æ³•ä¸openaiæœåŠ¡å™¨æˆ–å»ºç«‹å®‰å…¨è¿æ¥")
    except openai.PermissionDeniedError as e:
        # set_threading_num(mredis)
        texts[index] = text
        # return use_backup_model(trans, event, texts, index, "ä»¤ç‰Œé¢åº¦ä¸è¶³")
    except openai.RateLimitError as e:
        # set_threading_num(mredis)
        if "retry" not in text:
            trans['model'] = backup_model
            trans['backup_model'] = model
            time.sleep(1)
            logging.warning("è®¿é—®é€Ÿç‡è¾¾åˆ°é™åˆ¶,äº¤æ¢å¤‡ç”¨æ¨¡å‹ä¸æ¨¡å‹é‡æ–°é‡è¯•")
            get(trans, event, texts, index)
        else:
            return use_backup_model(trans, event, texts, index,
                                    "è®¿é—®é€Ÿç‡è¾¾åˆ°é™åˆ¶,10åˆ†é’Ÿåå†è¯•" + str(text['text']))
    except openai.InternalServerError as e:
        # set_threading_num(mredis)
        if "retry" not in text:
            trans['model'] = backup_model
            trans['backup_model'] = model
            time.sleep(1)
            logging.warning("å½“å‰åˆ†ç»„ä¸Šæ¸¸è´Ÿè½½å·²é¥±å’Œï¼Œäº¤æ¢å¤‡ç”¨æ¨¡å‹ä¸æ¨¡å‹é‡æ–°é‡è¯•")
            get(trans, event, texts, index)
        else:
            return use_backup_model(trans, event, texts, index,
                                    "å½“å‰åˆ†ç»„ä¸Šæ¸¸è´Ÿè½½å·²é¥±å’Œï¼Œè¯·ç¨åå†è¯•" + str(text['text']))
    except openai.APIStatusError as e:
        # set_threading_num(mredis)
        return use_backup_model(trans, event, texts, index, e.response)
    except Exception as e:
        # set_threading_num(mredis)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        line_number = exc_traceback.tb_lineno  # å¼‚å¸¸æŠ›å‡ºçš„å…·ä½“è¡Œå·
        logging.error(f"Error occurred on line: {line_number}")
        logging.error(f"Error details: {e}")
        if "retry" not in text:
            text["retry"] = 0
        text["retry"] += 1
        if text["retry"] <= 3:
            trans['model'] = backup_model
            trans['backup_model'] = model
            logging.warning("å½“å‰æ¨¡å‹æ‰§è¡Œå¼‚å¸¸ï¼Œäº¤æ¢å¤‡ç”¨æ¨¡å‹ä¸æ¨¡å‹é‡æ–°é‡è¯•")
            time.sleep(1)
            get(trans, event, texts, index)
            return
        else:
            text['complete'] = True
        # traceback.print_exc()
        # print("translate error")
    texts[index] = text
    # print(text)
    if not event.is_set():
        process(texts, translate_id)
    # set_threading_num(mredis)
    exit(0)


def handle_pdf(trans, event, texts, index):
    try:
        from . import pdf_parser
        success = pdf_parser.start(trans)
        if success:
            texts[index]['complete'] = True
        else:
            return use_backup_model(trans, event, texts, index, "PDFè§£æå¤±è´¥")
    except Exception as e:
        return use_backup_model(trans, event, texts, index, str(e))



# def get_threading_num(mredis):
#    threading_count=mredis.get("threading_count")
#    if threading_count is None or threading_count=="" or int(threading_count)<0:
#        threading_num=0
#    else:
#        threading_num=int(threading_count)
#    return threading_num
# def set_threading_num(mredis):
#    threading_count=mredis.get("threading_count")
#    if threading_count is None or threading_count=="" or int(threading_count)<1:
#        mredis.set("threading_count",0)
#    else:
#        threading_num=int(threading_count)
#        mredis.set("threading_count",threading_num-1)

def md5_encryption(data):
    md5 = hashlib.md5(data.encode('utf-8'))  # åˆ›å»ºä¸€ä¸ªmd5å¯¹è±¡
    return md5.hexdigest()  # è¿”å›åŠ å¯†åçš„åå…­è¿›åˆ¶å­—ç¬¦ä¸²


def req(text, target_lang, model, prompt, ext):
    # åˆ¤æ–­æ˜¯å¦æ˜¯mdæ ¼å¼
    if ext == True:
        # å¦‚æœæ˜¯ md æ ¼å¼ï¼Œè¿½åŠ æç¤ºæ–‡æœ¬
        prompt += "ã€‚ è¯·å¸®åŠ©æˆ‘ç¿»è¯‘ä»¥ä¸‹ Markdown æ–‡ä»¶ä¸­çš„å†…å®¹ã€‚è¯·æ³¨æ„ï¼Œæ‚¨åªéœ€ç¿»è¯‘æ–‡æœ¬éƒ¨åˆ†ï¼Œè€Œä¸åº”æ›´æ”¹ä»»ä½• Markdown æ ‡ç­¾æˆ–æ ¼å¼ã€‚ä¿æŒåŸæœ‰çš„æ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ã€é“¾æ¥å’Œå…¶ä»– Markdown æ ‡ç­¾çš„å®Œæ•´æ€§ã€‚"
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸Šä¸‹æ–‡æ ‡è®°
    if '[å‰æ–‡:' in text or '[åæ–‡:' in text:
        # æœ‰ä¸Šä¸‹æ–‡çš„æƒ…å†µï¼šå¢å¼ºæç¤ºè¯
        enhanced_prompt = f"""
        {prompt}
        
        ä¸¥æ ¼æŒ‡ä»¤ï¼š
        1. åªç¿»è¯‘æ–¹æ‹¬å·å¤–çš„æ–‡æœ¬ï¼Œä¸è¦ç¿»è¯‘æ–¹æ‹¬å·å†…çš„ä»»ä½•å†…å®¹
        2. çº¯å¤§å†™è‹±æ–‡çš„ä¸ºä¸“æœ‰åè¯ï¼Œä¸è¦ç¿»è¯‘
        3. è¯·ç»“åˆä¸Šä¸‹æ–‡çš„è¯­ä¹‰è¯­å¢ƒè¿›è¡Œç¿»è¯‘
        4. ä¸è¦è¾“å‡ºä»»ä½•æ–¹æ‹¬å·æ ‡è®°
        5. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€è¯´æ˜æˆ–æ€è€ƒè¿‡ç¨‹
        6. åªè¿”å›çº¯ç¿»è¯‘ç»“æœ
        7. ç›®æ ‡è¯­è¨€ä¸º{target_lang}
        
        ç¤ºä¾‹ï¼š
        è¾“å…¥ï¼š"[å‰æ–‡: Hello] World [åæ–‡: Program]"
        è¾“å‡ºï¼š"ä¸–ç•Œ"
        
        è¾“å…¥ï¼š"[å‰æ–‡: ä½ å¥½] ä¸–ç•Œ [åæ–‡: ç¨‹åº]"
        è¾“å‡ºï¼š"world"
        
        è®°ä½ï¼šæ–¹æ‹¬å·å†…çš„å†…å®¹æ˜¯ä¸Šä¸‹æ–‡å‚è€ƒç”¨äºç¿»è¯‘å‰åçš„è¯­ä¹‰è¯­å¢ƒï¼Œä¸éœ€è¦ç¿»è¯‘å’Œè¾“å‡ºï¼
        """
    else:
        # æ²¡æœ‰ä¸Šä¸‹æ–‡çš„æƒ…å†µï¼šä½¿ç”¨åŸå§‹æç¤ºè¯
        enhanced_prompt = prompt
    
    # æ„å»º message
    message = [
        {"role": "system", "content": enhanced_prompt.replace("{target_lang}", target_lang)},
        {"role": "user", "content": text}
    ]
    # print(openai.base_url)
    logging.info(message)
    # ç¦ç”¨ OpenAI çš„æ—¥å¿—è¾“å‡º
    logging.getLogger("openai").setLevel(logging.WARNING)
    # ç¦ç”¨ httpx çš„æ—¥å¿—è¾“å‡º
    logging.getLogger("httpx").setLevel(logging.WARNING)
    response = openai.chat.completions.create(
        model=model,  # ä½¿ç”¨GPT-3.5ç‰ˆæœ¬
        messages=message,
        temperature=0.8
    )
    # for choices in response.choices:
    #     print(choices.message.content)
    content = response.choices[0].message.content
    # print(content)
    return content


def translate_html(html, target_lang, model, prompt):
    message = [
        {"role": "system",
         "content": "æŠŠä¸‹é¢çš„htmlç¿»è¯‘æˆ{},åªè¿”å›ç¿»è¯‘åçš„å†…å®¹".format(target_lang)},
        {"role": "user", "content": html}
    ]
    # print(openai.base_url)
    response = openai.chat.completions.create(
        model=model,
        messages=message
    )
    # for choices in response.choices:
    #     print(choices.message.content)
    content = response.choices[0].message.content
    return content


def get_content_by_image(base64_image, target_lang):
    # print(image_path)
    # file_object = openai.files.create(file=Path(image_path), purpose="è¿™æ˜¯ä¸€å¼ å›¾ç‰‡")
    # print(file_object)
    message = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå›¾ç‰‡ORCè¯†åˆ«ä¸“å®¶"},
        {"role": "user", "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": base64_image
                }
            },
            {
                "type": "text",
                # "text": "è¯»å–å›¾ç‰‡é“¾æ¥å¹¶æå–å…¶ä¸­çš„æ–‡æœ¬æ•°æ®,åªè¿”å›è¯†åˆ«åçš„æ•°æ®ï¼Œå°†æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡,å¹¶æŒ‰ç…§å›¾ç‰‡ä¸­çš„æ–‡å­—å¸ƒå±€è¿”å›htmlã€‚åªåŒ…å«body(ä¸åŒ…å«bodyæœ¬èº«)éƒ¨åˆ†",
                # "text": f"æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—æ•°æ®ï¼Œå°†æå–çš„æ–‡æœ¬ç¿»è¯‘æˆ{target_lang},åªè¿”å›åŸå§‹æ–‡æœ¬å’Œç¿»è¯‘ç»“æœ",
                "text": f"æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—æ•°æ®,å°†æå–çš„æ–‡æœ¬ç¿»è¯‘æˆ{target_lang},åªè¿”å›ç¿»è¯‘ç»“æœ",
            }
        ]}
    ]
    # print(message)
    # print(openai.base_url)
    response = openai.chat.completions.create(
        model="gpt-4o",  # ä½¿ç”¨GPT-3.5ç‰ˆæœ¬
        messages=message
    )
    # for choices in response.choices:
    #     print(choices.message.content)
    content = response.choices[0].message.content
    # return content
    # print(''.join(map(lambda x: f'<p>{x}</p>',content.split("\n"))))
    return ''.join(map(lambda x: f'<p>{x}</p>', content.split("\n")))


def check(model):
    try:
        message = [
            {"role": "system", "content": "ä½ é€šæ™“ä¸–ç•Œæ‰€æœ‰è¯­è¨€,å¯ä»¥ç”¨æ¥ä»ä¸€ç§è¯­è¨€ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€"},
            {"role": "user", "content": "ä½ ç°åœ¨èƒ½ç¿»è¯‘å—ï¼Ÿ"}
        ]
        response = openai.chat.completions.create(
            model=model,
            messages=message
        )
        return "OK"
    except openai.AuthenticationError as e:
        return "openaiå¯†é’¥æˆ–ä»¤ç‰Œæ— æ•ˆ"
    except openai.APIConnectionError as e:
        return "è¯·æ±‚æ— æ³•ä¸openaiæœåŠ¡å™¨æˆ–å»ºç«‹å®‰å…¨è¿æ¥"
    except openai.PermissionDeniedError as e:
        return "ä»¤ç‰Œé¢åº¦ä¸è¶³"
    except openai.RateLimitError as e:
        return "è®¿é—®é€Ÿç‡è¾¾åˆ°é™åˆ¶,10åˆ†é’Ÿåå†è¯•"
    except openai.InternalServerError as e:
        return "å½“å‰åˆ†ç»„ä¸Šæ¸¸è´Ÿè½½å·²é¥±å’Œï¼Œè¯·ç¨åå†è¯•"
    except openai.APIStatusError as e:
        return e.response
    except Exception as e:
        return "å½“å‰æ— æ³•å®Œæˆç¿»è¯‘"


def process(texts, translate_id):
    total = 0
    complete = 0
    for text in texts:
        total += 1
        if text['complete']:
            complete += 1
    if total != complete:
        if (total != 0):
            process = format((complete / total) * 100, '.1f')
            db.execute("update translate set process=%s where id=%s", str(process), translate_id)


def complete(trans, text_count, spend_time):
    target_filesize = 1 #os.stat(trans['target_file']).st_size
    # ä½¿ç”¨Pythonæ—¶åŒºæ—¶é—´ï¼Œä¸start_atä¿æŒä¸€è‡´
    from datetime import datetime
    import pytz
    end_time = datetime.now(pytz.timezone('Asia/Shanghai'))  # ä½¿ç”¨ä¸œå…«åŒºæ—¶åŒºï¼Œä¸translate_service.pyä¿æŒä¸€è‡´
    
    # ç¡®ä¿target_filepathå­—æ®µè¢«æ­£ç¡®æ›´æ–°
    target_filepath = trans.get('target_file', '')
    
    db.execute(
        "update translate set status='done',end_at=%s,process=100,target_filesize=%s,word_count=%s,target_filepath=%s where id=%s",
        end_time, target_filesize, text_count, target_filepath, trans['id'])
    
    # æ±‡æ€»tokenä½¿ç”¨æƒ…å†µ
    try:
        from app.utils.token_recorder import aggregate_tokens_for_translate
        aggregate_tokens_for_translate(trans['id'])
    except Exception as e:
        logging.warning(f"âš ï¸ æ±‡æ€»tokenä½¿ç”¨å¤±è´¥: translate_id={trans['id']}, é”™è¯¯: {e}")


def error(translate_id, message):
    # ä½¿ç”¨Pythonæ—¶åŒºæ—¶é—´ï¼Œä¸start_atä¿æŒä¸€è‡´
    from datetime import datetime
    import pytz
    end_time = datetime.now(pytz.timezone('Asia/Shanghai'))  # ä½¿ç”¨ä¸œå…«åŒºæ—¶åŒºï¼Œä¸translate_service.pyä¿æŒä¸€è‡´
    
    db.execute(
        "update translate set failed_count=failed_count+1,status='failed',end_at=%s,failed_reason=%s where id=%s",
        end_time, message, translate_id)


def count_text(text):
    count = 0
    for char in text:
        if common.is_chinese(char):
            count += 1;
        elif char is None or char == " ":
            continue
        else:
            count += 0.5
    return count


def init_openai(url, key):
    openai.api_key = key
    if "v1" not in url:
        if url[-1] == "/":
            url += "v1/"
        else:
            url += "/v1/"
    openai.base_url = url


def check_translated(content):
    if content.startswith("Sorry, I cannot") or content.startswith(
            "I am sorry,") or content.startswith(
            "I'm sorry,") or content.startswith("Sorry, I can't") or content.startswith(
        "Sorry, I need more") or content.startswith("æŠ±æ­‰ï¼Œæ— æ³•") or content.startswith(
        "é”™è¯¯ï¼šæä¾›çš„æ–‡æœ¬") or content.startswith("æ— æ³•ç¿»è¯‘") or content.startswith(
        "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•") or content.startswith(
        "å¯¹ä¸èµ·ï¼Œæˆ‘æ— æ³•") or content.startswith("ã”æŒ‡ç¤ºã®å†…å®¹ã¯") or content.startswith(
        "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“") or content.startswith("ĞŸÑ€Ğ¾ÑÑ‚Ğ¸Ñ‚Ğµï¼Œ") or content.startswith(
        "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ,") or content.startswith("Lo siento,"):
        return False
    else:
        return True


# def get_model_tokens(model,content):
#     encoding=tiktoken.encoding_for_model(model)
#     return en(encoding.encode(content))

def use_backup_model(trans, event, texts, index, message):
    if trans['backup_model'] != None and trans['backup_model'] != "":
        trans['model'] = trans['backup_model']
        trans['backup_model'] = ""
        get(trans, event, texts, index)
    else:
        if not event.is_set():
            error(trans['id'], message)
            print(message)
        event.set()


def clean_translation_result(text):
    """æ¸…ç†ç¿»è¯‘ç»“æœï¼Œç§»é™¤ä¸Šä¸‹æ–‡æ ‡è®°"""
    import re
    
    # ç§»é™¤ä¸Šä¸‹æ–‡æ ‡è®°
    text = re.sub(r'\[å‰æ–‡:.*?\]', '', text)
    text = re.sub(r'\[åæ–‡:.*?\]', '', text)
    
    # ç§»é™¤å¯èƒ½çš„è§£é‡Šæ€§å†…å®¹
    text = re.sub(r'ç¿»è¯‘.*?[:ï¼š]\s*', '', text)
    text = re.sub(r'æ ¹æ®ä¸Šä¸‹æ–‡.*?[:ï¼š]\s*', '', text)
    text = re.sub(r'ç­”æ¡ˆæ˜¯.*?[:ï¼š]\s*', '', text)
    text = re.sub(r'ç»“æœ.*?[:ï¼š]\s*', '', text)
    text = re.sub(r'åº”è¯¥æ˜¯.*?[:ï¼š]\s*', '', text)
    text = re.sub(r'è¾“å‡º.*?[:ï¼š]\s*', '', text)
    text = re.sub(r'è¾“å…¥.*?[:ï¼š]\s*', '', text)
    
    # ç§»é™¤å¯èƒ½çš„æ€è€ƒè¿‡ç¨‹
    text = re.sub(r'è®©æˆ‘åˆ†æ.*?[:ï¼š]\s*', '', text)
    text = re.sub(r'æ ¹æ®.*?[:ï¼š]\s*', '', text)
    text = re.sub(r'è®°ä½.*?[:ï¼š]\s*', '', text)
    
    # æ¸…ç†å¤šä½™çš„ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()