# -*- coding: utf-8 -*-
"""
Okapi Framework é›†æˆæ¨¡å—

ä½¿ç”¨ Okapi Framework è¿›è¡Œ Word æ–‡æ¡£ç¿»è¯‘ï¼Œè§£å†³ run åˆ‡å‰²è¿‡ç»†çš„é—®é¢˜ã€‚
é€šè¿‡ XLIFF æ ¼å¼ä¿æŒå®Œæ•´æ ¼å¼å’Œä¸Šä¸‹æ–‡ã€‚

ä½œè€…ï¼šClaude
ç‰ˆæœ¬ï¼š1.0.0
"""

import os
import subprocess
import tempfile
import shutil
import logging
import time
import xml.etree.ElementTree as ET
from contextlib import contextmanager
from typing import Optional, Dict, Any, List
import zipfile
import re

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

def clean_xliff_for_translation(text: str) -> tuple[str, dict]:
    """
    æ¸…ç† XLIFF æ–‡æœ¬ä¸­çš„æ ¼å¼æ ‡ç­¾ï¼Œä¸ºç¿»è¯‘åšå‡†å¤‡
    åªæ¸…ç†æ˜æ˜¾çš„æ ¼å¼æ ‡ç­¾ï¼Œä¿ç•™Okapiçš„æ ‡å‡†XLIFFæ ‡ç­¾
    
    Args:
        text: åŒ…å«æ ¼å¼æ ‡ç­¾çš„XLIFFæ–‡æœ¬
        
    Returns:
        tuple: (æ¸…ç†åçš„æ–‡æœ¬, ä»£ç æ˜ å°„å­—å…¸)
    """
    # éœ€è¦æ¸…ç†çš„æ ‡ç­¾æ¨¡å¼ï¼ˆè¿™äº›æ˜¯Wordæ–‡æ¡£çš„åŸå§‹æ ¼å¼æ ‡ç­¾ï¼‰
    format_patterns = [
        r'<run\d+>', r'</run\d+>',  # Wordè¿è¡Œæ ‡ç­¾
        r'<tags\d+/>',              # Wordæ ¼å¼æ ‡ç­¾
        r'<lendof\d+\|>',           # æ®µè½ç»“æŸæ ‡ç­¾
        r'<[a-z]+\d*[^>]*/>',       # å…¶ä»–è‡ªé—­åˆæ ‡ç­¾
    ]
    
    # ä¿ç•™çš„Okapiæ ‡å‡†XLIFFæ ‡ç­¾ï¼ˆè¿™äº›ä¸åº”è¯¥è¢«æ¸…ç†ï¼‰
    # <bpt>, <ept>, <ph>, <g>, <x> ç­‰æ˜¯Okapiçš„æ ‡å‡†æ ‡ç­¾
    
    combined_pattern = '|'.join(format_patterns)
    matches = re.findall(combined_pattern, text)
    
    # åˆ›å»ºä»£ç æ˜ å°„
    code_mapping = {}
    clean_text = text
    
    for i, match in enumerate(matches):
        placeholder = f"__FORMAT_TAG_{i}__"
        code_mapping[placeholder] = match
        clean_text = clean_text.replace(match, placeholder, 1)
    
    logger.info(f"æ¸…ç†æ ¼å¼æ ‡ç­¾: {len(matches)} ä¸ªæ ‡ç­¾")
    logger.info(f"åŸæ–‡: {text[:100]}...")
    logger.info(f"æ¸…ç†å: {clean_text[:100]}...")
    
    return clean_text, code_mapping

def restore_xliff_tags(translated_text: str, code_mapping: dict) -> str:
    """
    æ¢å¤æ ¼å¼æ ‡ç­¾åˆ°ç¿»è¯‘åçš„æ–‡æœ¬ä¸­
    
    Args:
        translated_text: ç¿»è¯‘åçš„æ–‡æœ¬
        code_mapping: ä»£ç æ˜ å°„å­—å…¸
        
    Returns:
        str: æ¢å¤æ ¼å¼æ ‡ç­¾åçš„æ–‡æœ¬
    """
    restored_text = translated_text
    
    for placeholder, original_code in code_mapping.items():
        # å°†å ä½ç¬¦æ›¿æ¢å›åŸå§‹çš„æ ¼å¼æ ‡ç­¾
        restored_text = restored_text.replace(placeholder, original_code)
    
    logger.info(f"æ¢å¤æ ¼å¼æ ‡ç­¾: {len(code_mapping)} ä¸ªæ ‡ç­¾")
    logger.info(f"ç¿»è¯‘æ–‡æœ¬: {translated_text[:100]}...")
    logger.info(f"æ¢å¤å: {restored_text[:100]}...")
    
    return restored_text

class OkapiIntegrationError(Exception):
    """Okapi é›†æˆé”™è¯¯"""
    pass

class DockerOkapiIntegration:
    """Docker ç¯å¢ƒä¸­çš„ Okapi é›†æˆç±»"""
    
    def __init__(self, okapi_home: str = "/opt/okapi"):
        """
        åˆå§‹åŒ– Okapi é›†æˆ
        
        Args:
            okapi_home: Okapi å®‰è£…ç›®å½•
        """
        self.okapi_home = okapi_home
        
        # è·å– Tikal è„šæœ¬
        self.tikal_script = self._get_tikal_script()
        
        logger.info(f"Okapi é›†æˆåˆå§‹åŒ–å®Œæˆ: {okapi_home}")
        # è°ƒè¯•ï¼šæ˜¾ç¤ºæ‰€æœ‰æ‰¾åˆ°çš„æ–‡ä»¶
        self._debug_okapi_installation()
    
    def _debug_okapi_installation(self):
        """è°ƒè¯• Okapi å®‰è£…"""
        import glob
        
        logger.info(f"=== Okapi å®‰è£…è°ƒè¯•ä¿¡æ¯ ===")
        logger.info(f"Okapi ç›®å½•: {self.okapi_home}")
        logger.info(f"ç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists(self.okapi_home)}")
        
        if os.path.exists(self.okapi_home):
            # åˆ—å‡ºç›®å½•å†…å®¹
            try:
                dir_contents = os.listdir(self.okapi_home)
                logger.info(f"ç›®å½•å†…å®¹: {dir_contents}")
                
                # æŸ¥æ‰¾æ‰€æœ‰ JAR æ–‡ä»¶
                all_jars = glob.glob(os.path.join(self.okapi_home, "**", "*.jar"), recursive=True)
                logger.info(f"æ‰€æœ‰ JAR æ–‡ä»¶: {all_jars}")
                
                # æŸ¥æ‰¾æ‰€æœ‰å¯æ‰§è¡Œæ–‡ä»¶
                all_executables = glob.glob(os.path.join(self.okapi_home, "**", "*"), recursive=True)
                executables = [f for f in all_executables if os.path.isfile(f) and os.access(f, os.X_OK)]
                logger.info(f"å¯æ‰§è¡Œæ–‡ä»¶: {executables}")
                
            except Exception as e:
                logger.error(f"è¯»å–ç›®å½•å†…å®¹å¤±è´¥: {e}")
        
        logger.info("=== è°ƒè¯•ä¿¡æ¯ç»“æŸ ===")
    
    def _get_tikal_script(self) -> str:
        """è·å– Tikal è„šæœ¬è·¯å¾„"""
        tikal_script = os.path.join(self.okapi_home, "tikal.sh")
        
        if not os.path.exists(tikal_script):
            raise OkapiIntegrationError(f"Tikal è„šæœ¬ä¸å­˜åœ¨: {tikal_script}")
        
        if not os.access(tikal_script, os.X_OK):
            raise OkapiIntegrationError(f"Tikal è„šæœ¬æ— æ‰§è¡Œæƒé™: {tikal_script}")
        
        logger.info(f"ä½¿ç”¨ Tikal è„šæœ¬: {tikal_script}")
        return tikal_script
    
    def _verify_java_environment(self) -> bool:
        """éªŒè¯ Java ç¯å¢ƒæ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                ["java", "-version"],
                capture_output=True,
                timeout=10
            )
            if result.returncode != 0:
                raise OkapiIntegrationError("Java ä¸å¯ç”¨")
            
            logger.info("Java ç¯å¢ƒéªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            raise OkapiIntegrationError(f"Java ç¯å¢ƒéªŒè¯å¤±è´¥: {e}")
    
    @contextmanager
    def temp_workspace(self):
        """åˆ›å»ºä¸´æ—¶å·¥ä½œç©ºé—´"""
        temp_dir = tempfile.mkdtemp(prefix="okapi_work_")
        try:
            logger.debug(f"åˆ›å»ºä¸´æ—¶å·¥ä½œç©ºé—´: {temp_dir}")
            yield temp_dir
        finally:
            # è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            shutil.rmtree(temp_dir, ignore_errors=True)
            logger.debug(f"æ¸…ç†å·¥ä½œç©ºé—´: {temp_dir}")
    
    def extract_to_xliff(self, input_file: str, output_xliff: str, 
                        source_lang: str = "zh", target_lang: str = "en",
                        java_opts: Optional[str] = None) -> bool:
        """
        ä½¿ç”¨ Tikal æå– Word æ–‡æ¡£åˆ° XLIFF
        
        æ ¹æ® Tikal æ–‡æ¡£ï¼Œæå–ä¼šç”Ÿæˆ input_file.xlf æ–‡ä»¶
        
        Args:
            input_file: è¾“å…¥çš„ Word æ–‡æ¡£è·¯å¾„
            output_xliff: è¾“å‡ºçš„ XLIFF æ–‡ä»¶è·¯å¾„
            source_lang: æºè¯­è¨€ä»£ç 
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            java_opts: Java é€‰é¡¹
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # ä½¿ç”¨ Tikal è„šæœ¬ - é»˜è®¤ç”Ÿæˆ XLIFF 1.2ï¼Œä½†æˆ‘ä»¬ä¼šå¤„ç†ä¸º 2.0
            cmd = [self.tikal_script, "-x", input_file, "-sl", source_lang, "-tl", target_lang]
            logger.info(f"ä½¿ç”¨ Tikal è„šæœ¬æ‰§è¡Œæå–")
            logger.info(f"æ‰§è¡Œæå–å‘½ä»¤: {' '.join(cmd)}")
            
            # è®°å½•æ‰§è¡Œæ—¶é—´
            start_time = time.time()
            
            # æ‰§è¡Œè¿›ç¨‹
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=120,  # 2åˆ†é’Ÿè¶…æ—¶
                cwd=os.path.dirname(input_file)  # åœ¨è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•æ‰§è¡Œ
            )
            
            duration = time.time() - start_time
            logger.info(f"Tikal æå–å®Œæˆï¼Œç”¨æ—¶: {duration:.2f}ç§’")
            
            # è¯¦ç»†çš„ç»“æœå¤„ç†
            if result.returncode == 0:
                # æ ¹æ® Tikal æ–‡æ¡£ï¼Œè¾“å‡ºæ–‡ä»¶ä¸º input_file.xlf
                expected_xliff = f"{input_file}.xlf"
                
                if os.path.exists(expected_xliff):
                    # å¤åˆ¶åˆ°æŒ‡å®šä½ç½®
                    shutil.copy2(expected_xliff, output_xliff)
                    logger.info(f"âœ… Tikal æå–æˆåŠŸ: {output_xliff}")
                    if result.stdout:
                        logger.debug(f"STDOUT: {result.stdout}")
                    return True
                else:
                    logger.error(f"âŒ é¢„æœŸçš„ XLIFF æ–‡ä»¶ä¸å­˜åœ¨: {expected_xliff}")
                    return False
            else:
                logger.error(f"âŒ Tikal æå–å¤±è´¥ (è¿”å›ç : {result.returncode})")
                logger.error(f"STDOUT: {result.stdout}")
                logger.error(f"STDERR: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ Tikal æ‰§è¡Œè¶…æ—¶")
            return False
        except FileNotFoundError:
            logger.error("âŒ Java æˆ– Tikal æœªæ‰¾åˆ°")
            return False
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def merge_from_xliff(self, original_file: str, xliff_file: str, 
                        output_file: str, java_opts: Optional[str] = None) -> bool:
        """
        å°†ç¿»è¯‘åçš„ XLIFF åˆå¹¶å› Word æ–‡æ¡£
        
        æ ¹æ® Tikal æ–‡æ¡£ï¼Œåˆå¹¶æ—¶éœ€è¦ï¼š
        1. XLIFF æ–‡ä»¶åä¸ºï¼šoriginal_file.xlf
        2. åŸå§‹æ–‡ä»¶åœ¨åŒä¸€ç›®å½•
        3. è¾“å‡ºæ–‡ä»¶ä¸ºï¼šoriginal_file.out.docx
        
        Args:
            original_file: åŸå§‹ Word æ–‡æ¡£è·¯å¾„
            xliff_file: ç¿»è¯‘åçš„ XLIFF æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºçš„ Word æ–‡æ¡£è·¯å¾„
            java_opts: Java é€‰é¡¹
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç¡®ä¿åŸå§‹æ–‡ä»¶åœ¨ XLIFF æ–‡ä»¶çš„åŒä¸€ç›®å½•
            xliff_dir = os.path.dirname(xliff_file)
            original_filename = os.path.basename(original_file)
            original_in_xliff_dir = os.path.join(xliff_dir, original_filename)
            
            # å¤åˆ¶åŸå§‹æ–‡ä»¶åˆ° XLIFF ç›®å½•ï¼ˆå¦‚æœä¸åœ¨åŒä¸€ç›®å½•ï¼‰
            if original_file != original_in_xliff_dir:
                shutil.copy2(original_file, original_in_xliff_dir)
                logger.info(f"å¤åˆ¶åŸå§‹æ–‡ä»¶åˆ° XLIFF ç›®å½•: {original_in_xliff_dir}")
            
            # æ ¹æ® Tikal å®˜æ–¹æ–‡æ¡£ï¼ŒXLIFF æ–‡ä»¶ååº”è¯¥æ˜¯åŸå§‹æ–‡ä»¶ååŠ ä¸Š .xlf æ‰©å±•å
            # ä¾‹å¦‚ï¼šmyFile.html -> myFile.html.xlf
            correct_xliff_name = f"{original_filename}.xlf"
            correct_xliff_path = os.path.join(xliff_dir, correct_xliff_name)
            
            # å¦‚æœå½“å‰ XLIFF æ–‡ä»¶åä¸æ­£ç¡®ï¼Œé‡å‘½åå®ƒ
            if os.path.basename(xliff_file) != correct_xliff_name:
                shutil.copy2(xliff_file, correct_xliff_path)
                logger.info(f"é‡å‘½å XLIFF æ–‡ä»¶ä¸º: {correct_xliff_path}")
                xliff_file = correct_xliff_path
            else:
                # å¦‚æœæ–‡ä»¶åå·²ç»æ­£ç¡®ï¼Œä½¿ç”¨å½“å‰è·¯å¾„
                xliff_file = correct_xliff_path
            
            # ç¡®ä¿æ–‡ä»¶ç¡®å®å­˜åœ¨ä¸”æœ‰æ­£ç¡®çš„æ‰©å±•å
            if not os.path.exists(xliff_file):
                logger.error(f"XLIFF æ–‡ä»¶ä¸å­˜åœ¨: {xliff_file}")
                return False
            
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            if not xliff_file.endswith('.xlf'):
                logger.error(f"æ–‡ä»¶æ‰©å±•åä¸æ­£ç¡®: {xliff_file}")
                return False
            
            logger.info(f"ä½¿ç”¨ XLIFF æ–‡ä»¶è¿›è¡Œåˆå¹¶: {xliff_file}")
            
            # åˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶è¿›è¡Œè°ƒè¯•
            logger.info(f"ç›®å½• {xliff_dir} ä¸­çš„æ–‡ä»¶:")
            for f in os.listdir(xliff_dir):
                logger.info(f"  - {f}")
            
            # ä½¿ç”¨ Tikal è„šæœ¬ - æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œåˆå¹¶å‘½ä»¤ä¸éœ€è¦ -f å‚æ•°
            cmd = [self.tikal_script, "-m", xliff_file, "-trace"]
            logger.info(f"ä½¿ç”¨ Tikal è„šæœ¬æ‰§è¡Œåˆå¹¶")
            
            logger.info(f"æ‰§è¡Œåˆå¹¶å‘½ä»¤: {' '.join(cmd)}")
            
            # è®°å½•æ‰§è¡Œæ—¶é—´
            start_time = time.time()
            
            # æ‰§è¡Œè„šæœ¬
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=120,
                cwd=xliff_dir  # åœ¨ XLIFF æ–‡ä»¶æ‰€åœ¨ç›®å½•æ‰§è¡Œ
            )
            
            duration = time.time() - start_time
            logger.info(f"Tikal åˆå¹¶å®Œæˆï¼Œç”¨æ—¶: {duration:.2f}ç§’")
            
            if result.returncode == 0:
                # æ£€æŸ¥ç›®å½•ä¸­ç”Ÿæˆçš„æ‰€æœ‰æ–‡ä»¶
                logger.info(f"Tikal åˆå¹¶æˆåŠŸï¼Œæ£€æŸ¥è¾“å‡ºæ–‡ä»¶...")
                logger.info(f"ç›®å½• {xliff_dir} ä¸­çš„æ‰€æœ‰æ–‡ä»¶:")
                for f in os.listdir(xliff_dir):
                    logger.info(f"  - {f}")
                
                # æŸ¥æ‰¾å¯èƒ½çš„è¾“å‡ºæ–‡ä»¶
                # æ ¹æ®åŸå§‹æ–‡ä»¶æ‰©å±•åç¡®å®šè¾“å‡ºæ–‡ä»¶æ‰©å±•å
                original_ext = os.path.splitext(original_filename)[1].lower()
                if original_ext == '.pptx':
                    output_ext = '.pptx'
                    expected_pattern = '.out.pptx'
                elif original_ext in ['.docx', '.doc']:
                    output_ext = '.docx'
                    expected_pattern = '.out.docx'
                else:
                    # é»˜è®¤ä½¿ç”¨åŸå§‹æ–‡ä»¶æ‰©å±•å
                    output_ext = original_ext
                    expected_pattern = f'.out{original_ext}'
                
                possible_outputs = []
                for f in os.listdir(xliff_dir):
                    # æŸ¥æ‰¾åŒ¹é…çš„è¾“å‡ºæ–‡ä»¶ï¼ˆ.out.æ‰©å±•åï¼‰
                    if f.endswith(expected_pattern) and f != original_filename:
                        possible_outputs.append(f)
                    # ä¹ŸæŸ¥æ‰¾åŒæ‰©å±•åçš„æ–‡ä»¶ï¼ˆå…¼å®¹å…¶ä»–å¯èƒ½çš„å‘½åæ–¹å¼ï¼‰
                    elif f.endswith(output_ext) and f != original_filename and '.out.' in f:
                        possible_outputs.append(f)
                
                if possible_outputs:
                    # ä½¿ç”¨æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªè¾“å‡ºæ–‡ä»¶
                    output_filename = possible_outputs[0]
                    actual_output = os.path.join(xliff_dir, output_filename)
                    shutil.copy2(actual_output, output_file)
                    logger.info(f"âœ… XLIFF åˆå¹¶æˆåŠŸ: {output_file}")
                    logger.info(f"å®é™…è¾“å‡ºæ–‡ä»¶: {actual_output}")
                    if result.stdout:
                        logger.debug(f"STDOUT: {result.stdout}")
                    return True
                else:
                    logger.error(f"âŒ æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶")
                    logger.error(f"æœŸæœ›çš„æ–‡ä»¶: {original_filename}{expected_pattern}")
                    logger.error(f"ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶:")
                    for f in os.listdir(xliff_dir):
                        logger.error(f"  - {f}")
                    return False
            else:
                logger.error(f"âŒ XLIFF åˆå¹¶å¤±è´¥: {result.stderr}")
                logger.error(f"STDOUT: {result.stdout}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ åˆå¹¶è¿‡ç¨‹å‡ºé”™: {e}")
            return False
    
    def parse_xliff_content(self, xliff_file: str) -> List[Dict[str, Any]]:
        """
        è§£æ XLIFF æ–‡ä»¶å†…å®¹ï¼Œæå–éœ€è¦ç¿»è¯‘çš„æ–‡æœ¬
        
        Args:
            xliff_file: XLIFF æ–‡ä»¶è·¯å¾„
            
        Returns:
            List[Dict]: ç¿»è¯‘å•å…ƒåˆ—è¡¨
        """
        try:
            logger.info(f"å¼€å§‹è§£æ XLIFF æ–‡ä»¶: {xliff_file}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(xliff_file):
                logger.error(f"XLIFF æ–‡ä»¶ä¸å­˜åœ¨: {xliff_file}")
                return []
            
            # è¯»å–æ–‡ä»¶å†…å®¹è¿›è¡Œè°ƒè¯•
            with open(xliff_file, 'r', encoding='utf-8') as f:
                content = f.read()
                logger.info(f"XLIFF æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
                logger.info(f"XLIFF æ–‡ä»¶å†…å®¹å‰1000å­—ç¬¦: {content[:1000]}")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å« trans-unit æˆ– unit
                if 'trans-unit' in content:
                    logger.info("æ–‡ä»¶ä¸­åŒ…å« trans-unit æ ‡ç­¾")
                if 'unit' in content:
                    logger.info("æ–‡ä»¶ä¸­åŒ…å« unit æ ‡ç­¾")
                if 'source' in content:
                    logger.info("æ–‡ä»¶ä¸­åŒ…å« source æ ‡ç­¾")
                if 'target' in content:
                    logger.info("æ–‡ä»¶ä¸­åŒ…å« target æ ‡ç­¾")
            
            tree = ET.parse(xliff_file)
            root = tree.getroot()
            
            logger.info(f"XLIFF æ ¹å…ƒç´ : {root.tag}")
            
            # æ”¯æŒ XLIFF 1.2 å’Œ 2.0 æ ¼å¼
            translation_units = []
            
            # æ£€æŸ¥ XLIFF ç‰ˆæœ¬
            if 'urn:oasis:names:tc:xliff:document:2.0' in root.tag:
                logger.info("è§£æ XLIFF 2.0 æ ¼å¼")
                namespaces = {'xliff': 'urn:oasis:names:tc:xliff:document:2.0'}
                unit_xpath = './/xliff:unit'
                source_xpath = './/xliff:source'
                target_xpath = './/xliff:target'
            else:
                logger.info("è§£æ XLIFF 1.2 æ ¼å¼")
                namespaces = {'xliff': 'urn:oasis:names:tc:xliff:document:1.2'}
                unit_xpath = './/xliff:trans-unit'
                source_xpath = './/xliff:source'
                target_xpath = './/xliff:target'
            
            units = root.findall(unit_xpath, namespaces)
            logger.info(f"æ‰¾åˆ° {len(units)} ä¸ªç¿»è¯‘å•å…ƒ")
            
            for unit in units:
                unit_id = unit.get('id', '')
                
                source_elem = unit.find(source_xpath, namespaces)
                target_elem = unit.find(target_xpath, namespaces)
                
                if source_elem is not None:
                    # åªæå–<bpt>å’Œ<ept>æ ‡ç­¾ä¹‹é—´çš„çº¯æ–‡æœ¬å†…å®¹
                    # ä¸æå–<bpt>å’Œ<ept>æ ‡ç­¾å†…éƒ¨çš„æ ¼å¼ä¿¡æ¯
                    text_parts = []
                    
                    # æ·»åŠ sourceå…ƒç´ å¼€å¤´çš„ç›´æ¥æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
                    if source_elem.text:
                        text_parts.append(source_elem.text)
                    
                    # éå†æ‰€æœ‰å­å…ƒç´ ï¼Œåªæå–å®é™…æ–‡æœ¬å†…å®¹
                    for child in source_elem:
                        # è·³è¿‡<bpt>å’Œ<ept>æ ‡ç­¾æœ¬èº«ï¼Œä½†æå–å®ƒä»¬åé¢çš„tailæ–‡æœ¬
                        if child.tail:
                            text_parts.append(child.tail)
                    
                    source_text = ''.join(text_parts).strip()
                    
                    if source_text and len(source_text) > 0:
                        translation_units.append({
                            'id': unit_id,
                            'source': source_text,  # çº¯æ–‡æœ¬ç”¨äºç¿»è¯‘
                            'target': ''.join(target_elem.itertext()).strip() if target_elem is not None else '',
                            'unit_element': unit
                        })
            
            logger.info(f"è§£æåˆ° {len(translation_units)} ä¸ªç¿»è¯‘å•å…ƒ")
            return translation_units
            
        except Exception as e:
            logger.error(f"è§£æ XLIFF æ–‡ä»¶å¤±è´¥: {e}")
            return []

    def parse_xliff_with_placeholders(self, xliff_file: str) -> List[Dict[str, Any]]:
        """
        è§£æ XLIFF æ–‡ä»¶å†…å®¹ï¼Œä½¿ç”¨å ä½ç¬¦æ ‡è®°æ ¼å¼è¾¹ç•Œ
        
        Args:
            xliff_file: XLIFF æ–‡ä»¶è·¯å¾„
            
        Returns:
            List[Dict]: ç¿»è¯‘å•å…ƒåˆ—è¡¨ï¼ŒåŒ…å«å ä½ç¬¦ä¿¡æ¯
        """
        try:
            logger.info(f"å¼€å§‹è§£æ XLIFF æ–‡ä»¶ï¼ˆä½¿ç”¨å ä½ç¬¦ï¼‰: {xliff_file}")
            
            if not os.path.exists(xliff_file):
                logger.error(f"XLIFF æ–‡ä»¶ä¸å­˜åœ¨: {xliff_file}")
                return []
            
            tree = ET.parse(xliff_file)
            root = tree.getroot()
            
            # æ”¯æŒ XLIFF 1.2 å’Œ 2.0 æ ¼å¼
            if 'urn:oasis:names:tc:xliff:document:2.0' in root.tag:
                logger.info("è§£æ XLIFF 2.0 æ ¼å¼")
                namespaces = {'xliff': 'urn:oasis:names:tc:xliff:document:2.0'}
                unit_xpath = './/xliff:unit'
                source_xpath = './/xliff:source'
                target_xpath = './/xliff:target'
            else:
                logger.info("è§£æ XLIFF 1.2 æ ¼å¼")
                namespaces = {'xliff': 'urn:oasis:names:tc:xliff:document:1.2'}
                unit_xpath = './/xliff:trans-unit'
                source_xpath = './/xliff:source'
                target_xpath = './/xliff:target'
            
            units = root.findall(unit_xpath, namespaces)
            logger.info(f"æ‰¾åˆ° {len(units)} ä¸ªç¿»è¯‘å•å…ƒ")
            
            translation_units = []
            
            for unit in units:
                unit_id = unit.get('id', '')
                source_elem = unit.find(source_xpath, namespaces)
                target_elem = unit.find(target_xpath, namespaces)
                
                if source_elem is not None:
                    # æ„å»ºå¸¦å ä½ç¬¦çš„æ–‡æœ¬ç»“æ„
                    placeholder_info = self._build_placeholder_text(source_elem)
                    
                    if placeholder_info['text_with_placeholders']:
                        translation_units.append({
                            'id': unit_id,
                            'source': placeholder_info['text_with_placeholders'],
                            'placeholder_info': placeholder_info,
                            'target': ''.join(target_elem.itertext()).strip() if target_elem is not None else '',
                            'unit_element': unit
                        })
            
            logger.info(f"è§£æåˆ° {len(translation_units)} ä¸ªç¿»è¯‘å•å…ƒï¼ˆä½¿ç”¨å ä½ç¬¦ï¼‰")
            return translation_units
            
        except Exception as e:
            logger.error(f"è§£æ XLIFF æ–‡ä»¶å¤±è´¥: {e}")
            return []

    def _build_placeholder_text(self, source_elem) -> Dict[str, Any]:
        """
        æ„å»ºå¸¦å ä½ç¬¦çš„æ–‡æœ¬ç»“æ„
        
        Args:
            source_elem: sourceå…ƒç´ 
            
        Returns:
            Dict: åŒ…å«å ä½ç¬¦ä¿¡æ¯çš„å­—å…¸
        """
        # ä½¿ç”¨ç‰¹æ®Šå ä½ç¬¦ â˜¼ (U+263C WHITE SUN WITH RAYS)
        # è¿™ä¸ªç¬¦å·å¾ˆå°‘è§ï¼Œä¸å¤ªå¯èƒ½å‡ºç°åœ¨æ­£å¸¸æ–‡æœ¬ä¸­
        PLACEHOLDER = "â™‚"
        
        text_parts = []
        text_with_placeholders = ""
        format_tags = []
        
        # å¤„ç†å¼€å¤´çš„ç›´æ¥æ–‡æœ¬
        if source_elem.text:
            text_parts.append(source_elem.text)
            text_with_placeholders += source_elem.text
        
        # å¤„ç†æ‰€æœ‰å­å…ƒç´ 
        for child in source_elem:
            # å¤„ç†æ ¼å¼æ ‡ç­¾
            if child.tag.endswith('}bpt') or child.tag.endswith('}ept') or child.tag.endswith('}ph'):
                format_tags.append({
                    'tag': child.tag,
                    'attrib': child.attrib.copy(),
                    'content': child.text or '',
                    'position': len(text_parts)  # è®°å½•åœ¨å“ªä¸ªæ–‡æœ¬æ®µä¹‹å
                })
                # åœ¨æ ¼å¼æ ‡ç­¾ä½ç½®æ’å…¥å ä½ç¬¦
                text_with_placeholders += PLACEHOLDER
            
            # å¤„ç†æ ‡ç­¾åçš„æ–‡æœ¬
            if child.tail:
                text_parts.append(child.tail)
                text_with_placeholders += child.tail
        
        return {
            'text_parts': text_parts,
            'text_with_placeholders': text_with_placeholders,
            'format_tags': format_tags,
            'placeholder': PLACEHOLDER
        }

    def _clean_placeholder_spaces(self, translated_text: str, placeholder: str) -> str:
        """
        æ™ºèƒ½æ¸…ç†å ä½ç¬¦å‰åçš„ç©ºæ ¼
        
        Args:
            translated_text: ç¿»è¯‘åçš„æ–‡æœ¬
            placeholder: å ä½ç¬¦
            
        Returns:
            str: æ¸…ç†åçš„æ–‡æœ¬
        """
        import re
        
        # æƒ…å†µ1ï¼šå ä½ç¬¦å‰åéƒ½æœ‰ç©ºæ ¼ï¼Œåˆ é™¤åé¢çš„ä¸€ä¸ªç©ºæ ¼
        # ä¾‹å¦‚ï¼šâ™‚ XCMG â™‚ Personnel -> â™‚ XCMG â™‚Personnel
        pattern = f"{placeholder} (.+?) {placeholder}"
        replacement = f"{placeholder}\\1 {placeholder}"
        cleaned_text = re.sub(pattern, replacement, translated_text)
        
        # å…¶ä»–æƒ…å†µï¼ˆâ™‚å‰é¢æœ‰ç©ºæ ¼åé¢æ²¡æœ‰ï¼Œâ™‚åé¢æœ‰ç©ºæ ¼å‰é¢æ²¡æœ‰ï¼Œâ™‚å‰åéƒ½æ²¡æœ‰ç©ºæ ¼ï¼‰
        # éƒ½ä¸åˆ é™¤ç©ºæ ¼ï¼Œä¿æŒåŸæ ·
        
        logger.debug(f"æ™ºèƒ½æ¸…ç†å ä½ç¬¦ç©ºæ ¼: '{translated_text}' -> '{cleaned_text}'")
        return cleaned_text

    def apply_translation_with_placeholders(self, target_elem, translated_text: str, placeholder_info: Dict[str, Any]) -> bool:
        """
        å°†ç¿»è¯‘æ–‡æœ¬åº”ç”¨åˆ°ç›®æ ‡å…ƒç´ ï¼Œä½¿ç”¨å ä½ç¬¦æ¢å¤æ ¼å¼æ ‡ç­¾
        
        Args:
            target_elem: ç›®æ ‡å…ƒç´ 
            translated_text: ç¿»è¯‘åçš„æ–‡æœ¬
            placeholder_info: å ä½ç¬¦ä¿¡æ¯
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ¸…ç©ºç›®æ ‡å…ƒç´ 
            target_elem.clear()
            
            placeholder = placeholder_info['placeholder']
            format_tags = placeholder_info['format_tags']
            
            # æ¸…ç†å ä½ç¬¦åé¢çš„å¤šä½™ç©ºæ ¼
            cleaned_text = self._clean_placeholder_spaces(translated_text, placeholder)
            
            if not format_tags:
                # æ²¡æœ‰æ ¼å¼æ ‡ç­¾ï¼Œç›´æ¥è®¾ç½®æ–‡æœ¬
                target_elem.text = cleaned_text
                return True
            
            # æŒ‰å ä½ç¬¦åˆ†å‰²ç¿»è¯‘æ–‡æœ¬
            translated_parts = cleaned_text.split(placeholder)
            logger.debug(f"ç¿»è¯‘æ–‡æœ¬æŒ‰å ä½ç¬¦åˆ†å‰²: {len(translated_parts)} éƒ¨åˆ†")
            
            # é‡å»ºXMLç»“æ„
            current_part_index = 0
            
            for i, format_tag in enumerate(format_tags):
                # æ·»åŠ æ ¼å¼æ ‡ç­¾å‰çš„æ–‡æœ¬
                if current_part_index < len(translated_parts):
                    text_before = translated_parts[current_part_index]
                    if target_elem.text is None:
                        target_elem.text = text_before
                    else:
                        if len(target_elem) == 0:
                            target_elem.text = (target_elem.text or "") + text_before
                        else:
                            last_child = target_elem[-1]
                            last_child.tail = (last_child.tail or "") + text_before
                    current_part_index += 1
                
                # æ·»åŠ æ ¼å¼æ ‡ç­¾
                new_tag = ET.SubElement(target_elem, format_tag['tag'], format_tag['attrib'])
                if format_tag['content']:
                    new_tag.text = format_tag['content']
            
            # æ·»åŠ å‰©ä½™çš„æ–‡æœ¬
            if current_part_index < len(translated_parts):
                remaining_text = translated_parts[current_part_index]
                if target_elem.text is None:
                    target_elem.text = remaining_text
                else:
                    if len(target_elem) == 0:
                        target_elem.text = (target_elem.text or "") + remaining_text
                    else:
                        last_child = target_elem[-1]
                        last_child.tail = (last_child.tail or "") + remaining_text
            
            logger.debug(f"å ä½ç¬¦æ ¼å¼æ˜ å°„æˆåŠŸï¼Œç¿»è¯‘æ–‡æœ¬é•¿åº¦: {len(cleaned_text)}")
            return True
            
        except Exception as e:
            logger.error(f"å ä½ç¬¦æ ¼å¼æ˜ å°„å¤±è´¥: {e}")
            return False
    
    def update_xliff_translations(self, xliff_file: str, translations: Dict[str, str]) -> bool:
        """
        æ›´æ–° XLIFF æ–‡ä»¶ä¸­çš„ç¿»è¯‘å†…å®¹
        
        Args:
            xliff_file: XLIFF æ–‡ä»¶è·¯å¾„
            translations: ç¿»è¯‘ç»“æœå­—å…¸ {unit_id: translated_text}
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            tree = ET.parse(xliff_file)
            root = tree.getroot()
            
            updated_count = 0
            
            # æ£€æŸ¥ XLIFF ç‰ˆæœ¬å¹¶å®šä¹‰ç›¸åº”çš„å‘½åç©ºé—´
            if 'urn:oasis:names:tc:xliff:document:2.0' in root.tag:
                logger.info("æ›´æ–° XLIFF 2.0 æ ¼å¼")
                namespaces = {'xliff': 'urn:oasis:names:tc:xliff:document:2.0'}
                unit_xpath = './/xliff:unit'
                source_xpath = './/xliff:source'
                target_xpath = './/xliff:target'
                target_ns = f'{{{namespaces["xliff"]}}}target'
            else:
                logger.info("æ›´æ–° XLIFF 1.2 æ ¼å¼")
                namespaces = {'xliff': 'urn:oasis:names:tc:xliff:document:1.2'}
                unit_xpath = './/xliff:trans-unit'
                source_xpath = './/xliff:source'
                target_xpath = './/xliff:target'
                target_ns = f'{{{namespaces["xliff"]}}}target'
            
            # æ›´æ–°æ¯ä¸ªç¿»è¯‘å•å…ƒ
            units = root.findall(unit_xpath, namespaces)
            logger.info(f"æ‰¾åˆ° {len(units)} ä¸ªç¿»è¯‘å•å…ƒè¿›è¡Œæ›´æ–°")
            
            for unit in units:
                unit_id = unit.get('id', '')
                
                if unit_id in translations:
                    # æŸ¥æ‰¾æˆ–åˆ›å»ºç›®æ ‡å…ƒç´ 
                    target_elem = unit.find(target_xpath, namespaces)
                    if target_elem is None:
                        # å¦‚æœæ²¡æœ‰ç›®æ ‡å…ƒç´ ï¼Œåˆ›å»ºä¸€ä¸ª
                        source_elem = unit.find(source_xpath, namespaces)
                        if source_elem is not None:
                            target_elem = ET.SubElement(unit, target_ns)
                    
                    if target_elem is not None:
                        # ä¿æŒtargetå…ƒç´ çš„å®Œæ•´ç»“æ„ï¼Œåªæ›¿æ¢å…¶ä¸­çš„æ–‡æœ¬å†…å®¹
                        translated_text = translations[unit_id]
                        
                        # æ–¹æ³•ï¼šä¿æŒæ‰€æœ‰<bpt>å’Œ<ept>æ ‡ç­¾ï¼Œåªæ›¿æ¢å®ƒä»¬ä¹‹é—´çš„æ–‡æœ¬
                        # é¦–å…ˆä¿å­˜æ‰€æœ‰æ ¼å¼æ ‡ç­¾
                        format_tags = []
                        for child in target_elem:
                            if child.tag.endswith('}bpt') or child.tag.endswith('}ept'):
                                format_tags.append((child.tag, child.attrib.copy(), child.text))
                        
                        # æ¸…ç©ºtargetå…ƒç´ 
                        target_elem.clear()
                        
                        # é‡æ–°æ’å…¥æ ¼å¼æ ‡ç­¾
                        for tag, attrib, text in format_tags:
                            new_tag = ET.SubElement(target_elem, tag, attrib)
                            if text:
                                new_tag.text = text
                        
                        # å°†ç¿»è¯‘æ–‡æœ¬ä½œä¸ºçº¯æ–‡æœ¬æ’å…¥ï¼ˆOkapiä¼šåœ¨åˆå¹¶æ—¶å¤„ç†ï¼‰
                        target_elem.text = translated_text
                        
                        updated_count += 1
                        logger.debug(f"æ›´æ–°ç¿»è¯‘å•å…ƒ {unit_id}: {translated_text[:50]}...")
            
            # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
            tree.write(xliff_file, encoding='utf-8', xml_declaration=True)
            
            logger.info(f"æ›´æ–°äº† {updated_count} ä¸ªç¿»è¯‘å•å…ƒ")
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–° XLIFF ç¿»è¯‘å¤±è´¥: {e}")
            return False

    def update_xliff_translations_with_placeholders(self, xliff_file: str, translations: Dict[str, Dict]) -> bool:
        """
        æ›´æ–° XLIFF æ–‡ä»¶ä¸­çš„ç¿»è¯‘å†…å®¹ï¼Œä½¿ç”¨å ä½ç¬¦æ¢å¤æ ¼å¼æ ‡ç­¾
        
        Args:
            xliff_file: XLIFF æ–‡ä»¶è·¯å¾„
            translations: ç¿»è¯‘ç»“æœå­—å…¸ {unit_id: {'text': translated_text, 'placeholder_info': placeholder_info}}
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            tree = ET.parse(xliff_file)
            root = tree.getroot()
            
            updated_count = 0
            
            # æ£€æŸ¥ XLIFF ç‰ˆæœ¬å¹¶å®šä¹‰ç›¸åº”çš„å‘½åç©ºé—´
            if 'urn:oasis:names:tc:xliff:document:2.0' in root.tag:
                logger.info("æ›´æ–° XLIFF 2.0 æ ¼å¼ï¼ˆä½¿ç”¨å ä½ç¬¦ï¼‰")
                namespaces = {'xliff': 'urn:oasis:names:tc:xliff:document:2.0'}
                unit_xpath = './/xliff:unit'
                source_xpath = './/xliff:source'
                target_xpath = './/xliff:target'
                target_ns = f'{{{namespaces["xliff"]}}}target'
            else:
                logger.info("æ›´æ–° XLIFF 1.2 æ ¼å¼ï¼ˆä½¿ç”¨å ä½ç¬¦ï¼‰")
                namespaces = {'xliff': 'urn:oasis:names:tc:xliff:document:1.2'}
                unit_xpath = './/xliff:trans-unit'
                source_xpath = './/xliff:source'
                target_xpath = './/xliff:target'
                target_ns = f'{{{namespaces["xliff"]}}}target'
            
            # æ›´æ–°æ¯ä¸ªç¿»è¯‘å•å…ƒ
            units = root.findall(unit_xpath, namespaces)
            logger.info(f"æ‰¾åˆ° {len(units)} ä¸ªç¿»è¯‘å•å…ƒè¿›è¡Œæ›´æ–°")
            logger.info(f"ç¿»è¯‘ç»“æœå­—å…¸åŒ…å« {len(translations)} ä¸ªæ¡ç›®")
            
            for unit in units:
                unit_id = unit.get('id', '')
                
                if unit_id in translations:
                    # æŸ¥æ‰¾æˆ–åˆ›å»ºç›®æ ‡å…ƒç´ 
                    target_elem = unit.find(target_xpath, namespaces)
                    if target_elem is None:
                        # å¦‚æœæ²¡æœ‰ç›®æ ‡å…ƒç´ ï¼Œåˆ›å»ºä¸€ä¸ª
                        source_elem = unit.find(source_xpath, namespaces)
                        if source_elem is not None:
                            target_elem = ET.SubElement(unit, target_ns)
                    
                    if target_elem is not None:
                        translation_data = translations[unit_id]
                        
                        # æ£€æŸ¥æ•°æ®ç»“æ„
                        if isinstance(translation_data, dict) and 'text' in translation_data:
                            # å ä½ç¬¦æ¨¡å¼
                            translated_text = translation_data['text']
                            placeholder_info = translation_data['placeholder_info']
                            
                            # ä½¿ç”¨å ä½ç¬¦æ–¹æ³•
                            success = self.apply_translation_with_placeholders(
                                target_elem, translated_text, placeholder_info
                            )
                        else:
                            # ç®€å•æ¨¡å¼
                            translated_text = translation_data
                            target_elem.text = translated_text
                            success = True
                        
                        if success:
                            updated_count += 1
                            logger.debug(f"æ›´æ–°ç¿»è¯‘å•å…ƒ {unit_id}: {translated_text[:50]}...")
                        else:
                            logger.warning(f"æ›´æ–°ç¿»è¯‘å•å…ƒ {unit_id} å¤±è´¥")
            
            # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
            tree.write(xliff_file, encoding='utf-8', xml_declaration=True)
            
            logger.info(f"æ›´æ–°äº† {updated_count} ä¸ªç¿»è¯‘å•å…ƒï¼ˆä½¿ç”¨å ä½ç¬¦ï¼‰")
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–° XLIFF ç¿»è¯‘å¤±è´¥: {e}")
            return False


class OkapiWordTranslator:
    """ä½¿ç”¨ Okapi Framework çš„ Word æ–‡æ¡£ç¿»è¯‘å™¨"""
    
    def __init__(self, okapi_home: str = "/opt/okapi", use_placeholders: bool = True):
        """
        åˆå§‹åŒ–ç¿»è¯‘å™¨
        
        Args:
            okapi_home: Okapi å®‰è£…ç›®å½•
            use_placeholders: æ˜¯å¦ä½¿ç”¨å ä½ç¬¦æ¨¡å¼
        """
        self.okapi_integration = DockerOkapiIntegration(okapi_home)
        self.translation_service = None  # ç¿»è¯‘æœåŠ¡å°†åœ¨åç»­è®¾ç½®
        self.use_placeholders = use_placeholders  # å ä½ç¬¦æ¨¡å¼
        
        logger.info(f"Okapi Word ç¿»è¯‘å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨å ä½ç¬¦: {use_placeholders}")
    
    def set_translation_service(self, translation_service):
        """è®¾ç½®ç¿»è¯‘æœåŠ¡"""
        self.translation_service = translation_service
        logger.info("ç¿»è¯‘æœåŠ¡å·²è®¾ç½®")
    
    def translate_document(self, input_file: str, output_file: str,
                          source_lang: str = "zh", target_lang: str = "en") -> bool:
        """
        ç¿»è¯‘ Word æ–‡æ¡£
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            source_lang: æºè¯­è¨€
            target_lang: ç›®æ ‡è¯­è¨€
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not self.translation_service:
            raise OkapiIntegrationError("ç¿»è¯‘æœåŠ¡æœªè®¾ç½®")
        
        try:
            with self.okapi_integration.temp_workspace() as workspace:
                # æ–‡ä»¶è·¯å¾„
                xliff_file = os.path.join(workspace, "extracted.xliff")
                translated_xliff = os.path.join(workspace, "translated.xliff")
                
                # æ­¥éª¤1ï¼šWord æ–‡æ¡£ â†’ XLIFF
                logger.info("ğŸ”„ æ­¥éª¤1: æå– Word æ–‡æ¡£åˆ° XLIFF...")
                success = self.okapi_integration.extract_to_xliff(
                    input_file, xliff_file, source_lang, target_lang
                )
                if not success:
                    return False
                
                # æ­¥éª¤2ï¼šç¿»è¯‘ XLIFF å†…å®¹
                logger.info("ğŸ”„ æ­¥éª¤2: ç¿»è¯‘ XLIFF å†…å®¹...")
                if self.use_placeholders:
                    logger.info("ä½¿ç”¨å ä½ç¬¦æ¨¡å¼")
                    success = self._translate_xliff_content_with_placeholders(
                        xliff_file, translated_xliff, source_lang, target_lang
                    )
                else:
                    logger.info("ä½¿ç”¨ç®€å•æ¨¡å¼")
                    success = self._translate_xliff_content(
                        xliff_file, translated_xliff, source_lang, target_lang
                    )
                if not success:
                    return False
                
                # æ­¥éª¤2.5ï¼šæ ¹æ®ç›®æ ‡è¯­è¨€è°ƒæ•´XLIFFä¸­çš„å­—ä½“ä¿¡æ¯
                logger.info("ğŸ”„ æ­¥éª¤2.5: æ ¹æ®ç›®æ ‡è¯­è¨€è°ƒæ•´XLIFFå­—ä½“...")
                font_success = self._adjust_xliff_font(translated_xliff, target_lang)
                if font_success:
                    logger.info("âœ… XLIFFå­—ä½“è°ƒæ•´æˆåŠŸ")
                else:
                    logger.warning("XLIFFå­—ä½“è°ƒæ•´å¤±è´¥ï¼Œä½†ç»§ç»­å¤„ç†")
                
                # æ­¥éª¤3ï¼šXLIFF â†’ Word æ–‡æ¡£
                logger.info("ğŸ”„ æ­¥éª¤3: åˆå¹¶ç¿»è¯‘åçš„ XLIFF åˆ° Word...")
                success = self.okapi_integration.merge_from_xliff(
                    input_file, translated_xliff, output_file
                )
                
                if success:
                    # æ­¥éª¤4ï¼šæ ¹æ®ç›®æ ‡è¯­è¨€è°ƒæ•´Wordæ–‡æ¡£å­—ä½“
                    logger.info("ğŸ”„ æ­¥éª¤4: æ ¹æ®ç›®æ ‡è¯­è¨€è°ƒæ•´Wordæ–‡æ¡£å­—ä½“...")
                    font_success = self._adjust_word_document_font(output_file, target_lang)
                    if font_success:
                        logger.info("âœ… Wordæ–‡æ¡£å­—ä½“è°ƒæ•´æˆåŠŸ")
                    else:
                        logger.warning("Wordæ–‡æ¡£å­—ä½“è°ƒæ•´å¤±è´¥ï¼Œä½†ç¿»è¯‘å·²å®Œæˆ")
                    
                    # åªæœ‰åœ¨å­—ä½“è°ƒæ•´å®Œæˆåæ‰è¿”å›æˆåŠŸ
                    # è¿™æ ·å¯ä»¥ç¡®ä¿å‰ç«¯çŠ¶æ€æ›´æ–°æ—¶ï¼Œæ‰€æœ‰å¤„ç†éƒ½å·²å®Œæˆ
                    logger.info("ğŸ¯ æ‰€æœ‰å¤„ç†å®Œæˆï¼šç¿»è¯‘ + å­—ä½“è°ƒæ•´")
                    return True
                else:
                    logger.error("âŒ Wordæ–‡æ¡£åˆå¹¶å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œå­—ä½“è°ƒæ•´")
                    return False
                
        except Exception as e:
            logger.error(f"ç¿»è¯‘è¿‡ç¨‹å‡ºé”™: {e}")
            return False
    
    def _translate_xliff_content(self, xliff_file: str, translated_xliff: str,
                                source_lang: str, target_lang: str) -> bool:
        """
        ç¿»è¯‘ XLIFF æ–‡ä»¶ä¸­çš„å†…å®¹
        
        Args:
            xliff_file: åŸå§‹ XLIFF æ–‡ä»¶
            translated_xliff: ç¿»è¯‘åçš„ XLIFF æ–‡ä»¶
            source_lang: æºè¯­è¨€
            target_lang: ç›®æ ‡è¯­è¨€
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # è§£æ XLIFF å†…å®¹
            translation_units = self.okapi_integration.parse_xliff_content(xliff_file)
            
            if not translation_units:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ç¿»è¯‘çš„å†…å®¹")
                # å¤åˆ¶åŸæ–‡ä»¶
                shutil.copy2(xliff_file, translated_xliff)
                return True
            
            # æ‰¹é‡ç¿»è¯‘
            translations = {}
            batch_texts = []
            batch_ids = []
            code_mappings = []
            
            # ç›´æ¥ä½¿ç”¨çº¯æ–‡æœ¬è¿›è¡Œç¿»è¯‘
            for unit in translation_units:
                batch_texts.append(unit['source'])
                batch_ids.append(unit['id'])
                code_mappings.append({})
            
            logger.info(f"å¼€å§‹æ‰¹é‡ç¿»è¯‘ {len(batch_texts)} ä¸ªæ–‡æœ¬å•å…ƒ...")
            
            # è°ƒç”¨ç¿»è¯‘æœåŠ¡
            translated_texts = self.translation_service.batch_translate(
                batch_texts, source_lang, target_lang
            )
            
            if len(translated_texts) != len(batch_texts):
                logger.error("ç¿»è¯‘ç»“æœæ•°é‡ä¸åŒ¹é…")
                return False
            
            # ç›´æ¥ä½¿ç”¨ç¿»è¯‘ç»“æœï¼Œä¸æ¢å¤æ ¼å¼æ ‡ç­¾ï¼ˆè®©Okapiå¤„ç†æ ¼å¼ï¼‰
            for i, unit_id in enumerate(batch_ids):
                translations[unit_id] = translated_texts[i]
            
            # å¤åˆ¶åŸæ–‡ä»¶å¹¶æ›´æ–°ç¿»è¯‘
            shutil.copy2(xliff_file, translated_xliff)
            success = self.okapi_integration.update_xliff_translations(
                translated_xliff, translations
            )
            
            if success:
                logger.info(f"âœ… XLIFF å†…å®¹ç¿»è¯‘å®Œæˆï¼Œå…±ç¿»è¯‘ {len(translations)} ä¸ªå•å…ƒ")
            
            return success
            
        except Exception as e:
            logger.error(f"ç¿»è¯‘ XLIFF å†…å®¹å¤±è´¥: {e}")
            return False

    def _translate_xliff_content_with_placeholders(self, xliff_file: str, translated_xliff: str,
                                                  source_lang: str, target_lang: str) -> bool:
        """
        ç¿»è¯‘ XLIFF æ–‡ä»¶ä¸­çš„å†…å®¹ï¼Œä½¿ç”¨å ä½ç¬¦ä¿æŒæ ¼å¼æ ‡ç­¾
        
        Args:
            xliff_file: åŸå§‹ XLIFF æ–‡ä»¶
            translated_xliff: ç¿»è¯‘åçš„ XLIFF æ–‡ä»¶
            source_lang: æºè¯­è¨€
            target_lang: ç›®æ ‡è¯­è¨€
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # ä½¿ç”¨å ä½ç¬¦è§£ææ–¹æ³•
            translation_units = self.okapi_integration.parse_xliff_with_placeholders(xliff_file)
            
            if not translation_units:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ç¿»è¯‘çš„å†…å®¹")
                shutil.copy2(xliff_file, translated_xliff)
                return True
            
            # æ‰¹é‡ç¿»è¯‘
            translations = {}
            placeholder_infos = {}
            batch_texts = []
            batch_ids = []
            
            # æå–å¸¦å ä½ç¬¦çš„æ–‡æœ¬è¿›è¡Œç¿»è¯‘
            for unit in translation_units:
                batch_texts.append(unit['source'])
                batch_ids.append(unit['id'])
                placeholder_infos[unit['id']] = unit['placeholder_info']
            
            logger.info(f"å¼€å§‹æ‰¹é‡ç¿»è¯‘ {len(batch_texts)} ä¸ªæ–‡æœ¬å•å…ƒï¼ˆå¸¦å ä½ç¬¦ï¼‰...")
            
            # è°ƒç”¨ç¿»è¯‘æœåŠ¡
            translated_texts = self.translation_service.batch_translate(
                batch_texts, source_lang, target_lang
            )
            
            if len(translated_texts) != len(batch_texts):
                logger.error("ç¿»è¯‘ç»“æœæ•°é‡ä¸åŒ¹é…")
                return False
            
            # ä¿å­˜ç¿»è¯‘ç»“æœå’Œå ä½ç¬¦ä¿¡æ¯
            for i, unit_id in enumerate(batch_ids):
                translations[unit_id] = {
                    'text': translated_texts[i],
                    'placeholder_info': placeholder_infos[unit_id]
                }
            
            # å¤åˆ¶åŸæ–‡ä»¶å¹¶æ›´æ–°ç¿»è¯‘
            shutil.copy2(xliff_file, translated_xliff)
            success = self.okapi_integration.update_xliff_translations_with_placeholders(
                translated_xliff, translations
            )
            
            if success:
                logger.info(f"âœ… XLIFF å†…å®¹ç¿»è¯‘å®Œæˆï¼Œå…±ç¿»è¯‘ {len(translations)} ä¸ªå•å…ƒï¼ˆä½¿ç”¨å ä½ç¬¦ï¼‰")
            
            return success
            
        except Exception as e:
            logger.error(f"ç¿»è¯‘ XLIFF å†…å®¹å¤±è´¥: {e}")
            return False

    def _adjust_xliff_font(self, xliff_file: str, target_lang: str) -> bool:
        """
        åœ¨XLIFFæ–‡ä»¶ä¸­æ ¹æ®ç›®æ ‡è¯­è¨€è°ƒæ•´å­—ä½“ä¿¡æ¯
        
        Args:
            xliff_file: XLIFFæ–‡ä»¶è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ£€æŸ¥ç›®æ ‡è¯­è¨€æ˜¯å¦ä¸ºEnglish
            if not target_lang or target_lang.lower() not in ['english', 'en', 'eng']:
                logger.debug(f"ç›®æ ‡è¯­è¨€ä¸æ˜¯Englishï¼Œä¿æŒåŸå­—ä½“: {target_lang}")
                return True
            
            logger.info(f"ç›®æ ‡è¯­è¨€æ˜¯Englishï¼Œå¼€å§‹è°ƒæ•´XLIFFå­—ä½“ä¸ºTimes New Roman")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(xliff_file):
                logger.error(f"XLIFFæ–‡ä»¶ä¸å­˜åœ¨: {xliff_file}")
                return False
            
            # è¯»å–XLIFFæ–‡ä»¶å†…å®¹è¿›è¡Œåˆ†æ
            with open(xliff_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            logger.info(f"XLIFFæ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
            logger.info(f"XLIFFæ–‡ä»¶å‰1000å­—ç¬¦: {content[:1000]}")
            
            # æŸ¥æ‰¾å­—ä½“ç›¸å…³çš„ä¿¡æ¯ - æ”¯æŒXLIFF 1.2å’Œ2.0æ ¼å¼
            font_patterns = [
                # æ ‡å‡†å­—ä½“å±æ€§
                r'font-family="([^"]*)"',
                r'font="([^"]*)"',
                r'family="([^"]*)"',
                r'typeface="([^"]*)"',
                # XLIFF 1.2ç‰¹å®šå±æ€§
                r'ns\d+:font="([^"]*)"',
                r'ns\d+:family="([^"]*)"',
                # é€šç”¨å±æ€§æŸ¥æ‰¾
                r'[a-zA-Z-]*font[a-zA-Z-]*="([^"]*)"',
                r'[a-zA-Z-]*family[a-zA-Z-]*="([^"]*)"',
            ]
            
            updated_count = 0
            modified_content = content
            
            # ç­–ç•¥1ï¼šæŸ¥æ‰¾æ ‡å‡†å­—ä½“å±æ€§
            for pattern in font_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    if match.lower() not in ['times new roman', 'timesnewroman', 'times', 'new roman']:
                        old_font = match
                        # æ›¿æ¢å­—ä½“ä¿¡æ¯
                        modified_content = re.sub(
                            f'{pattern[:-1]}"{re.escape(old_font)}"',
                            f'{pattern[:-1]}"Times New Roman"',
                            modified_content,
                            flags=re.IGNORECASE
                        )
                        logger.info(f"å­—ä½“å±æ€§ä» '{old_font}' æ›´æ”¹ä¸º 'Times New Roman'")
                        updated_count += 1
            
            # ç­–ç•¥2ï¼šæŸ¥æ‰¾åŒ…å«å­—ä½“ä¿¡æ¯çš„æ–‡æœ¬å†…å®¹
            font_names_in_text = [
                'arial', 'simsun', 'simhei', 'microsoft', 'calibri', 'verdana', 'tahoma',
                'å®‹ä½“', 'é»‘ä½“', 'å¾®è½¯é›…é»‘', 'æ–°å®‹ä½“', 'ä»¿å®‹', 'æ¥·ä½“'
            ]
            
            for font_name in font_names_in_text:
                if font_name in content.lower():
                    # æ›¿æ¢æ–‡æœ¬ä¸­çš„å­—ä½“åç§°
                    modified_content = re.sub(
                        font_name, 'Times New Roman', modified_content, flags=re.IGNORECASE
                    )
                    logger.info(f"æ–‡æœ¬å†…å®¹å­—ä½“ä» '{font_name}' æ›´æ”¹ä¸º 'Times New Roman'")
                    updated_count += 1
            
            # ç­–ç•¥3ï¼šæŸ¥æ‰¾Wordç‰¹å®šçš„æ ¼å¼æ ‡ç­¾
            word_format_patterns = [
                r'<w:rFonts w:ascii="([^"]*)"',
                r'<w:rFonts w:eastAsia="([^"]*)"',
                r'<w:rFonts w:hAnsi="([^"]*)"',
                r'<w:rFonts w:cs="([^"]*)"',
            ]
            
            for pattern in word_format_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    if match.lower() not in ['times new roman', 'timesnewroman', 'times', 'new roman']:
                        old_font = match
                        # æ›¿æ¢Wordæ ¼å¼æ ‡ç­¾ä¸­çš„å­—ä½“
                        modified_content = re.sub(
                            f'{pattern[:-1]}"{re.escape(old_font)}"',
                            f'{pattern[:-1]}"Times New Roman"',
                            modified_content,
                            flags=re.IGNORECASE
                        )
                        logger.info(f"Wordæ ¼å¼æ ‡ç­¾å­—ä½“ä» '{old_font}' æ›´æ”¹ä¸º 'Times New Roman'")
                        updated_count += 1
            
            # ç­–ç•¥4ï¼šæŸ¥æ‰¾æ ·å¼å®šä¹‰ä¸­çš„å­—ä½“
            style_patterns = [
                r'<w:style w:name="[^"]*"[^>]*>.*?<w:rFonts[^>]*w:ascii="([^"]*)"',
                r'<w:style w:name="[^"]*"[^>]*>.*?<w:rFonts[^>]*w:eastAsia="([^"]*)"',
                r'<w:style w:name="[^"]*"[^>]*>.*?<w:rFonts[^>]*w:hAnsi="([^"]*)"',
            ]
            
            for pattern in style_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    if match.lower() not in ['times new roman', 'timesnewroman', 'times', 'new roman']:
                        old_font = match
                        # æ›¿æ¢æ ·å¼ä¸­çš„å­—ä½“
                        modified_content = re.sub(
                            f'{pattern[:-1]}"{re.escape(old_font)}"',
                            f'{pattern[:-1]}"Times New Roman"',
                            modified_content,
                            flags=re.IGNORECASE | re.DOTALL
                        )
                        logger.info(f"æ ·å¼å®šä¹‰å­—ä½“ä» '{old_font}' æ›´æ”¹ä¸º 'Times New Roman'")
                        updated_count += 1
            
            # ç­–ç•¥5ï¼šæŸ¥æ‰¾å¹¶å¤„ç†æˆ‘ä»¬æ·»åŠ çš„å­—ä½“æ ‡è®°
            font_marker_pattern = r'<font:Times New Roman>(.*?)</font:Times New Roman>'
            font_marker_matches = re.findall(font_marker_pattern, content)
            
            if font_marker_matches:
                logger.info(f"æ‰¾åˆ° {len(font_marker_matches)} ä¸ªå­—ä½“æ ‡è®°")
                # ç§»é™¤å­—ä½“æ ‡è®°ï¼Œä½†ä¿ç•™æ–‡æœ¬å†…å®¹
                modified_content = re.sub(font_marker_pattern, r'\1', modified_content)
                updated_count += len(font_marker_matches)
                logger.info("å·²ç§»é™¤å­—ä½“æ ‡è®°ï¼Œæ–‡æœ¬å†…å®¹ä¿ç•™")
                
                # åœ¨XLIFFä¸­æ·»åŠ å­—ä½“æ ·å¼ä¿¡æ¯
                # æŸ¥æ‰¾æ‰€æœ‰trans-unitæ ‡ç­¾ï¼Œä¸ºåŒ…å«è‹±æ–‡çš„targetæ·»åŠ å­—ä½“å±æ€§
                trans_unit_pattern = r'(<ns0:target[^>]*>)(.*?)(</ns0:target>)'
                
                def add_font_to_target(match):
                    target_tag = match.group(1)
                    target_content = match.group(2)
                    closing_tag = match.group(3)
                    
                    # æ£€æŸ¥ç›®æ ‡æ–‡æœ¬æ˜¯å¦åŒ…å«è‹±æ–‡ï¼ˆå¯èƒ½æ˜¯ç¿»è¯‘åçš„æ–‡æœ¬ï¼‰
                    if re.search(r'[a-zA-Z]', target_content):
                        # åœ¨targetæ ‡ç­¾ä¸­æ·»åŠ å­—ä½“å±æ€§
                        if 'xml:lang="english"' in target_tag or 'target-language="english"' in content:
                            # æ·»åŠ å­—ä½“æ ·å¼å±æ€§
                            font_attr = ' ns1:font="Times New Roman"'
                            if font_attr not in target_tag:
                                target_tag = target_tag.replace('>', font_attr + '>')
                                logger.info(f"ä¸ºç›®æ ‡æ–‡æœ¬æ·»åŠ å­—ä½“å±æ€§: Times New Roman")
                                updated_count += 1
                    
                    return target_tag + target_content + closing_tag
                
                modified_content = re.sub(trans_unit_pattern, add_font_to_target, modified_content, flags=re.DOTALL)
            
            # å¦‚æœå†…å®¹æœ‰å˜åŒ–ï¼Œä¿å­˜æ–‡ä»¶
            if modified_content != content:
                with open(xliff_file, 'w', encoding='utf-8') as f:
                    f.write(modified_content)
                logger.info(f"XLIFFå­—ä½“è°ƒæ•´å®Œæˆï¼Œæ›´æ–°äº† {updated_count} å¤„å­—ä½“ä¿¡æ¯")
                return True
            else:
                logger.info("æœªæ‰¾åˆ°éœ€è¦è°ƒæ•´çš„å­—ä½“ä¿¡æ¯")
                # è¾“å‡ºæ›´å¤šè°ƒè¯•ä¿¡æ¯
                logger.info("å°è¯•æŸ¥æ‰¾æ–‡ä»¶ä¸­çš„å…¶ä»–æ ¼å¼ä¿¡æ¯...")
                
                # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½åŒ…å«æ ¼å¼ä¿¡æ¯çš„æ ‡ç­¾
                format_tags = re.findall(r'<[^>]*>', content)
                format_info = []
                for tag in format_tags:
                    if any(keyword in tag.lower() for keyword in ['font', 'family', 'style', 'format']):
                        format_info.append(tag)
                
                if format_info:
                    logger.info(f"æ‰¾åˆ° {len(format_info)} ä¸ªå¯èƒ½åŒ…å«æ ¼å¼ä¿¡æ¯çš„æ ‡ç­¾:")
                    for i, tag in enumerate(format_info[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
                        logger.info(f"  {i+1}: {tag}")
                else:
                    logger.info("æœªæ‰¾åˆ°ä»»ä½•æ ¼å¼ç›¸å…³çš„æ ‡ç­¾")
                
                return True
                
        except Exception as e:
            logger.error(f"è°ƒæ•´XLIFFå­—ä½“å¤±è´¥: {str(e)}")
            return False

    def _adjust_word_document_font(self, docx_file: str, target_lang: str) -> bool:
        """
        æ ¹æ®ç›®æ ‡è¯­è¨€è°ƒæ•´Wordæ–‡æ¡£å­—ä½“
        
        Args:
            docx_file: Wordæ–‡æ¡£è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ£€æŸ¥ç›®æ ‡è¯­è¨€æ˜¯å¦ä¸ºEnglish
            if not target_lang or target_lang.lower() not in ['english', 'en', 'eng']:
                logger.debug(f"ç›®æ ‡è¯­è¨€ä¸æ˜¯Englishï¼Œä¿æŒåŸå­—ä½“: {target_lang}")
                return True
            
            logger.info(f"ç›®æ ‡è¯­è¨€æ˜¯Englishï¼Œå¼€å§‹è°ƒæ•´å­—ä½“ä¸ºTimes New Roman")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(docx_file):
                logger.error(f"Wordæ–‡æ¡£ä¸å­˜åœ¨: {docx_file}")
                return False
            
            # ä½¿ç”¨python-docxç›´æ¥ä¿®æ”¹Wordæ–‡æ¡£
            try:
                from docx import Document
                
                # åŠ è½½æ–‡æ¡£
                doc = Document(docx_file)
                
                # éå†æ‰€æœ‰æ®µè½å’Œè¡¨æ ¼ï¼Œè°ƒæ•´å­—ä½“
                updated_count = 0
                
                # è°ƒæ•´æ®µè½å­—ä½“
                for paragraph in doc.paragraphs:
                    for run in paragraph.runs:
                        # æ£€æŸ¥runæ˜¯å¦åŒ…å«è‹±æ–‡æ–‡æœ¬
                        if run.text and re.search(r'[a-zA-Z]', run.text):
                            # å¦‚æœå­—ä½“ä¸æ˜¯Times New Romanï¼Œåˆ™æ›´æ”¹
                            if not run.font.name or run.font.name != 'Times New Roman':
                                old_font = run.font.name or 'é»˜è®¤å­—ä½“'
                                run.font.name = 'Times New Roman'
                                logger.debug(f"æ®µè½å­—ä½“ä» '{old_font}' æ›´æ”¹ä¸º 'Times New Roman': {run.text[:30]}...")
                                updated_count += 1
                
                # è°ƒæ•´è¡¨æ ¼å­—ä½“
                for table in doc.tables:
                    for row in table.rows:
                        for cell in row.cells:
                            for paragraph in cell.paragraphs:
                                for run in paragraph.runs:
                                    # æ£€æŸ¥runæ˜¯å¦åŒ…å«è‹±æ–‡æ–‡æœ¬
                                    if run.text and re.search(r'[a-zA-Z]', run.text):
                                        # å¦‚æœå­—ä½“ä¸æ˜¯Times New Romanï¼Œåˆ™æ›´æ”¹
                                        if not run.font.name or run.font.name != 'Times New Roman':
                                            old_font = run.font.name or 'é»˜è®¤å­—ä½“'
                                            run.font.name = 'Times New Roman'
                                            logger.debug(f"è¡¨æ ¼å­—ä½“ä» '{old_font}' æ›´æ”¹ä¸º 'Times New Roman': {run.text[:30]}...")
                                            updated_count += 1
                
                # ä¿å­˜æ–‡æ¡£
                doc.save(docx_file)
                logger.info(f"Wordæ–‡æ¡£å­—ä½“è°ƒæ•´å®Œæˆï¼Œæ›´æ–°äº† {updated_count} ä¸ªåŒ…å«è‹±æ–‡çš„run")
                return True
                
            except ImportError:
                logger.error("python-docxæœªå®‰è£…ï¼Œæ— æ³•è°ƒæ•´Wordæ–‡æ¡£å­—ä½“")
                return False
            except Exception as e:
                logger.error(f"è°ƒæ•´Wordæ–‡æ¡£å­—ä½“å¤±è´¥: {str(e)}")
                return False
                
        except Exception as e:
            logger.error(f"è°ƒæ•´Wordæ–‡æ¡£å­—ä½“å¤±è´¥: {str(e)}")
            return False


class OkapiPptxTranslator:
    """ä½¿ç”¨ Okapi Framework çš„ PPTX æ–‡æ¡£ç¿»è¯‘å™¨"""
    
    def __init__(self, okapi_home: str = "/opt/okapi", use_placeholders: bool = True):
        """
        åˆå§‹åŒ–ç¿»è¯‘å™¨
        
        Args:
            okapi_home: Okapi å®‰è£…ç›®å½•
            use_placeholders: æ˜¯å¦ä½¿ç”¨å ä½ç¬¦æ¨¡å¼
        """
        self.okapi_integration = DockerOkapiIntegration(okapi_home)
        self.translation_service = None  # ç¿»è¯‘æœåŠ¡å°†åœ¨åç»­è®¾ç½®
        self.use_placeholders = use_placeholders  # å ä½ç¬¦æ¨¡å¼
        
        logger.info(f"Okapi PPTX ç¿»è¯‘å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨å ä½ç¬¦: {use_placeholders}")
    
    def set_translation_service(self, translation_service):
        """è®¾ç½®ç¿»è¯‘æœåŠ¡"""
        self.translation_service = translation_service
        logger.info("ç¿»è¯‘æœåŠ¡å·²è®¾ç½®")
    
    def translate_document(self, input_file: str, output_file: str,
                          source_lang: str = "zh", target_lang: str = "en") -> bool:
        """
        ç¿»è¯‘ PPTX æ–‡æ¡£
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            source_lang: æºè¯­è¨€
            target_lang: ç›®æ ‡è¯­è¨€
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not self.translation_service:
            raise OkapiIntegrationError("ç¿»è¯‘æœåŠ¡æœªè®¾ç½®")
        
        try:
            with self.okapi_integration.temp_workspace() as workspace:
                # æ–‡ä»¶è·¯å¾„
                xliff_file = os.path.join(workspace, "extracted.xliff")
                translated_xliff = os.path.join(workspace, "translated.xliff")
                
                # æ­¥éª¤1ï¼šPPTX æ–‡æ¡£ â†’ XLIFF
                logger.info("ğŸ”„ æ­¥éª¤1: æå– PPTX æ–‡æ¡£åˆ° XLIFF...")
                success = self.okapi_integration.extract_to_xliff(
                    input_file, xliff_file, source_lang, target_lang
                )
                if not success:
                    return False
                
                # æ­¥éª¤2ï¼šç¿»è¯‘ XLIFF å†…å®¹
                logger.info("ğŸ”„ æ­¥éª¤2: ç¿»è¯‘ XLIFF å†…å®¹...")
                if self.use_placeholders:
                    logger.info("ä½¿ç”¨å ä½ç¬¦æ¨¡å¼")
                    success = self._translate_xliff_content_with_placeholders(
                        xliff_file, translated_xliff, source_lang, target_lang
                    )
                else:
                    logger.info("ä½¿ç”¨ç®€å•æ¨¡å¼")
                    success = self._translate_xliff_content(
                        xliff_file, translated_xliff, source_lang, target_lang
                    )
                if not success:
                    return False
                
                # æ­¥éª¤3ï¼šXLIFF â†’ PPTX æ–‡æ¡£
                logger.info("ğŸ”„ æ­¥éª¤3: åˆå¹¶ç¿»è¯‘åçš„ XLIFF åˆ° PPTX...")
                success = self.okapi_integration.merge_from_xliff(
                    input_file, translated_xliff, output_file
                )
                
                if success:
                    logger.info("ğŸ¯ PPTX ç¿»è¯‘å®Œæˆ")
                    return True
                else:
                    logger.error("âŒ PPTX æ–‡æ¡£åˆå¹¶å¤±è´¥")
                    return False
                
        except Exception as e:
            logger.error(f"ç¿»è¯‘è¿‡ç¨‹å‡ºé”™: {e}")
            return False
    
    def _translate_xliff_content(self, xliff_file: str, translated_xliff: str,
                                source_lang: str, target_lang: str) -> bool:
        """
        ç¿»è¯‘ XLIFF æ–‡ä»¶ä¸­çš„å†…å®¹
        
        Args:
            xliff_file: åŸå§‹ XLIFF æ–‡ä»¶
            translated_xliff: ç¿»è¯‘åçš„ XLIFF æ–‡ä»¶
            source_lang: æºè¯­è¨€
            target_lang: ç›®æ ‡è¯­è¨€
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # è§£æ XLIFF å†…å®¹
            translation_units = self.okapi_integration.parse_xliff_content(xliff_file)
            
            if not translation_units:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ç¿»è¯‘çš„å†…å®¹")
                # å¤åˆ¶åŸæ–‡ä»¶
                shutil.copy2(xliff_file, translated_xliff)
                return True
            
            # æ‰¹é‡ç¿»è¯‘
            translations = {}
            batch_texts = []
            batch_ids = []
            
            # ç›´æ¥ä½¿ç”¨çº¯æ–‡æœ¬è¿›è¡Œç¿»è¯‘
            for unit in translation_units:
                batch_texts.append(unit['source'])
                batch_ids.append(unit['id'])
            
            logger.info(f"å¼€å§‹æ‰¹é‡ç¿»è¯‘ {len(batch_texts)} ä¸ªæ–‡æœ¬å•å…ƒ...")
            
            # è°ƒç”¨ç¿»è¯‘æœåŠ¡
            translated_texts = self.translation_service.batch_translate(
                batch_texts, source_lang, target_lang
            )
            
            if len(translated_texts) != len(batch_texts):
                logger.error("ç¿»è¯‘ç»“æœæ•°é‡ä¸åŒ¹é…")
                return False
            
            # ç›´æ¥ä½¿ç”¨ç¿»è¯‘ç»“æœï¼Œä¸æ¢å¤æ ¼å¼æ ‡ç­¾ï¼ˆè®©Okapiå¤„ç†æ ¼å¼ï¼‰
            for i, unit_id in enumerate(batch_ids):
                translations[unit_id] = translated_texts[i]
            
            # å¤åˆ¶åŸæ–‡ä»¶å¹¶æ›´æ–°ç¿»è¯‘
            shutil.copy2(xliff_file, translated_xliff)
            success = self.okapi_integration.update_xliff_translations(
                translated_xliff, translations
            )
            
            if success:
                logger.info(f"âœ… XLIFF å†…å®¹ç¿»è¯‘å®Œæˆï¼Œå…±ç¿»è¯‘ {len(translations)} ä¸ªå•å…ƒ")
            
            return success
            
        except Exception as e:
            logger.error(f"ç¿»è¯‘ XLIFF å†…å®¹å¤±è´¥: {e}")
            return False

    def _translate_xliff_content_with_placeholders(self, xliff_file: str, translated_xliff: str,
                                                  source_lang: str, target_lang: str) -> bool:
        """
        ç¿»è¯‘ XLIFF æ–‡ä»¶ä¸­çš„å†…å®¹ï¼Œä½¿ç”¨å ä½ç¬¦ä¿æŒæ ¼å¼æ ‡ç­¾
        
        Args:
            xliff_file: åŸå§‹ XLIFF æ–‡ä»¶
            translated_xliff: ç¿»è¯‘åçš„ XLIFF æ–‡ä»¶
            source_lang: æºè¯­è¨€
            target_lang: ç›®æ ‡è¯­è¨€
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # ä½¿ç”¨å ä½ç¬¦è§£ææ–¹æ³•
            translation_units = self.okapi_integration.parse_xliff_with_placeholders(xliff_file)
            
            if not translation_units:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ç¿»è¯‘çš„å†…å®¹")
                shutil.copy2(xliff_file, translated_xliff)
                return True
            
            # æ‰¹é‡ç¿»è¯‘
            translations = {}
            placeholder_infos = {}
            batch_texts = []
            batch_ids = []
            
            # æå–å¸¦å ä½ç¬¦çš„æ–‡æœ¬è¿›è¡Œç¿»è¯‘
            for unit in translation_units:
                batch_texts.append(unit['source'])
                batch_ids.append(unit['id'])
                placeholder_infos[unit['id']] = unit['placeholder_info']
            
            logger.info(f"å¼€å§‹æ‰¹é‡ç¿»è¯‘ {len(batch_texts)} ä¸ªæ–‡æœ¬å•å…ƒï¼ˆå¸¦å ä½ç¬¦ï¼‰...")
            
            # è°ƒç”¨ç¿»è¯‘æœåŠ¡
            translated_texts = self.translation_service.batch_translate(
                batch_texts, source_lang, target_lang
            )
            
            if len(translated_texts) != len(batch_texts):
                logger.error("ç¿»è¯‘ç»“æœæ•°é‡ä¸åŒ¹é…")
                return False
            
            # ä¿å­˜ç¿»è¯‘ç»“æœå’Œå ä½ç¬¦ä¿¡æ¯
            for i, unit_id in enumerate(batch_ids):
                translations[unit_id] = {
                    'text': translated_texts[i],
                    'placeholder_info': placeholder_infos[unit_id]
                }
            
            # å¤åˆ¶åŸæ–‡ä»¶å¹¶æ›´æ–°ç¿»è¯‘
            shutil.copy2(xliff_file, translated_xliff)
            success = self.okapi_integration.update_xliff_translations_with_placeholders(
                translated_xliff, translations
            )
            
            if success:
                logger.info(f"âœ… XLIFF å†…å®¹ç¿»è¯‘å®Œæˆï¼Œå…±ç¿»è¯‘ {len(translations)} ä¸ªå•å…ƒï¼ˆä½¿ç”¨å ä½ç¬¦ï¼‰")
            
            return success
            
        except Exception as e:
            logger.error(f"ç¿»è¯‘ XLIFF å†…å®¹å¤±è´¥: {e}")
            return False


# ä¾¿æ·å‡½æ•°
def create_okapi_translator(okapi_home: str = "/opt/okapi", use_placeholders: bool = True) -> OkapiWordTranslator:
    """åˆ›å»º Okapi ç¿»è¯‘å™¨å®ä¾‹"""
    return OkapiWordTranslator(okapi_home, use_placeholders)


def verify_okapi_installation(okapi_home: str = "/opt/okapi") -> bool:
    """éªŒè¯ Okapi å®‰è£…æ˜¯å¦æ­£ç¡®"""
    try:
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(okapi_home):
            logger.error(f"âŒ Okapi ç›®å½•ä¸å­˜åœ¨: {okapi_home}")
            return False
        
        # å°è¯•åˆ›å»ºé›†æˆå®ä¾‹ï¼ˆä¼šè‡ªåŠ¨æŸ¥æ‰¾ JAR æ–‡ä»¶ï¼‰
        integration = DockerOkapiIntegration(okapi_home)
        logger.info("âœ… Okapi å®‰è£…éªŒè¯é€šè¿‡")
        return True
    except Exception as e:
        logger.error(f"âŒ Okapi å®‰è£…éªŒè¯å¤±è´¥: {e}")
        return False 